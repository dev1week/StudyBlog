<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Hanju]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib/media/favicon.png</url><title>Hanju</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Fri, 12 Jul 2024 15:54:49 GMT</lastBuildDate><atom:link href="lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Fri, 12 Jul 2024 15:54:48 GMT</pubDate><copyright><![CDATA[1week]]></copyright><ttl>60</ttl><dc:creator>1week</dc:creator><item><title><![CDATA[완전탐색을 DP로 바꾸기 (Memoization)]]></title><description><![CDATA[ 
 <br><br>완전 탐색은 서로 다른 여러 경우의 수를 탐색하는 중복이 많으면 많을 수록 비효율적으로 변합니다.<br><img src="https://i.imgur.com/3fizcUr.png" referrerpolicy="no-referrer"><br>fib(5)의 왼쪽 fib(4)에서 fib(3)과 fib(2)를 호출합니다. 바로 오른쪽 fib(3)에서 또한 fib(2)를 호출하기 때문에 동일한 결과를 반환하는 연산을 계속해서 시행합니다.<br><br>한 번 풀었던 부분 문제에 대한 답을 저장해 놓았다가 해당 부분 문제를 다시 풀 일이 생기면 재사용하는 것이 메모이제이션입니다.<br><br>재귀 구현에 메모이제이션을 적용하려면 다음 과정을 거치면 됩니다.<br>1: 문제에서 제시된 범위에 따라 메모이제이션 배열 선언과 초기화<br>
2: 재귀 종료 조건에 메모이제이션 조건 추가<br>
3: 부분 문제에 대한 답을 구한 후 메모이제이션 배열에 기록하기<br><br>메모이제이션을 활용해 피보나치 수열을 구하는 백트래킹 코드를 개선해 보겠습니다. 다음과 같은 사고의 흐름으로 재귀 코드를 작성한 후 메모이제이션을 적용해 시간 복잡도를 개선할 수 있습니다. <br>문제에서 제시된 범위에 따라 메모이제이션 배열 선언과 초기화합니다.<br>-차원 : 상태에 포함된 변수 개수<br>
-변수 : 차원의 인덱스<br>실제 코드<br>-피보나치 수 문제의 상태는 n 하나이므로 1차원 배열입니다.<br>
-부분 문제의 답은 피보나치 수 이므로 Long 배열이어야합니다.<br>
-최대 100까지 입력된다고 가정하면 배열의 크기는 101입니다.<br>위 3가지 조건을 고려하여 다음 코드를 작성합니다. <br>private static final long[] mem = new long[101];
Copy<br>-배열을 선언 후에는 정답이 될 수 없는 값으로 배열을 모두 채웁니다.<br>Arrays.fill(mem, -1); 
Copy<br>재귀의 종료 조건에 메모이제이션 추가합니다<br>→ 이미 풀어본 문제를 다시 풀 필요가 없습니다.<br>→ 메모이제이션이 되어 있는지 먼저 확인합니다.<br>종료 조건 vs 메모이제이션 조건의 순서<br>-종료 조건에서 비용이 큰 연산이 있다면 메모이제이션 검사를 우선으로 하는 것이 좋습니다.<br>
-종료 조건이 불가능한 상태를 검사하는 것이라면 기존 종료 조건을 먼저 검사해야합니다.<br>위 조건을 고려하면 다음 코드를 작성합니다. <br>if(mem[n] != -1) return mem[n];
if(n=0||n==1) return n; 
Copy<br>부분 문제에 대한 답을 구한 후 메모이제이션 배열에 기록<br>메모이제이션이 되어 있지 않을 경우 부분 문제를 풉니다. 이후 결과를 메모이제이션 배열에 저장합니다.<br>return mem[n] = fib(n-1) + fib(n-2); 
Copy<br>전체 코드<br>private static final long = new long[101];
private static long fib(int n){

	if(mem[n]!=-1) return men[n]; 
	
	if(n==0 || n==1) return n; 
	
	return mem[n] = fib(n-1) + fib(n-2); 
	
}

public static void main(String[] args){
	Arrays.fill(mem, -1);
	System.out.println(fib(10)); 
}
Copy<br><br>동적 프로그래밍 문제는 대부분 점화식을 이용한 재귀로 우선 구현하고 메모이제이션 처리를 추가하는 방식으로 해결 가능합니다.<br>문제 해결은 다음과 같이 진행합니다.<br>1: 상태 (부분 문제) 정의하기<br>
2: 종료 조건 찾기<br>
3: 점화식 세우기<br>
4: 재귀로 구현하기<br>
5: 메모이제이션 적용하기<br><br>1: 중복이 많이 발생하지 않는 재귀 문제는 메모이제이션 처리를 하더라도 효율적이지 않습니다.<br>→ 동적 프로그래밍을 적용하기 위해서는 중복되는 부분 문제가 많이 발생하는지 따져 보아야합니다.
Copy<br>2: 재귀 호출이 너무 깊어지면 StackOverflowError가 발생합니다. 일반적으로 재귀는 깊이를 10,000번 이하로 유지 시켜야 합니다.<br><br>
<br>탑 다운 방식은 다음과 같이 진행됩니다.
fibo(10) -&gt; fibo(9) -&gt; fibo(8) -&gt; ... -&gt; fibo(2) -&gt; fibo(1)
Copy
  n이 조금만 커져도 재귀의 깊이가 굉장히 깊어집니다.<br>

<br>-같은 부분 문제의 답은 항상 같다 는 재귀의 특성을 이용하여 다음과 같이 작은 부분 문제부터 미리 풉니다.<br>    for(int i=0; i&lt;=10000; i++){
    	fibo(i); 
    }
    ```
Copy]]></description><link>알고리즘과-자료구조/알고리즘/dp/완전탐색을-dp로-바꾸기-(memoization).html</link><guid isPermaLink="false">알고리즘과 자료구조/알고리즘/DP/완전탐색을 DP로 바꾸기 (Memoization).md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Fri, 12 Jul 2024 15:54:29 GMT</pubDate><enclosure url="https://i.imgur.com/3fizcUr.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/3fizcUr.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[소셜 로그인 구현하기]]></title><description><![CDATA[ 
 <br><br><br><a data-tooltip-position="top" aria-label="https://console.cloud.google.com/welcome?pli=1&amp;project=login-demo-380814" rel="noopener" class="external-link" href="https://console.cloud.google.com/welcome?pli=1&amp;project=login-demo-380814" target="_blank">구글 클라우드 콘솔</a>으로 접속하여 설정을 진행합니다. <br>상단의 [새프로젝트]를 클릭하여 프로젝트를 생성합니다.<br>
<img src="https://i.imgur.com/1OFEIAu.png" referrerpolicy="no-referrer"><br>이름을 설정하여 최종 생성을 진행합니다.<br>
<img src="https://i.imgur.com/Ssaj3WL.png" referrerpolicy="no-referrer"><br>[좌상단 햄버거 버튼 클릭] - [API 및 서비스] - [OAuth 동의 화면] 클릭, 외부 옵션을 체크 후 [만들기] 클릭<br>
<img src="https://i.imgur.com/iHm5zgz.png" referrerpolicy="no-referrer"><br>다음 화면에 접속하여 사용자에게 보여줄 로그인 화면을 만듭니다.<br>
<img src="https://i.imgur.com/op6MtOw.png" referrerpolicy="no-referrer"><br>[범위 추가 또는 삭제]를 클릭하여 제공받을 유저 정보의 scope를 설정해야합니다. 이 예제에서는 이메일과 프로필, 오픈아이디를 사용합니다. 체크한 후 밑의 [업데이트]를 클릭하여 반영합니다.<br>
<img src="https://i.imgur.com/LqgCv8i.png" referrerpolicy="no-referrer"><br>이후 테스트 사용자와 요약페이지는 건너뜁니다. <br>[사용자 인증 정보] - [사용자 인증 정보 만들기] - [OAuthClientID]를 클릭합니다.<br>
<img src="https://i.imgur.com/QpucyVE.png" referrerpolicy="no-referrer"><br>애플리케이션 유형을 웹 애플리케이션, redirection url을 설정합니다.<br>
<img src="https://i.imgur.com/hCXCDru.png" referrerpolicy="no-referrer"><br>생성된 클라이언트 ID와 보안 비밀번호를 확인하고 다른 파일에 복사해둡니다. <br><br><a data-tooltip-position="top" aria-label="https://developers.naver.com/main/" rel="noopener" class="external-link" href="https://developers.naver.com/main/" target="_blank">네이버 개발자 센터</a>으로 이동합니다.<br>[Applicaion] - [애플리케이션 등록]으로 이동합니다.<br><img src="https://i.imgur.com/KIzkTl6.png" referrerpolicy="no-referrer"><br>[사용 API] - [네이버 로그인] 클릭한 후 다음과 같이 설정을 진행합니다.<br>
<img src="https://i.imgur.com/2so4IYr.png" referrerpolicy="no-referrer"><br>
<img src="https://i.imgur.com/HqyrfZv.png" referrerpolicy="no-referrer"><br>클라이언트 ID와 시크릿을 확인합니다.<br>
<img src="https://i.imgur.com/ety1SLT.png" referrerpolicy="no-referrer"><br><br><br><br>public interface ProviderUser {  
  
    public String getId();  
    public String getUsername();  
    public String getPassword();  
    public String getEmail();  
    public String getProvider();  
    public List&lt;? extends GrantedAuthority&gt; getAuthorities();  
    public Map&lt;String, Object&gt; getAttributes();  
  
}
Copy<br>인터페이스로 기본 로직에 대한 골격을 작성합니다. <br><br>@Data  
public abstract class OAuth2ProviderUser implements ProviderUser {  
  
    private Map&lt;String, Object&gt; attributes;  
    private OAuth2User oAuth2User;  
    private ClientRegistration clientRegistration;  
  
    public OAuth2ProviderUser(Map&lt;String, Object&gt; attributes, OAuth2User oAuth2User, ClientRegistration clientRegistration){  
        this.attributes = attributes;  
        this.oAuth2User = oAuth2User;  
        this.clientRegistration = clientRegistration;  
    }  
  
    @Override  
    public String getPassword() {  
        return UUID.randomUUID().toString();  
    }  
  
    @Override  
    public String getEmail() {  
        return (String)attributes.get("email");  
    }  
  
    @Override  
    public String getProvider() {  
        return clientRegistration.getRegistrationId();  
    }  
  
    @Override  
    public List&lt;? extends GrantedAuthority&gt; getAuthorities() {  
        return oAuth2User.getAuthorities().stream().map(authority -&gt; new SimpleGrantedAuthority(authority.getAuthority())).collect(Collectors.toList());  
    }  
}
Copy<br>추상 클래스를 활용해 공통 로직의 구현부를 미리 정의합니다.<br><br>public class GoogleUser extends OAuth2ProviderUser {  
  
    public GoogleUser(OAuth2User oAuth2User, ClientRegistration clientRegistration){  
        super(oAuth2User.getAttributes(), oAuth2User, clientRegistration);  
    }  
  
    @Override  
    public String getId() {  
        return (String)getAttributes().get("sub");  
    }  
  
    @Override  
    public String getUsername() {  
        return (String)getAttributes().get("sub");  
    }  
  
}
Copy<br>각 벤더에 맞게끔 user 정보를 담을 구현체를 정의합니다. google의 경우 user정보로 id와 username을 제공하기 때문에 위와 같이 정의합니다. ]]></description><link>spring/openid/소셜-로그인-구현하기.html</link><guid isPermaLink="false">Spring/OpenID/소셜 로그인 구현하기.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sat, 06 Jul 2024 13:27:34 GMT</pubDate><enclosure url="https://i.imgur.com/1OFEIAu.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/1OFEIAu.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[<strong>Open ID</strong>]]></title><description><![CDATA[ 
 <br><br><br>OAuth 2.0 프로토콜을 확장한 인증 프로토콜입니다. 클라이언트 앱이 사용자의 정보(이메일, 프로필, 이름 등등)에 접근할 수 있도록 권한을 부여 받을 수 있습니다.<br><br><br>정의 : 사용자가 자신이 누구인지 확인하는 과정입니다.<br>
방법 : 로그인, 지문 인식, OTP 등<br>
-&gt; 신원 확인 <br><br>정의 : 인증된 사용자가 특정 자원이나 기능에 접근할 수 있는 권한을 부여받는 과정입니다.<br>
방법 : 관리자 페이지 접근, 프리미엄 회원에게 제공하는 특수 기능<br>
-&gt; 권한 확인 <br><br>인증은 사용자가 누구인지 확인하는 과정이고, 인가는 확인된 사용자 정보를 바탕으로 사용자가 무엇을 할 수 있는지 확인하는 과정입니다. 즉, 인증이 완료되어야만 인가가 가능해집니다. <br><br><img src="https://i.imgur.com/2TROtDc.png" referrerpolicy="no-referrer"><br><br>OAuth 2.0이란?<br>
리소스 소유자(실제 유저)로 부터 권한을 위임받은 클라이언트 애플리케이션이 리소스 서버에서 보호된 리소스에 접근할 수 있도록 허용하는 인가 프레임워크입니다. 즉 앱이 사용자의 자원에 접근할 수 있도록 권한을 부여하는 것입니다. <br>작동 방식은 다음과 같습니다.<br>
1: 클라이언트(내 웹)가 리소스 소유자(실제 사용자)의 승인을 받아 인가 서버(=구글 OAuth)로부터 액세스 토큰을 발급 받습니다.<br>
2: 클라이언트는 이 액세스 토큰을 사용하여 리소스 서버(=구글 드라이브)에 보호된 리소스에 접근합니다. <br><br>ODIC란?<br>
OAuth 2.0을 기반으로한 인증 프로토콜입니다. OAuth 2.0의 인가 기능 외에도 사용자 인증을 처리합니다. 사용자의 신원을 확인하고 사용자 정보 (ID 토큰)을 안전하게 교환합니다. <br>작동 방식은 다음과 같습니다.<br>
1: 사용자는 OpenID Connect Provider(Goolge, naver, kakao)(이하 OP)에 인증 요청을 보냅니다.<br>
2: 인증이 성공하면 OP는 클라이언트에 ID 토큰과 액세스 토큰을 반환합니다.<br>
3: 클라이언트는 ID 토큰을 사용해 사용자의 신원을 확인할 수 있습니다. <br><br>ID 토큰은 사용자가 인증되었음을 증명하는 결과물입니다. OIDC 요청시 access token과 함께 JWT 형태로 클라이언트에 전달됩니다. ID 토큰은 개인 키로 발급자가 서명하고, 앱은 공개 키로 ID 토큰의 유효성을 검사합니다. 또한 클라이언트는 클레임 정보에 포함되어 있는 사용자명, 이메일을 활용해 인증 관리를 할 수 있습니다. <br><br><img src="https://i.imgur.com/vesdmtA.png" referrerpolicy="no-referrer"><br><br>Google OAuth와 OpenID Connect 예시<br>
사용자가 클라이언트 애플리케이션에 Google 계정으로 로그인할 때, OpenID Connect를 통해 ID 토큰과 액세스 토큰을 발급받습니다.<br>ID 토큰: 클라이언트 애플리케이션이 사용자의 신원을 확인하는 데 사용됩니다(예: 사용자의 이메일 주소, 이름 등).<br>
액세스 토큰: 클라이언트 애플리케이션이 Google 드라이브 API를 호출하여 사용자의 파일에 접근할 때 사용됩니다.<br>Facebook 로그인 예시<br>
사용자가 모바일 애플리케이션에 Facebook 계정으로 로그인할 때, Facebook 인가 서버가 액세스 토큰을 발급합니다.<br>액세스 토큰: 애플리케이션이 Facebook Graph API를 통해 사용자의 친구 목록, 사진 등에 접근할 때 사용됩니다.<br><br>스코프는 클라이언트가 요청하는 권한의 범위를 지정하는 변수입니다. 클라이언트가 ID 토큰을 통해 접근할 수 있는 리소스와 정보를 명시적으로 제한하고 제어합니다. 공백으로 구분된 문자열의 리스트로 저장합니다. <br><img src="https://i.imgur.com/132iviN.png" referrerpolicy="no-referrer"><br><br><br><br><br>줄여서 OP라고 하며 OpenID 제공자로서 사용자를 인증하고 인증 결과와 사용자 정보를 신뢰 당사자에게 제공할 수 있는 OAuth 2.0 서버를 의미합니다. <br><br>줄여서 RP라고 하며 신뢰 당사자로서, 인증 요청을 처리하기 위해 OP에 의존하는 Oauth 2.0 애플리케이션을 의미합니다. <br><br>1: RP는 OP에 권한 부여 요청을 보냅니다.<br>
2: OP는 최종 사용자를 인증하고 권한을 얻습니다.<br>
3: OP는 권한을 ID 토큰과 액세스 토큰으로 응답합니다.<br>
4: RP는 Access Token을 사용하여 User의 정보를 제공하는 API에 요청을 보낼 수 있습니다.<br>
5: 유저의 정보를 제공하는 API는 최종 사용자에 대한 클레임을 반환합니다. <br><br><img src="https://i.imgur.com/hcRmqXc.png" referrerpolicy="no-referrer"><br>
요청시 주의사항<br>
1: 요청시 openid 범위를 scope에 포함합니다.<br>
2: response_type은 id_token을 포함하며, response_type이 해당 토큰을 지원해야합니다.<br>
3: 요청시 nonce를 포함해야합니다.<br>nonce란?<br>
id_token 값에 클레임으로 포함되며, 토큰의 재생 공격을 방지하고 요청의 출처를 식별하는데 사용할 수 있는 고유 문자열입니다. 응답 nonce에는 요청에서 nonce와 같은 값이어야 합니다.]]></description><link>spring/openid/open-id.html</link><guid isPermaLink="false">Spring/OpenID/Open ID.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sat, 06 Jul 2024 10:08:24 GMT</pubDate><enclosure url="https://i.imgur.com/2TROtDc.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/2TROtDc.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[사용자 정의 보안 설정하기]]></title><description><![CDATA[ 
 <br><br>한 개 이상의 SecurityFilterChaing 타입의 빈을 정의한 후 인증 API 및 인가 API를 설정합니다. <br><img src="https://i.imgur.com/c6Rl5Y1.png" referrerpolicy="no-referrer"><br>하나 이상의 SecufiryFilterChain 타입의 빈이 있어야 정상적으로 처리됩니다. 유저가 직접 설정하지 않을 경우에는 Security에서 자동 설정에 의해 기본 빈 하나가 생성됩니다. SecurityFilterChain을 빈으로 정의하면 자동설정은 이루어지지 않습니다. <br><br>실제 예제 코드를 통해 확인해보겠습니다. <br>@EnableWebSecurity  
@Configuration  
public class SecurityConfig {  
  
    @Bean  
    public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception{  
  
        http.authorizeHttpRequests(auth-&gt; auth.anyRequest().authenticated())  
                //폼로그인 방식을 default 로 사용   
.formLogin(Customizer.withDefaults());  
  
  
        return http.build();  
    }  
  
}
Copy<br>모든 설정 코드는 시큐리티 7버전부터는 람다 형식만 지원합니다. <br><br><br>spring:
  security:
    user:
      name: user
      password: 1111
      roles: USER

Copy<br><br>@Bean
public InMemoryUserDetailsManager inMemoryUserDetailsManager() {

    UserDetails user = User.withUsername("user")
        .password("{noop}1111")
        .authorities("ROLE_USER")
        .build();

    return new InMemoryUserDetailsManager(user);
}

Copy<br>위 코드를 이용하면 메모리 상에서 사용자가 정의한 유저 정보를 저장하고 있습니다. ]]></description><link>spring/security/초기화-과정-이해/3.-사용자-정의-보안-설정하기.html</link><guid isPermaLink="false">Spring/Security/초기화 과정 이해/3. 사용자 정의 보안 설정하기.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sat, 06 Jul 2024 12:56:23 GMT</pubDate><enclosure url="https://i.imgur.com/c6Rl5Y1.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/c6Rl5Y1.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[4. 인증 프로세스]]></title><description><![CDATA[ 
 <br><br><br><br>HTTP 기반의 폼 로그인 인증 매커니즘을 활성하는 API입니다. 사용자 정의 로그인 페이지를 쉽게 구현할 수 있습니다. 기본적으로는 스프링 시큐리티가 제공하는 기본 로그인 페이지를 사용하며 사용자 이름과 비밀번호 필드가 포함된 간단한 로그인 양식을 제공합니다. 사용자는 웹 폼을 통해 자격 증명(사용자 이름과 비밀번호)를 제공하고 Spring Security는 HttpServletRequest에서 이 값을 읽어옵니다. <br><br><img src="https://i.imgur.com/KDeFoTB.png" referrerpolicy="no-referrer"><br>1: 권한 검사 필터는 현재 권한으로 /user를 호출할 수 있는지 검사합니다.<br>
2: 당연히 로그인이 안된 상태이므로 권한 필터를 통과하지 못해 접근 예외가 발생합니다.<br>
3: 예외처리 필터가 발생한 예외를 처리합니다.<br>
4: AuthenticationEntryPoint가 로그인할 수 있는 페이지로 이동시킵니다. (로그인 페이지 리다이렉트)<br>
5: 로그인 페이지에서 아이디와 비밀번호를 입력받아 서버에 재요청합니다. <br><br><img src="https://i.imgur.com/QHWggyt.png" referrerpolicy="no-referrer"><br>
UsernamePasswordAuthenticationFilter가 생성되어 폼 방식의 인증 처리를 담당하게 됩니다. ]]></description><link>spring/security/초기화-과정-이해/4.-인증-프로세스.html</link><guid isPermaLink="false">Spring/Security/초기화 과정 이해/4. 인증 프로세스.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sat, 06 Jul 2024 13:05:01 GMT</pubDate><enclosure url="https://i.imgur.com/KDeFoTB.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/KDeFoTB.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Untitled]]></title><description><![CDATA[ 
 ]]></description><link>spring/untitled.html</link><guid isPermaLink="false">Spring/Untitled.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sat, 06 Jul 2024 09:30:14 GMT</pubDate></item><item><title><![CDATA[OAuth 2.0 Grant Type]]></title><description><![CDATA[ 
 <br><br><br><br>
권한부여란 클라이언트가 사용자를 대신하여 사용자의 승인 하에 인가서버로부터 권한을 부여 받는 것을 의미합니다. 
<br><br><br><img src="https://i.imgur.com/tH8wk0z.png" referrerpolicy="no-referrer"><br><br><br><br><br>흐름<br>
1: 인가서버에게 code를 요청<br>
<img src="https://i.imgur.com/WHI2uf0.png" referrerpolicy="no-referrer"><br>
2: 사용자의 승인 후 인가서버가 클라이언트에게 코드를 발급한다.<br>
<img src="https://i.imgur.com/6XFPToo.png" referrerpolicy="no-referrer"><br>3: 앱은 해당 임시 코드를 인가서버로 전달하고 액세스 토큰으로 교환한다.<br>
<img src="https://i.imgur.com/fh7yw0S.png" referrerpolicy="no-referrer"><br>특징<br>
1: 앱이 액세스 토큰을 요청 시, 해당 요청을 클라이언트 암호로 인증할 수 있습니다.<br>
-&gt; 공격자가 인증 코드를 가로채 스스로 사용할 위험이 줄어듭니다.<br>
2: 액세스 토큰이 클라이언트에 표시되지 않습니다.<br>
-&gt; 토큰이 다른 사람에게 노출될 확률이 줄어듭니다. <br>권한 부여 요청 시 필요한 매개변수 <br><br>액세스 토큰 교환 요청 시 매개변수 <br><br><br>코드 교환을 위한 증명 키로서 CSRF 및 권한부여코드 삽입 공격을 방지하기 위한 Authorization Code Grant Flow의 확장 버전입니다. 권한부여코드 요청 시 Code Verifier와 Code Challenge를 추가하여 만약 Authorization Code Grant Flow에서 Authorization Code가 탈취당했을 때, 액세스 토큰을 발급 받지 못하도록 차단합니다. 모든 유형의 OAuth2 클라이언트, 심지어 웹서버 양측 모두 유용합니다. <br><br>Code Verifier<br>
권한부여코드 요청 전 앱이 원래 생성한 PKCE 요청에 대한 코드 검증기입니다. 48~128 글자수를 가진 무작위 문자열이며, A-Z,a-z,0-9의 아스키 문자로만 구성됩니다. <br>Code Challenge<br>
선택한 Hash 알고리즘으로 Code Verifier를 Hashing한 후 Base64 인코딩을 한 값입니다. <br>Code Challenge Method<br>
plain : Code Verifier가 특정한 알고리즘을 사용하지 않도록 설정합니다.<br>
S256 : Code Verifier 해시 알고리즘을 사용하도록 설정합니다. ]]></description><link>spring/oauth-2.0/oauth-2.0-grant-type.html</link><guid isPermaLink="false">Spring/OAuth 2.0/OAuth 2.0 Grant Type.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Tue, 02 Jul 2024 15:33:34 GMT</pubDate><enclosure url="https://i.imgur.com/tH8wk0z.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/tH8wk0z.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[OAuth 2.0이란]]></title><description><![CDATA[ 
 <br><br><br>Open + Authorization의 약자입니다. OAuth 2.0인가 사용자가 속한 사이트의 보호된 자원에 대해 앱의 접근을 허용하도록 승인하는 것을 의미합니다. RFC표준 6749에서 처음 등장하였습니다. <br>인가서버가 애플리케이션에게 권한을 부여합니다. <br><br><br><img src="https://i.imgur.com/ulSOeLn.png" referrerpolicy="no-referrer"><br>
<br>해당하는 계정을 로그인하는 창을 띄운다. 
<br>id와 비밀번호를 입력받아 그대로 공급자(google, naver, kakao)에게 post요청을 보낸다. 
<br><br>
<br>아이디와 패스워드가 노출됩니다. 
<br>공급자의 모든 서비스를 제한없이 사용할 수 있습니다. 
<br>클라이언트 어플리케이션을 신뢰할 수 있는가? 
<br><br><img src="https://i.imgur.com/7CNOey1.png" referrerpolicy="no-referrer"><br><br>인가 서버의 역할을 할 수 있도록 제공하는 오픈소스입니다. 사용자 관리뿐만 아니라 토큰을 발급하고 토큰을 검증하는 기능까지 수행할 수 있도록, 기능을 제공합니다. <br><br><a rel="noopener" class="external-link" href="https://www.keycloak.org/downloads" target="_blank">https://www.keycloak.org/downloads</a><br>1: keycloack내부 bin 폴더 내부 kc.bat을 실행한다. <br>.\kc.bat start-dev
Copy<br>2: localhost:8080으로 접속한 후 admin 계정을 생성합니다.<br>
<img src="https://i.imgur.com/duTW2yz.png" referrerpolicy="no-referrer"><br>3: 계정을 생성한 후 로그인하여 접속합니다. <br>4: realm을 생성합니다.<br>
<img src="https://i.imgur.com/NbKZfkm.png" referrerpolicy="no-referrer"><br>5: 생성한 realm에서 client를 생성합니다.<br>
<img src="https://i.imgur.com/z3VsBhT.png" referrerpolicy="no-referrer"><br>
<img src="https://i.imgur.com/GlaRc0c.png" referrerpolicy="no-referrer"><br>
<img src="https://i.imgur.com/f83DjPJ.png" referrerpolicy="no-referrer"><br>6: redirect url을 지정합니다.<br>
<img src="https://i.imgur.com/F8e8cWP.png" referrerpolicy="no-referrer"><br>
<img src="https://i.imgur.com/BrnOuVM.png" referrerpolicy="no-referrer"><br>7: user를 생성합니다.<br>
<img src="https://i.imgur.com/deTpGO4.png" referrerpolicy="no-referrer"><br>8: user의 비밀번호를 생성합니다.<br>
<img src="https://i.imgur.com/F07ez4H.png" referrerpolicy="no-referrer"><br><br><img src="https://i.imgur.com/T75j0P6.png" referrerpolicy="no-referrer"><br><br>
<br>보호된 자원에 대한 접근 권한을 부여할 수 있는 주체입니다. 
<br>사용자로서 계정의 일부에 대한 접근 권한을 부여할 수 있습니다. 
<br>사용자를 대신하여 작동하려는 모든 클라이언트는 먼저 사용자의 허가를 받아야합니다. 
<br><br>
<br>우리 어플리케이션이 접근하는 사용자의 자원이 포함된 서버를 의미합니다. 
<br>액세스 토큰을 수락 및 검증할 수 있어야 하며 권한 체계에 따라 요청을 승인할 수 있어야합니다. 
<br><br>
<br>클라이언트가 사용자 계정에 대한 동의 및 접근을 요청할 때 상호 작용하는 서버입니다. 
<br>클라이언트의 권한 부여 요청을 승인하거나 거부하는 서버입니다. 
<br>사용자가 클라이언트의 권한 부여 요청을 승인한 후 access token을 클라이언트에게 부여합니다. 
<br><br>
<br>사용자를 대신하여 권한을 부여받아 사용자의 리소스에 접근하는 앱입니다. 
<br>사용자를 권한 부여 서버로 안내하거나, 사용자의 상호작용없이 권한 부여 서버로부터 직접 권한을 얻을 수 있습니다. 
<br><br>1: postman에 다음 요청을 입력합니다. <br>http://localhost:8080/realms/oauth2/protocol/openid-connect/auth?resource_type=code&amp;client_id=oauth2-client-app&amp;scope=profile email&amp;redirect_url=http://localhost:8081
Copy<br><img src="https://i.imgur.com/OBECnIl.png" referrerpolicy="no-referrer"><br>2: 로그인 페이지로 이동하여 로그인을 진행합니다. <br>3: 로그인을 완료하면 사용할 수 있는 토큰을 url을 통해 전달 받습니다.<br>4: 토큰을 이용해 권한(jwt토큰)을 최종 획득합니다. <br>http://localhost:8080/realms/oauth2/protocol/openid-connect/token?grant_type=authorization_code&amp;client_id&amp;client_secret&amp;redirect_url&amp;code
Copy<br><img src="https://i.imgur.com/osEFQHN.png" referrerpolicy="no-referrer"><br>5: 사용자 정보를 가져와 봅니다. <br><br><img src="https://i.imgur.com/ZdZSyPB.png" referrerpolicy="no-referrer"><br>인증 서버에 유저를 등록할 때 자격증명을 위해 클라이언트 id와 클라이언트 암호를 받습니다. 클라이언트 ID와 암호를 이용해 자격을 증명하는데, 클라이언트 암호는 비밀, 클라이언트 ID는 공개할 수 있습니다. <br><br>일반적으로 사용자가 소스 코드에 액세스할 수 없는 서버에서 실행되는 응용 서버입니다. (=백엔드 애플리케이션) 이러한 유형의 애플리케이션은 대부분 웹 서버에서 실행되기 때문에 일반적으로는 웹앱이라고 합니다.<br><br>크롬 개발자 도구, 디스어셈블러와 같은 디버깅 도구를 사용해 바이너리나 실행 코드에서 민감 정보를 추출할 수 있기 때문에 공개로 간주됩니다. 브라우저에서 실행되는 Java Script 애플리케이션, Android 또는 iOS 모바일 앱, 데스크톱에서 실행되는 기본 앱, IoT/임베디드 애플리케이션 등이 있습니다. <br><br><br>보호된 리소스에 접근하기 위해 사용하는 자격증명입니다. 일반적으로 JWT 형식을 취하지만, 반드시 그럴 필요는 없습니다. 토큰 내부에는 액세스 기간, 범위 및 서버에 필요한 기타 정보가 존재합니다. <br><br><img src="https://i.imgur.com/1Aqq2yL.png" referrerpolicy="no-referrer"><br>
<img src="https://i.imgur.com/rfe9MAQ.png" referrerpolicy="no-referrer"><br>인가 서버는 DB에 토큰의 내용을 저장하고, ID만 클라이언트에게 반환합니다.<br>
토큰을 수신하는 API는 토큰의 유효성을 검증하기 위해 DB를 조회해야합니다. <br><br><img src="https://i.imgur.com/Uw1erwR.png" referrerpolicy="no-referrer"><br>
<img src="https://i.imgur.com/On6ka9X.png" referrerpolicy="no-referrer"><br>JWT 토큰 형식으로 발급되며, 클레임과 만료가 있는 보호된 자료구조입니다. 리소스 서버의 검증 키만 알아도 발급자와 통신할 필요 없이 토큰의 유효성을 검증할 수 있습니다. 특정한 암호화 알고리즘에 의해 개인키로 서명되고 공개키로 검증할 수 있으며, 만료될 때까지 유효합니다. <br><br>액세스 토큰이 만료된 경우 Refresh Token의 유효성을 검사, 통과할 경우 새 AccessToken을 발급합니다. Refresh Token은 액세스 토큰과 달리 서버 토큰 엔드 포인트에만 보내지고 리소스 서버에는 보내지 않습니다. <br><br><br><img src="https://i.imgur.com/7vz9W8t.png" referrerpolicy="no-referrer"><br>권한 부여 코드 흐름에서 사용하며, 이 코드는 액세스 토큰과 교환되는 임시 코드입니다. ]]></description><link>spring/oauth-2.0/oauth-2.0이란.html</link><guid isPermaLink="false">Spring/OAuth 2.0/OAuth 2.0이란.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Mon, 01 Jul 2024 13:49:03 GMT</pubDate><enclosure url="https://i.imgur.com/ulSOeLn.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/ulSOeLn.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[No title]]></title><description><![CDATA[ 
 <br><br>만약 문제를 읽는데<br>
1: 배열이 등장하고,<br>
2: 연속된 부분수열로 무언가를 수행하고<br>
3: 연속된 부분 수열의 구간이 계속 바뀐다면<br>
세그먼트 트리 문제일 확률이 높습니다. <br>세그먼트 트리로만 풀 수 있는 문제는 없지만, 세그먼트 트리를 활용하면 쉽게 풀리는 문제가 존재합니다. <br><br>원소에 대한 갱신이 일어나는 경우 <br>세그먼트 트리에서 세그먼트가 의미하는 것 <br>많이 계산할 유형에 대해서 미리 계산함.<br>
절반씩 나눠서 조각으로 만들고 해당 조각 내 원소의 총합을 저장함.<br>
궁금한 구간의 쿼리가 들어올 경우 미리 만들어놓은 조각을 합쳐서 쿼리와 동일한 구간을 만든다. <br>조각이 많이 생기면 어떡하나요?<br>
생각보다 조각이 많이 생기지 않습니다. 조각의 개수는 최대 2~4배까지 생성됩니다. 마지막 층에는 길이 1짜리 조각이 데이터 개수 만큼 생성이 됩니다. 위로 올라갈 수록 조각의 수는 1/2배가 됩니다.<br>
n, n/2, n/4, ..., 1개처럼 1/2가 공비인 수열의 총합이기 때문에 대부분의 케이스에서 데이터가 개수를n으로 할 때, 4배에서 2배 정도 사이의 조각이 생성됩니다. <br>부모 노드의 대표값은 자식 노드의 대표값을 활용해서 계산할 수 있음<br>원소의 값이 바뀐다면?<br>
루트노드부터 시작하여 대표값을 변경합니다. 이후 루트에서 리프노드에 도달하는 경로를 찾는다. 리프노드에서 경로를 따라 루트노드까지 다시 이동하면서 각 노드의 대표값을 수정합니다. <br>특정 구간의 합을 구할 경우?<br>
// 세그먼트 트리 초기화
public static void init(int node, int nodeLeft, int nodeRight) {
	if (nodeLeft == nodeRight) {
		maxTree[node] = a[nodeLeft];
		minTree[node] = a[nodeLeft];
		return;
	}

	int mid = (nodeLeft + nodeRight) / 2;

	init(
			node * 2,
			nodeLeft,
			mid
	);

	init(
			node * 2 + 1,
			mid + 1,
			nodeRight
	);

	maxTree[node] = Math.max(maxTree[node * 2], maxTree[node * 2 + 1]);
	minTree[node] = Math.min(minTree[node * 2], minTree[node * 2 + 1]);
}
Copy<br>노드의 왼쪽구간과 오른쪽 구간이 같은 경우는 현재 노드가 리프 노드인 상황입니다. 최소 트리, 최대 트리, 총합트리 모두 구간이 1인 경우의 대표값은 자기 자신이므로 바로 값을 초기화하면됩니다. <br>if (nodeLeft == nodeRight) {
	maxTree[node] = a[nodeLeft];
	minTree[node] = a[nodeLeft];
	return;
}
Copy<br>구간을 분할할 때는 절반씩 나누어 분배합니다. <br>int mid = (nodeLeft + nodeRight) / 2;

init(
		node * 2,
		nodeLeft,
		mid
);

init(
		node * 2 + 1,
		mid + 1,
		nodeRight
);
Copy<br>왼쪽 자식과 오른쪽 자식의 대표값 계산이 끝났으므로, 현재 노드의 대표값을 계산해야합니다. <br>maxTree[node] = Math.max(maxTree[node * 2], maxTree[node * 2 + 1]);
minTree[node] = Math.min(minTree[node * 2], minTree[node * 2 + 1]);
Copy<br>특정 원소가 변경될 경우?<br>

public static void update(int node, int nodeLeft, int nodeRight, int queryIndex, int value) {
	if (queryIndex &lt; nodeLeft || nodeRight &lt; queryIndex) {
		return;
	}

	if (nodeLeft == nodeRight) {
		maxTree[node] = value;
		minTree[node] = value;
		return;
	}

	int mid = (nodeLeft + nodeRight) / 2;

	update(
			node * 2,
			nodeLeft,
			mid,
			queryIndex,
			value
	);

	update(
			node * 2 + 1,
			mid + 1,
			nodeRight,
			queryIndex,
			value
	);

	maxTree[node] = Math.max(maxTree[node * 2], maxTree[node * 2 + 1]);
	minTree[node] = Math.min(minTree[node * 2], minTree[node * 2 + 1]);
}

Copy<br>update 함수에 들어오는 인자는 5개입니다.<br>
queryIndex 위치의 값을 value 로 변경해야합니다.<br>
node는 현재 탐색중인 노드를 의미하며 nodeLeft와 nodeRight는 현재 노드가 담당하고 있는 구간이 됩니다. <br>내가 담당하고 있지 않는 구간의 업데이트일 경우 <br>if (queryIndex &lt; nodeLeft || nodeRight &lt; queryIndex) {
	return;
}
Copy<br>하위 노드에 대해서 먼저 업데이트 처리를 진행해봅니다. <br>
int mid = (nodeLeft + nodeRight) / 2;

update(
		node * 2,
		nodeLeft,
		mid,
		queryIndex,
		value
);

update(
		node * 2 + 1,
		mid + 1,
		nodeRight,
		queryIndex,
		value
);
Copy<br>자식 노드를 이용해서 현재 노드의 대표값을 업데이트합니다. <br>maxTree[node] = Math.max(maxTree[node * 2], maxTree[node * 2 + 1]);
minTree[node] = Math.min(minTree[node * 2], minTree[node * 2 + 1]);
Copy<br>특정 구간에서 변경이 일어날 경우 <br>public static int queryMax(int node, int nodeLeft, int nodeRight, int queryLeft, int queryRight) {
	if (queryRight &lt; nodeLeft || nodeRight &lt; queryLeft) {
		return 0;
	}

	if (queryLeft &lt;= nodeLeft &amp;&amp; nodeRight &lt;= queryRight) {
		return maxTree[node];
	}

	int mid = (nodeLeft + nodeRight) / 2;
	int leftMax = queryMax(
			node * 2,
			nodeLeft,
			mid,
			queryLeft,
			queryRight
	);
	int rightMax = queryMax(
			node * 2 + 1,
			mid + 1,
			nodeRight,
			queryLeft,
			queryRight
	);

	return Math.max(leftMax, rightMax);
}

Copy<br>case1. 완전히 안겹치는 경우 = 업데이트할 필요 없는 경우<br>
쿼리의 최대범위 &lt; 현대 노드의 최소 범위<br>
현재 노드의 최대 범위 &lt;쿼리의 최소 범위 <br>if (queryRight &lt; nodeLeft || nodeRight &lt; queryLeft) {
	return 0;
}
Copy<br>이 때 아무값이나 반환하면 안되고, 내가 구하고자하는 연산의 항등원 반환해야합니다.<br>
더하거나 뺄 경우에는 0<br>
최대값을 계산할 경우에는 -무한대나 문제 범위의 최소값 <br>case2. 궁금한 구간이 현재 노드에서 전부 커버하는 경우 <br>if (queryLeft &lt;= nodeLeft &amp;&amp; nodeRight &lt;= queryRight) {
	return maxTree[node];
}
Copy<br>case3. 그 외 경우 <br>int mid = (nodeLeft + nodeRight) / 2;
int leftMax = queryMax(
		node * 2,
		nodeLeft,
		mid,
		queryLeft,
		queryRight
);
int rightMax = queryMax(
		node * 2 + 1,
		mid + 1,
		nodeRight,
		queryLeft,
		queryRight
);

return Math.max(leftMax, rightMax);
Copy<br>하위 노드를 찾아보면서 진행합니다. <br>비재귀 형식 vs 재귀형식<br>
비재귀 형식 구현 (바텀업)은 특정 원소를 바꾸는 연산을 구현할 수 있지만, 특정 구간의 원소 전체를 변경하는 연산은 구현할 수 없습니다. ]]></description><link>알고리즘과-자료구조/세그먼트-트리.html</link><guid isPermaLink="false">알고리즘과 자료구조/세그먼트 트리.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sat, 29 Jun 2024 07:43:06 GMT</pubDate></item><item><title><![CDATA[마이크로서비스]]></title><description><![CDATA[ 
 <br><br><br><img src="https://i.imgur.com/bL3ygE3.png" referrerpolicy="no-referrer"><br>클라이언트, 서버, DB로 구성된 전통적인 3-tier구조에서 서버가 단일 프로세스에서 실행되는 경우를 의미합니다. 애플리케이션이 한 덩어리로 구성되어있어 단일 프로세스를 실행합니다. 시스템을 일부만 수정한다 하더라도, 시스템 전체가 배포되어야합니다. 또한 하나의 기능에서 장애가 발생하면 모든 기능을 사용할 수 없습니다. <br><img src="https://i.imgur.com/tC9GW65.png" referrerpolicy="no-referrer"><br>또한 스케일 아웃시, 시스템 전체를 스케일 아웃시켜야합니다. a와 b 기능이 있을 때, a 기능만 담당하는 프로세스만 스케일 아웃이 불가능합니다. 현대 클라우드 개념은 온디맨드 즉, 쓴 만큼 돈을 지불합니다. 전체 시스템을 스케일 아웃하는 것은 비용상 문제가 발생합니다. <br><br><img src="https://i.imgur.com/2oudfi0.png" referrerpolicy="no-referrer"><br>마이크로 서비스는 애플리케이션의 각 기능을 잘라, 여러 개의 서비스 조각으로 구성합니다. 서비스는 각기 독립적인 기능을 제공하며 각 서비스의 저장소는 다른 서비스와 완벽하게 격리됩니다. 따라서 독립적으로 수정 가능하며, 별도 배포와 확장이 가능합니다. 또한 하나의 기능에서 장애가 발생하더라도 다른 서비스에 장애가 발생하지 않습니다. 또한 스케일 아웃시, 특정 트래픽이 몰리는 서비스에만 적용이 가능합니다. <br><img src="https://i.imgur.com/Jz1TVLh.png" referrerpolicy="no-referrer"><br>DB는 각 서비스마다 격리되어 있으며, 타 서비스가 다른 서비스의 DB에 직접 접근하는 것은 허용되지 않습니다. 해당 DB의 자원이 필요한 경우, 반드시 해당 서비스의 API를 이용하여 접근해야합니다. 객체지향에서 배웠던대로 DB는 캡슐화되어있으며 API는 인터페이스라고 이해하면 편합니다. <br>]]></description><link>msa/ddd/마이크로-서비스.html</link><guid isPermaLink="false">MSA/DDD/마이크로 서비스.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 23 Jun 2024 13:06:26 GMT</pubDate><enclosure url="https://i.imgur.com/bL3ygE3.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/bL3ygE3.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[<font color="#8064a2">Profile.</font>]]></title><description><![CDATA[ 
 <br><br><br><br>
안녕하세요. 백엔드 개발자 김한주입니다.<br>
제 강점은 단순 기능 구현을 넘어 안정적인 상황을 목표로 개발하는 습관입니다.<br>
또한, 다양한 기술 스택을 효율적으로 결합하여 안정적인 시스템을 만들어 나갑니다.<br>
이를 위해 새로운 기술이나 도구를 습득하고 프로젝트에 적용하는 것에 있어서도 익숙합니다.
<br><br><br><br><br><br><br>1.<a data-href="Index 잘 쓰는 방법" href="db/rdb/index-잘-쓰는-방법.html" class="internal-link" target="_self" rel="noopener">Index 잘 쓰는 방법</a><br>
RDBMS에서 Index를 사용할 때 주의점과 팁을 알아봅니다.
<br>2.<a data-href="Hash 함부로 쓰면 메모리 터진다" href="알고리즘과-자료구조/hash-함부로-쓰면-메모리-터진다.html" class="internal-link" target="_self" rel="noopener">Hash 함부로 쓰면 메모리 터진다</a><br>
코테에서 Java의 HashSet을 사용시 메모리가 터질 수 있는 이유와 간단한 계산법을 알아봅니다.
<br>3.<a data-href="Dynamo DB - 채팅 내역 저장을 위한 키 설계" href="prj/cloudy/dynamo-db-채팅-내역-저장을-위한-키-설계.html" class="internal-link" target="_self" rel="noopener">Dynamo DB - 채팅 내역 저장을 위한 키 설계</a>, <a data-href="RDB와 NoSQL의 차이" href="prj/cloudy/rdb와-nosql의-차이.html" class="internal-link" target="_self" rel="noopener">RDB와 NoSQL의 차이</a><br>
Cloudy에서 채팅 내역 저장시 Dynamo DB를 활용한 방향을 소개합니다. 
<br>4.<a data-href="Flux를 활용한 SSE 구현기" href="prj/cloudy/flux를-활용한-sse-구현기.html" class="internal-link" target="_self" rel="noopener">Flux를 활용한 SSE 구현기</a><br>
Cloudy에서 챗봇 사용자 경험을 위해 Flux를 활용해 SSE를 적용한 개선기를 소개합니다.
<br>5.<a data-href="콘팅이 서비스를 잘게 쪼갠 이유" href="prj/conting/콘팅이-서비스를-잘게-쪼갠-이유.html" class="internal-link" target="_self" rel="noopener">콘팅이 서비스를 잘게 쪼갠 이유</a><br>
콘팅의 서비스가 잘게 쪼갠 근거와 그 방향성을 소개합니다. 
<br><br><br>
<br>KIST (Korea Institute of Science and Technology / AI &amp; Robot Lab) Intern (2022.09.03 ~ 2023.02.19)
<br>SSAFY (Samsung Software Academy Foy Youth) 10th Trainnee<br>
(2023.07~2024.07)
<br><br><br>
<br>동계 한국방송미디어공학회 대학생 논문/캡스톤디자인 경진대회 최우수상 (2022.11.19)
<br>교내 캡스톤디자인 경진대회 우수상 (2023.01.16)
<br>신한은행 해커톤 본선진출 (2023..12)
<br>삼성 청년 SW 아카데미 1학기 관통 프로젝트 최우수상 (2023.11.24)
<br>삼성 청년 SW 아카데미 2학기 공통 프로젝트 우수상 (2024.2.29)
<br>삼성 청년 SW 아카데미 2학기 특화 프로젝트 최우수상 (2024.4.04)
<br>삼성 청년 SW 아카데미 2학기 기업연계 프로젝트 최우수상 (2024.6.06)
<br>삼성 청년 SW 아카데미 삼성전자 이사 우수상 (2024.6.26)
<br><br><br>
<br>한국데이터진흥원 SQL Developer 취득 (2022.12.09)
<br>제7차 현대 Softeer 정기 역량 진단(HSAT) Level3 취득(2023.08.11)
<br><br><br><img src="https://i.imgur.com/1c4Jlsl.png" referrerpolicy="no-referrer"><br><br><br><img src="https://i.imgur.com/cehUtrI.png" referrerpolicy="no-referrer"><br>]]></description><link>hanju's-study-note.html</link><guid isPermaLink="false">Hanju's Study Note.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 30 Jun 2024 15:24:49 GMT</pubDate><enclosure url="https://i.imgur.com/1c4Jlsl.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/1c4Jlsl.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[B-Tree 인덱스에서 데이터를 읽는 방법]]></title><description><![CDATA[ 
 <br><br><br><br>B-Tree는 최상위의 하나의 루트 노드가 존재하고 그 하위에 자식 노드가 붙어 있습니다. 트리 구조 가장 하위에 있는 노드를 리프 노드, 중간에 있는 노드를 브랜치 노드라합니다.<br>
<img src="https://i.imgur.com/0NUG6Dq.png" referrerpolicy="no-referrer"><br>DB에서 인덱스와 실제 데이터는 따로 관리됩니다. 인덱스는 테이블의 키 칼럼만 가지고 있으므로 나머지 칼럼을 읽으려면 데이터 파일에서 해당 레코드를 찾아야합니다. 때문에 인덱스의 리프노드는 실제 데이터 레코드를 찾아가기 위한 주솟값을 가지고 있습니다. <br><br>
인덱스의 접근방법 가운데 가장 대표적이고 빠른 접근 방법입니다. 
<br>검색해야할 인덱스의 범위가 결정되었을 때 사용합니다. <br>다음 쿼리로 예를 들어보겠습니다. <br>SELECT * FROM employees WHERE first_name BETWEEN 'Ebbe' AND 'Gad';
Copy<br><img src="https://i.imgur.com/QWTZI3g.png" referrerpolicy="no-referrer"><br>검색하려는 값의 수나 검색 결과 레코드 수의 상관 없이 레인지 스캔이라고 표현합니다. 그림에서 알 수 있듯이, 루트 노드에서부터 비교를 시작해 브랜치 노드를 거치고 리프노드까지 들어가야만 레코드의 시작 지점을 찾을 수 있습니다. 일단 시작 위치만 찾아놓으면 리프 노드의 레코드만 순서대로 읽으면 됩니다. 스캔하다가 리프 노드 끝까지 읽으면 리프 노드 간의 링크를 이용해 다음 리프 노드를 찾아 다시 스캔합니다. 이후 스캔을 멈춰야할 위치에 다다르면 지금까지 읽은 레코드를 사용자에게 반환합니다. <br>실제 데이터 파일의 레코드를 읽어와야하는 경우<br>
<img src="https://i.imgur.com/HYnSD6u.png" referrerpolicy="no-referrer"><br>리프 노드에 저장된 레코드 주소로 데이터 파일의 레코드를 읽어옵니다. 이 때 건당 랜덤 I/O가 일어납니다. 그림에서 처럼 3건의 레코드가 검색 조건에 일치했다고 가정하면, 데이터 레코드를 읽기 위해 랜덤 I/O가 최대 3번 필요합니다. 그래서 인덱스를 통해 데이터 레코드를 읽는 작업은 비용이 많이 듭니다. 때문에 인덱스를 통해서 선택되는 레코드가 전체의 20~25%를 넘으면 인덱스를 통해서 읽는 것 보다는 테이블의 데이터를 직접 읽는 것이 낫습니다. <br>커버링 인덱스<br>
위와 같이 레코드의 랜덤 I/O를 방지하려면 주요 사용 데이터 자체를 인덱스화할 수 있습니다. 때문에 리프노드에서 가지고 있는 정보만으로 쿼리의 결과를 반환할 수 있습니다. <br>인덱스 레인지 스캔 정리<br>
1: 인덱스에서 조건을 만족하는 값이 저장된 위치를 찾는다. (이 과정을 인덱스 탐색이라고 한다. )<br>
2: 1번에서 찾은 시작위치부터 필요한 만큼 인덱스를 차례로 읽는다. (이 과정을 인덱스 스캔이라고 한다.)<br>
3: 읽어들인 인덱스 키와 레코드 주소를 이용해 레코드가 저장된 페이지를 랜덤 액세스하고 최종 레코드를 읽어온다. <br>과정마다 실행횟수 보기 <br>SHOW STATUS LIKE 'Handler_%';
Copy<br>]]></description><link>db/rdb/b-tree-인덱스에서-데이터를-읽는-방법.html</link><guid isPermaLink="false">DB/RDB/B-Tree 인덱스에서 데이터를 읽는 방법.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sat, 15 Jun 2024 08:19:48 GMT</pubDate><enclosure url="https://i.imgur.com/0NUG6Dq.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/0NUG6Dq.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Select 튜닝]]></title><description><![CDATA[ 
 <br><br><br>Insert나 Update 작업은 대부분의 경우 레코드 단위로 발생하기 때문에 성능상 문제가 되는 경우는 별로 없습니다. 하지만 Select는 주어진 조건에 따라 여러개의 테이블에서 데이터를 조합해서 가져와야합니다. 즉, 여러개의 테이블을 어떻게 읽을 것인가에 대한 주의가 필요합니다. <br><br>기본순서<br>
<img src="https://i.imgur.com/d6oJaQm.png" referrerpolicy="no-referrer"><br><img src="https://i.imgur.com/DUqMraP.png" referrerpolicy="no-referrer"><br>각 쿼리절의 실행순서를 도식화한 그림입니다. CTE(with 절)와 윈도우 함수를 제외하고, 순서가 바뀌어서 실행되는 형태의 쿼리는 거의 없습니다. 또한 ORDER BY나 GROUP BY가 있어도 인덱스를 이용해 처리할 때는 생략되어 실행됩니다. <br>예제 쿼리로 확인해보겠습니다. <br>SELECT s.emp_no, COUNT(DISTINCT e.first_name) AS cnt 
FROM salaries s 
INNER JOIN employees e ON e.emp_no=s.emp_no
WHERE s.emp_no IN (100001, 100002)
GROUP BY s.emp_no 
HAVING AVG(s.salary) &gt; 1000
ORDER BY AVG(s.salary)
LIMIT 10; 

Copy<br>예제 쿼리를 각 절로 나눠봅시다. <br><br>각 절의 실행 계획을 풀어서 보면 다음과 같습니다. <br><br>조인보다 먼저 ORDER BY가 실행되는 경우<br>
<img src="https://i.imgur.com/ZdWQaTg.png" referrerpolicy="no-referrer"><br>예외적으로 ORDER BY가 조인보다 먼저 실행되는 경우입니다. 첫번째 테이블만 읽어서 정렬을 수행한 뒤, 나머지 테이블을 읽습니다. 주로 GROUP BY 절 없이 ORDER BY만 사용된 쿼리에서 사용되는 순서입니다. <br>순서를 다르게 실행하고 싶다면? 인라인 뷰!<br>SELECT emp_no, cnt
FROM (
    SELECT s.emp_no, COUNT(DISTINCT e.first_name) AS cnt, MAX(s.salary) AS max_salary
    FROM salaries s
    INNER JOIN employees e ON e.emp_no = s.emp_no
    WHERE s.emp_no IN (100001, 100002)
    GROUP BY s.emp_no
    HAVING MAX(s.salary) &gt; 1000
    LIMIT 10
) temp_view
ORDER BY max_salary;
Copy<br>위의 실행순서를 벗어나는 쿼리가 필요할 경우 서브 쿼리로 작성된 인라인 뷰를 사용해야합니다. 예시로 LIMIT를 먼저 적용하고 ORDER BY를 실행하고 싶다면 위와 같이 인라인 뷰를 적용해야합니다. <br>하지만 인라인뷰를 사용하면 임시 테이블을 쓰기 때문에 주의해야합니다. <br>CTE가 포함될 경우<br>
WITH 절(CTE, Common Table Expression)은 항상 제일 먼저 실행되어 임시 테이블로 저장됩니다.<br><br><br>
WHERE, GROUP BY, ORDER BY 절에서 어떤 요건을 갖췄을 때 인덱스를 사용할 수 있는지 자세히 알아보겠습니다. 
<br><br><br>인덱스 칼럼의 값을 변형하지 말아야합니다.<br>
인덱스는 칼럼의 값을 아무런 변환 없이 B-Tree에 정렬해서 저장합니다. WHERE, GROUP BY, ORDER BY 모두 원본값을 검색하거나 정렬할 때만 B-Tree에 저장된 인덱스를 이용합니다. 다음 예제와 같이 인덱스로 지정된 칼럼의 값을 변형한 후 다른 값과 비교하면 쿼리는 인덱스를 사용할 수 없습니다. <br>SELECT * FROM salaries WHERE salary*10 &gt; 10000; 
Copy<br>때문에 다음과 같이 변형하여 사용해야합니다. <br>SELECT * FROM salaries WHERE salary &gt; 10000/10; 
Copy<br>복잡한 연산을 수행한다거나, 해시 값을 만들어서 비교해야하는 경우<br>
2가지 해결방법이 존재합니다.<br>
1: 미리 계산된 값을 저장하도록 MYSQL의 가상 칼럼을 추가하고 그 칼럼에 인덱스를 생성하는 방법<br>
2: 함수 기반의 인덱스 사용하기 <br>비교 대상값은 같은 타입이어야합니다.<br>CREATE TABLE tb_test (age VARCHAR(10), INDEX ix_age (age)); 
INSERT INTO tb_test VALUES ('1'), ('2'), ('3'), ('4'), ('5'), ('6'), ('7'); 

SELECT * FROM tb_test WHERE age=2;
Copy<br>select 쿼리의 실행계획을 확인해봅시다. <br><br>age라는 칼럼에 인덱스가 있어서 type칼럼에 ref나 range가 표시되어야하지만, 실제로는 Index(인덱스 풀 스캔)라고 표시합니다.<br>인덱스 레인지 스캔을 사용하지 못하고 인덱스를 풀 스캔한 이유는 age칼럼의 데이터 타입과  비교되는 값의 데이터 타입이 다르기 때문입니다. 비교되는 값의 타입이 서로 다를 경우 옵티마이저가 내부적으로 문자열을 숫자 타입으로 변환한 후 비교 작업을 처리합니다. <br>실제 인덱스에 저장된 값은 문자열이고 이를 정수로 변환하는 과정에서 인덱스를 사용하지 못하게 됩니다. 이 현상을 예방하기 위해서는 쿼리를 다음과 같이 변경하여 해결할 수 있습니다. <br>SELECT * FROM tb_test WHERE age='2';
Copy<br>저장하고자 하는 값의 타입에 맞춰 칼럼의 타입을 선정해야합니다. <br><br>
크게 작업 범위 결정 조건과 체크 조건의 두 가지 방식으로 구분합니다. 
<br><br>작업 범위 결정 조건은 WHERE 절에서 동등 비교 조건이나 IN으로 안의 조건에 사용된 칼럼들이 실제 인덱스 칼럼 구성과 비교할 때 얼마나 일치하는지에 따라 달라집니다.<br>
<img src="https://i.imgur.com/OMWDUxX.png" referrerpolicy="no-referrer"><br>
위 그림과 같이 WHERE 절에 나열된 순서가 인덱스와 다르더라도 옵티마이저는 인덱스를 사용할 수 있는 조건들을 뽑아서 최적화를 수행할 수 있습니다. 점선 표기가 체크 조건, 실선 표기가 작업 범위 결정 조건입니다.<br>
col_1과 col_2는 동등 비교 조건이며, col_3의 조건이 범위 비교 조건이기 때문에 col_4는 작업 범위 결정 조건으로 사용되지 못하고, 체크 조건으로 사용됩니다. <br>인덱스 순서상, col_4이 직전 칼럼인 col_3가 동등 비교 조건이 아니라, 범위 비교 조건으로 사용되기 때문입니다. ]]></description><link>db/rdb/select-튜닝.html</link><guid isPermaLink="false">DB/RDB/Select 튜닝.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sat, 15 Jun 2024 06:39:01 GMT</pubDate><enclosure url="https://i.imgur.com/d6oJaQm.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/d6oJaQm.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Java 코드]]></title><description><![CDATA[ 
 <br><br><br>private int binarySearch(int[] arr, int target){

	//이진 탐색을 이용해 정렬된 배열 arr안에서 target 인덱스 반환 
	//target이 없다면 -1을 반환 

}

Copy<br>
<br>이진 탐색을 이용해 정렬된 배열 arr 안에서 target 인덱스 반환
<br>target이 없다면 -1을 반환
<br><br>arr배열 안에 있는 인덱스를 찾는 과정이므로, arr의 범위인 [0,arr.length)가 탐색 범위입니다. 찾는 범위는 다음과 같이 각각의 변수로 선언합니다. <br>int start = 0;
int end = arr.length; 

Copy<br><br>end-start가 양수일 때까지 탐색을 계속 반복해야 합니다. <br>while(end&gt;start){


}

Copy<br><br>범위의 중간 인덱스와 그 값을 구합니다. <br>
int mid = (start+end)/2;
int value = arr[mid];

Copy<br>찾아낸 중간값으로 target과의 대소 판단 후 범위를 조정합니다. <br>if(value==target){

	return mid;

}else if(value&gt; target){
	//다운 
	//정답은 더 작은 범위에 있다.
	//[start, mid) 
	end = mid;
}else{
	//업
	//정답은 더 큰 범위에 있다. 
	// [mid+1, end)
	start = mid+1; 
}

Copy<br><br>
private static int binarySearch(int[] arr, int target){

	int start = 0;
	int end = arr.length; 

	while(end&gt;start){
		int mid = (start+end)/2;
		int value = arr[mid];
		if(value==mid){
			return mid; 
		}else if(value&gt;target){
			end = mid;
		
		}else{
			start = mid+1; 
		}
	}
}

Copy<br><br><br>정렬기준이 중요한 이유<br>
이진 탐색 문제 대부분은 큰 범위의 정답 후보 중 문제 조건에 맞는 정답을 찾아내는 케이스입니다. 문제에서 요구하는 조건의 검색 결과가 정답 후보의 값에 따라 정렬된 상태인지 확인해야합니다. <br><br>이진 탐색은 정확한 값 뿐만 아니라 정답 조건을 만족하는 값 중 가장 큰 값 혹은 가장 작은 값을 찾는데도 많이 사용됩니다. 파라메트릭 서치를 구현하기 위해서는 다음 2가지를 고려해야합니다.<br>1. 범위 좁히기
2. 범위 표기법 
Copy<br><br>정답 조건을 만족하는 값 중 가장 큰 값을 구하는 경우<br>
중간값을 검사 했을 때 정답을 만족하더라도 더 큰값이 있는지 찾아야합니다. 범위를 큰 쪽으로 좁히되, 검사한 중간 값을 포함해서 좁혀야합니다. <br>정답 조건을 만족하는 값 중 가장 작은 값을 구하는 경우<br>
중간값을 검사했을 때 정답을 만족하더라도 더 작은 값이 있는지 찾아야합니다. 범위를 작은 쪽으로 좁히되, 검사한 중간값을 포함해서 좁혀야합니다. 이 경우 범위에 2개의 값이 남아있을 때 중간값은 start를 선택합니다. start가 정답 조건을 만족한다면 중간값을 포함한 [start, start] 를 선택하게 됩니다.<br>
반대로 start가 정답 조건을 만족하지 않는다면 큰 값이 들어 있는 범위인 [start+1, end]<br>하나의 값만 남았다고 해서 무조건 정답이 아니다.<br>
원소가 하나 남았다면 이 값이 정답을 만족하는지 여부를 한 번 더 검사해야합니다. <br><br><br>자바에서는 배열과 리스트에 적용할 수 있는 두 가지 메서드를 제공합니다. 주의해야할 점은 탐색 대상은 항상 정렬되어 있는 상태이어야합니다. <br><br>앞의 두 메서드는 배열이나 리스트에서 검색하려는 원소가 있다면 해당 원소의 인덱스를 반환합니다. 만약 찾고자 하는 값이 없다면 음수를 반환합니다. <br>원소가 들어갈 위치 찾기<br>
찾고자 하는 값이 없을 경우 음수 값을 반환합니다. 이 값을 양수로 변환하고 1을 빼면 해당 원소가 들어갈 위치가 됩니다. <br><br><br>
import java.util.Arrays;
import java.util.Collections;

public class LDSBinarySearch {
    public static void main(String[] args) {
        int[] nums = {10, 9, 2, 5, 3, 7, 101, 18};
        System.out.println("Length of LDS: " + lengthOfLDS(nums));
    }

    public static int lengthOfLDS(int[] nums) {
        if (nums == null || nums.length == 0) {
            return 0;
        }

        // dp 배열 초기화
        Integer[] dp = new Integer[nums.length];
        int length = 0;

        for (int num : nums) {
            // 이분 탐색을 통해 현재 num이 들어갈 위치를 찾음
            int i = Arrays.binarySearch(dp, 0, length, num, Collections.reverseOrder());
            if (i &lt; 0) {
                i = -(i + 1);
            }
            dp[i] = num;
            if (i == length) {
                length++;
            }
        }

        return length;
    }
}


Copy<br><br>import java.util.Arrays;

public class LISBinarySearch {
    public static void main(String[] args) {
        int[] nums = {10, 9, 2, 5, 3, 7, 101, 18};
        System.out.println("Length of LIS: " + lengthOfLIS(nums));
    }

    public static int lengthOfLIS(int[] nums) {
        if (nums == null || nums.length == 0) {
            return 0;
        }

        int[] dp = new int[nums.length];
        int length = 0;

        for (int num : nums) {
            int i = Arrays.binarySearch(dp, 0, length, num);
            if (i &lt; 0) {
                i = -(i + 1);
            }
            dp[i] = num;
            if (i == length) {
                length++;
            }
        }

        return length;
    }
}


Copy]]></description><link>알고리즘과-자료구조/알고리즘/이진탐색/이진탐색.html</link><guid isPermaLink="false">알고리즘과 자료구조/알고리즘/이진탐색/이진탐색.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Tue, 11 Jun 2024 05:31:48 GMT</pubDate></item><item><title><![CDATA[Redist Cluster]]></title><description><![CDATA[ 
 <br><br><br>레디스 클러스터는 페일오버와 샤딩을 통해 높은 가용성을 보장하며,  쓰기 및 읽기 작업의 확장성을 높일 수 있습니다. <br>페일 오버<br>
레디스 클러스터는 여러 레디스 노드를 연결하여 일부 노드에서 장애가 발생해도 운영할 수 있습니다. <br>샤딩<br>
레디스 서버가 실행 중일 때 노드 사이에 키를 옮길 수 있습니다. <br><br><br><img src="https://i.imgur.com/2ELVfy9.png" referrerpolicy="no-referrer"><br>데이터를 저장할 해시 슬롯을 선택하기 위해서 키 값의 해시 결과를 사용합니다. 레디스 클러스터에는 16,384개의 해시 슬롯이 있습니다. 이 슬롯은 각 샤드에 할당됩니다. <br>저장되는 키는 CRC16 해시 함수를 사용하여 해시값을 계산합니다. 그 값을 16384로 나눈 나머지를 구한다음 해당 값의 슬롯을 가진 샤드가 요청을 처리합니다. <br>샤드의 데이터 분산은 키를 해싱한 결과를 슬롯에 할당하고, 슬롯을 다시 각 샤드에 할당하는 방식으로 진행합니다. 이 과정은 슬롯의 개수를 기준으로 하며, 데이터 크기를 고려하지 않습니다. 따라서 특정 샤드에 데이터가 집중되는 경우, 슬롯 할당에 편향이 생기거나 특정 슬롯에 속하는 데이터의 크기가 커질 수 있습니다. <br><br>{user:1000}:name
{user:1000}:email
Copy<br>데이터를 저장할 때 해시 태그 기능을 사용해, 키가 달라도 같은 슬롯에 접근할 수 있습니다. 해시 태그를 사용하기 위해서는 키 내의 공통 문자열을 {}로 감싸야합니다. 단, 해시태그를 남용하면 특정 샤드에 편향이 발생할 수 있으므로 주의해서 사용해야합니다. <br>해시 태그 인식 조건 <br>1. 키에 {를 포함해야합니다. 
2. {의 오른쪽에 }를 포함해야합니다. 
3. {} 사이에 하나 이상의 문자가 포함되어야 합니다.
4. 대상이 여러개 있을 경우 가장 먼저 조건을 만족하는 것이 대상이 됩니다. 
	-&gt; {{foo}}}bar가 있으면 {foo가 해시 대상이 됩니다. 
Copy<br><br>클러스터 버스<br>
레디스 클러스터 내 각 노드는 클러스터 버스라고 하는 TCP 버스를 통해 이진 프로토콜과 완전 메시 구조로 서로 연결되어 있습니다. <br><img src="https://i.imgur.com/t17VsDP.png" referrerpolicy="no-referrer"><br><br>클러스터 버스 포트<br>
레디스 클러스터 내에서 노드간 통신에 사용하는 포트입니다. 각 노드는 클러스터 버스를 통해 다른 모든 노드와 연결됩니다. 통신에는 이진 프로토콜이 사용되며, 노드는 완전 메시 구조로 구성됩니다.<br>주로 구성 정보, 상태 정보 교환이 이루어집니다. 페일 오버 인증, 설정 업데이트 증에 사용되는 하트비트 패킷 교환도 이뤄집니다. <br>노드가 클러스터의 일부로 인식되는 과정 <br>가십 프로토콜<br>
노드의 상태를 서로 파악하기 위해 사용하는 프로토콜입니다. 클러스터의 노드가 증가해도 노드 간 메시지 수가 지수적으로 증가하지 않도록 고안되었습니다. 내부적으로는 클러스터 내의 노드 간에 설정 정보를 서로 공유하고 인지하기 위해 Raft라는 분산 합의 알고리즘을 기반으로 시스템이 구현되어 있습니다. <br>완전 메시라고 모든 노드 쌍에 핑을 주고 받지 않습니다.<br>
완전 메시 방식으로 통신하지 않습니다. 그 이유는 노드 수가 늘어날 수록 보내야하는 핑의 양이 기하급수적으로 증가해 성능이나 대역폭에 영향을 미칩니다. <br>각 노드는 다른 노드를 무작위로 선택하여 핑을 보내고 응답을 받습니다. 이 과정에서 각 노드가 보내는 전체 핑 패킷의 총량은 일정하도록 유지합니다. 만약 cluster-node-timeout 설정 시간의 절반을 초과하는 동안 다음 조건 중 하나라도 만족하는 노드가 있을 경우 모든 노드에 핑을 보냅니다. <br>1. ping이 전송되지 않은 노드 
2. ping의 응답을 받지 못한 노드 
Copy<br>슬롯 배치<br>
노드 사이의 슬롯 배치는 아래 두 종류의 메시지로 관리됩니다. 메시지를 통해 슬롯 구성이 업데이트 됩니다. <br><br><br>레플리케이션의 한계를 샤딩으로 극복<br>
마스터의 레플리카 수를 늘려 읽기 작업의 확장성을 늘릴 수 있지만, 쓰기 작업은 마스터에서만 수행되기 때문에 레플리케이션에서 확장성을 높이기 어려웠습니다. 이를 해결하기 위해 레디스 클러스터는 샤딩을 제공합니다. <br>각 샤드는 한 개의 마스터와 0개 이상의 레플리카로 구성됩니다. DB 내의 데이터 슬롯에 할당한 후 샤드들이 담당할 슬롯을 결정해 어느 샤드에 데이터를 저장할지 결정합니다. <br>데이터를 갖고 있지 않은 노드에 요청이 들어올 경우 오버헤드가 없습니다<br>
레디스 클러스터는 클라이언트에게 데이터를 가진 마스터 노드의 정보를 제공하고, 해당 노드로 요청을 리다이렉트합니다. 이후 클라이언트는 리다이렉트된 노드 정보를 저장하고 있기 때문에 리다이렉트에 의한 오버헤드가 없습니다. 또한 클러스터 내 각 노드로 요청을 분배하는 과정에서 프록시를 사용하지 않으므로, 프록시로 인한 오버헤드가 없습니다. <br><br><img src="https://i.imgur.com/5p8cB4A.png" referrerpolicy="no-referrer"><br>
<a data-tooltip-position="top" aria-label="레디스 클러스터의 요청 흐름.canvas" data-href="레디스 클러스터의 요청 흐름.canvas" href="db/cache/레디스-클러스터의-요청-흐름.html" class="internal-link" target="_self" rel="noopener">레디스 클러스터의 요청 흐름</a><br><br>마스터 노드에 편향이 발생하는 경우<br>
: READONLY 명령어를 사용하여 읽기쿼리를 전부 레플리카로 분산시키는지 여부 <br>마스터 노드 여부와 상관없이 발생하는 경우<br>
: DNS 리졸버에 의존하는 노드 IP 주소 선택 방식 검토<br>
: DNS 캐시<br>
: 슬롯 배치 편향 및 특정 슬롯에 저장되는 아이템 크기의 편향<br>
: 해시 태그 사용여부 <br><br>
레디스 클러스터는 문제가 발생한 마스터가 속한 샤드 내의 레플리카를 마스터로 승격시키도록 동작합니다. 이 동작의 수행 시점에 따라 매커니즘을 분류합니다. 
<br><br>캐시노드 상태<br>
레디스 클러스터의 캐시 노드 상태는 총 2가지 입니다. <br><br>가십 프로토콜<br>
레디스 클러스터는 가십 프로토콜을 사용해 주기적으로 핑을 보냅니다. 가십 부분에 다른 노드의 상태 정보를 담고 있는 내용을 포함합니다. 클러스터 내의 노드들은 신뢰할 수 있는 노드에서 다른 노드의 상태 정보를 공유하는 형태로 노드 간 상태를 파악합니다. <br><br>과반수 이상의 마스터가 뻗으면 소용없습니다.<br>
레디스 클러스터의 페일오버는 마스터 노드의 과반수가 정상 동작하는 것을 전제로 합니다. 때문에 클러스터 내 대부분의 노드가 사용 불가능한 상태라면 복구되지 않습니다. 단, 관리형 서비스(AWS 등)을 사용하는 경우에는 복구가 가능할 수도 있습니다. <br>데이터가 손실될 위험이 있습니다.<br>
case1.<br>
한 샤드가 마스터와 레플리카로 구성되어 있고, 장애가 발생한 동안 샤드 내에서 마스터가 두 개로 나뉜 상황을 가정합니다. 장애 복구 과정에서 각 마스터에 저장된 데이터를 병합할 때는 last failover wins 방식을 사용해 마스터를 포함하는 레플리카가 새로운 마스터로 승격됩니다. 이 때 승격되지 않은 다른 마스터의 기록은 손실 됩니다.<br>예를 들어, 원래 하나의 마스터(A)와 하나의 레플리카(B)가 있는 샤드가 있다고 가정해 봅시다. 네트워크 분할로 인해 A와 B가 서로를 볼 수 없게 됩니다. 네트워크가 복구되었을 때 B가 새로운 마스터로 선택되었다면 A에 있던 데이터는 그대로 남아있더라도 클러스터에서 무시됩니다.<br>즉, 장애가 발생하는 동안 A와 B가 독립적으로 업데이트 되었을 가능성이 있기 때문에 일관성을 유지하기 위해 승격된 마스터의 데이터만 보존합니다. <br>case 2.<br>
샤드 내 마스터와 레플리카 간의 레플리케이션은 비동기적으로 이루어집니다. 따라서 마스터에 데이터를 저장한 후 클라이언트에 응답을 반환하여 레플리카에 데이터가 기록되는 일련의 과정 중 마스터에 장애가 발생하면, 레플리카에 기록되지 않은 데이터는 손실될 수 있습니다. <br><br>마스터에 장애가 발생했을 때 레플리카는 자동적으로 새로운 마스터로 페일오버를 실행합니다. <br>선출 프로세스 시작 조건<br>
1 - 레플리카 마스터가 FAIL 상태여야합니다.<br>
2 - 마스터가 하나 이상인 슬롯을 관리합니다.<br>
3 - 레플리카가 일정 시간 이상 마스터와 연결이 끊긴 상태여야합니다. <br>선출 프로세스<br>
1 - 마스터가 FAIL 상태임을 감지한 레플리카는 일정시간 동안(DEALY) 대기합니다.<br>
2 - 클러스터 내 각 마스터에게 FAILOVER_AUTH-REQUEST를 브로드캐스팅합니다<br>
3 - 각 마스터는 해당 패킷을 받으면 FAILOVER_AUTH_ACK로 응답합니다. (=투표)<br>
4 - 레플리카는 currentEpoch보다 큰 에포크 응답을 반영합니다.<br>
5 - 과반수의 마스터로부터 투표를 받으면 해당 레플리카가 승격 대상이 되어 페일오버가 진행됩니다.<br>
5'- 과반수에 도달하지 못할 경우 cluster-node-timeoutx2의 시간 동안 대기한 후, cluster-node-time-outx4 시간 후 재투표를 진행합니다.<br>
6 - 마스터가 된 노드는 다른 마스터보다 더 크게 configEpoch를 증가시킵니다. <br>Epoch<br>
분산 시스템에서 중요한 변화가 일어날 때마다 증가하는 버전 번호입니다. <br>]]></description><link>db/cache/redis-cluster.html</link><guid isPermaLink="false">DB/Cache/Redis Cluster.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Thu, 13 Jun 2024 06:30:51 GMT</pubDate><enclosure url="https://i.imgur.com/2ELVfy9.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/2ELVfy9.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Redis Replication]]></title><description><![CDATA[ 
 <br><br><br><img src="https://i.imgur.com/IAmMhPR.png" referrerpolicy="no-referrer"><br>일반적으로 쓰기 작업이 있을 때마다 업데이트 된 데이터를 다른 레디스로 보내 복제합니다. 서버를 추가하하여 읽기 쿼리의 부하를 관리할 수 있으며 복제한 데이터로 페일오버를 실행할 수 있습니다. <br><br>비동기 처리를 통한 구현<br>
이벤트 루프의 비동기 논 블로킹 방식으로 구현되어 있습니다. 비동기 동작으로 인해 지연이 발생하는 경우 마스터와 레플리카 내의 데이터 차이가 발생할 수 있습니다. <br>기본적으로 읽기 전용<br>
기본적으로 레플리카에는 쓰기 작업이 불가능합니다. replica-only 지시자를 통해 변경할 수 있습니다. 레플리카에 쓰기 작업이 가능한 상태에서는 데이터의 일관성이 깨질 위험이 있으므로, 특별한 이유가 있을 경우에만 쓰기 작업을 사용해야합니다. <br>실행 시간이 많이 소요되는 작업일 경우에만 레플리카에 쓰기 작업을 활성화해 임시 데이터를 저장하고 여러번 참조하는 방식으로 레플리카에서 쓰기 방식을 사용할 수 있습니다. <br>마이그레이션으로 활용하기<br>
새로운 레디스 서버로 마이그레이션할 때, 서비스 중단 시간을 최소화하기 위해 레플리케이션 기능을 활용할 수 있습니다. 기존 레디스 서버에서 마이그레이션할 레디스 서버로 레플리케이션을 생성한 후 마이그레이션한 서버를 독립시키는 방식으로 수행합니다. <br><br><br><img src="https://i.imgur.com/euFLomG.png" referrerpolicy="no-referrer"><br><a data-tooltip-position="top" aria-label="Replication 구성 단계.canvas" data-href="Replication 구성 단계.canvas" href="db/cache/replication-구성-단계.html" class="internal-link" target="_self" rel="noopener">Replication 구성 단계</a><br><br>요청 처리에 미치는 영향이 크지만 모든 상황에서 실행 가능합니다. 프로세스가 포크 처리되어 마스터의 메모리 데이터를 덤프하고 디스크에 RDB를 저장합니다. 또한 덤프한 모든 데이터를 마스터에서 레플리카로 옮기기 때문에 네트워크 I/O도 발생합니다. <br>전체 동기화와 데이터 일관성<br>
마스터가 RDB파일을 전송할 때, 레플리카에 RDB 파일이 있다면 일관성을 위해 레플리카에 있는 파일은 삭제합니다.<br>replica-serve-stale-data<br>
레플리케이션을 시작한 후 RDB 파일을 수신하는 동안, 레플리카는 클라이언트로부터 요청 받을 수 있습니다. 이 때 동기화 이전의 데이터가 반환될 수 있습니다. replcia-serve-stale-data의 값을 no로 변경하여 요청에 응답하는 대신 SYNC with master in progress라는 오류 메시지에 답하게 할 수 있습니다. <br><br>요청 처리에 미치는 영향이 작지만, 조건부로 실행 가능합니다. ]]></description><link>db/cache/redis-replication.html</link><guid isPermaLink="false">DB/Cache/Redis Replication.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Thu, 13 Jun 2024 06:26:01 GMT</pubDate><enclosure url="https://i.imgur.com/IAmMhPR.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/IAmMhPR.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Index 잘쓰는 방법]]></title><description><![CDATA[ 
 <br><br><br><br>인덱스를 지정하는 기준 : 카디널리티와 선택률<br>
인덱스는 테이블의 특정 필드를 지정합니다. 이 때 어떤 필드를 지정할 것인지의 기준은 필드의 카디널리티와 선택률입니다. <br>카디널리티란<br>
카디널리티란 값의 균형을 나타내는 개념입니다. 고유성이라고 생각하면 편합니다. 카디 널리티가 가장 높은 필드는 PK 필드입니다. 반대로 모든 레코드에 같은 값이 들어가 있다면 카디널리티가 낮은 필드입니다. <br>선택률이란<br>
선택률은 특정 필드값을 지정했을 때 테이블 전체 레코드 중 선택되는 레코드의 비율입니다. 예를 들어서 100개의 레코드를 가진 테이블에서 pk=1을 조건으로 지정한다면 단 한 개의 레코드가 선택됩니다. 때문에 선택률은 1/100=0.01, 1%입니다.<br><br>인덱스를 작성하는 필드 집합의 조건은 두 가지 지표로 판단합니다. <br>첫째, 카디널리티가 높을 것<br>
값이 평균치에서 많이 흩어져 있고, 고유값이 많을 수록 좋은 인덱스 후보입니다. <br>둘째, 선택률이 낮을 것<br>
한 번의 선택으로 레코드가 가능한한 적게 선택되는 것이 좋습니다. 최근 DMBS환경에서는 5~10%이하가 좋은 선택기준입니다. 5% 미만이라면 해당 필드 집합은 인덱스를 도입할 가치가 있습니다. 선택률이 10%보다 높다면 테이블 풀 스캔이 더 빠를 수도 있습니다. <a data-footref="note1" href="about:blank#fn-1-d77aa48e41bd6931" class="footnote-link" target="_self" rel="noopener">[1]</a><br>왜 선택률에 따라 테이블 풀 스캔이 빨라질 수 있을까?<br>
정확하게는 선택되는 데이터의 개수에 따라 달라집니다. 먼저 풀 테이블 스캔과 인덱스 스캔의 작동 원리부터 알아보겠습니다. <br>인덱스 스캔은 각 레코드를 찾기 위해 인덱스 페이지를 읽고 그 다음 테이블 페이지를 읽습니다. 하지만 테이블 풀 스캔의 경우 디스크 I/O 작업이 순차적으로 이루어지기 때문에 많은 양의 데이터를 읽을 때, 더 효율적일 수 있습니다. 또한 한번에 큰 블록을 읽기 때문에 여러번 인덱스 테이블을 참조하는 것보다 빠를 수 있습니다. <br>즉, 찾아야하는 데이터의 수가 많아질수록 인덱스를 사용해 각각의 레코드를 찾는 것 보다 대다수의 레코드를 한번에 읽는 것이 빠를 수 있습니다.<br><br>셋째, 클러스터링 팩터가 낮을 것<br>
클러스터링 팩터는 인덱스된 컬럼의 순서가 테이블의 물리적 데이터 저장 순서와 얼마나 일치하는지를 나타내는 값입니다. 클러스터링 팩터가 높을수록 데이터가 물리적으로 분산되어 있고, 낮을수록 물리적으로 뭉쳐있습니다. <br>클러스터링 팩터는 다음과 같이 계산합니다. <br>1. 인덱스 엔트리를 순차적으로 스캔합니다.
2. 각 인덱스 엔트리가 가리키는 테이블의 데이터 블록을 확인합니다.
3. 인덱스 엔트리가 순차적으로 가리키는 데이터 블록이 이전 엔트리의 데이터 블록과 다를 때마다,
   클러스터링 팩터 값을 증가시킵니다.
Copy<br>즉, 클러스터링 팩터가 낮을수록 인덱스된 컬럼의 순서가 테이블의 물리적 저장 순서와 거의 일치합니다. 이는 인덱스를 사용할 때 디스크 I/O가 최소화되어 성능이 최적화됩니다.<br>클러스터링 팩터는 다음과 같이 확인합니다. <br><br>클러스터링 팩터를 최적화하는 방법<br>
<br>테이블 재구성: 테이블을 클러스터드 인덱스를 사용하여 재구성하면 클러스터링 팩터를 낮출 수 있습니다. 이는 테이블 데이터를 인덱스 키 순서대로 재배열합니다.
<br>인덱스 재구성: 인덱스를 주기적으로 재구성하여 인덱스와 테이블 데이터 간의 순서를 맞출 수 있습니다.
<br>적절한 인덱스 선택: 테이블의 액세스 패턴을 분석하여 적절한 인덱스를 선택하면 클러스터링 팩터를 최적화할 수 있습니다.
<br><br>인덱스 설계는 테이블 정의와 SQL만 봐서 할 수 있는 작업이 아닙니다. 특정 SQL에 적절한 인덱스를 생성하려면 검색 조건과 결합 조건을 바탕으로 데이터를 효율적으로 압축할 수 있는 조건을 찾아야합니다. 이를 위해서는 SQL 구문과 검색 키 필드의 카디널리티를 알아야합니다. <br>하지만 압축 조건을 찾지 못한다면 어떻게 해야할까요? <br><br>인덱스가 제대로 작동하려면 레코드를 크게 압축할 수 있는 검색조건이 필수입니다. 필드가 상태를 표시할 경우 카디널리티가 작아 인덱스로 만들기 적합하지 않을 수 있습니다.<br>SELECT order_id, recieve_date FROM Orders WHERE process_flg='5'; 
Copy<br>현재 테이블에서 process_flg의 분포는 다음과 같다고 가정합니다. <br><br>5로 선택하여 검색할 경우 선택률이 83%로 굉장히 높은 수치입니다. 이 상태에서 process_flg 필드에 인덱스를 생성하면 당연히 인덱스를 생성하는데 시간이 매우 오래걸립니다. 또한, 인덱스를 생성하여 사용한다 치더라도 풀 스캔을 할 때보다 느려질 가능성이 큽니다. <br><br>SELECT order_id
FROM Orders 
WHERE receive_date 
BETWEEN :start_date AND :end_date 

Copy<br>검색 범위를 하루로 설정할지, 1년으로 설정할지에 따라 선택률이 매우 크게 달라집니다. 1년 내내 주문량이 균등할 경우 1일로 지정할 때의 365배의 레코드가 선택될 확률이 매우큽니다. 다른 쿼리도 하나 더 보겠습니다. <br>SELECT count(*)
FROM Orders
WHERE shop_id=:sid; 
Copy<br>이 쿼리는 점포의 주문량에 따라 선택률이 급하게 변합니다. 소규모 점포에서 10만건이 선택되고 대규모 점포에서는 1000만건이 선택된다고 가정하겠습니다. 소규모 점포에서의 선택률은 0.01%, 대규모 점포에서의 선택률은 무려 10%입니다. <br>힌트를 사용해볼까?<br>
SELECT /*+ INDEX(Orders shop_id_index) */ count(*)
FROM Orders
WHERE shop_id = :sid;

SELECT /*+ FULL(Orders) */ count(*)
FROM Orders
WHERE shop_id = :sid;


Copy<br>전자에 대해서는 인덱스를 사용하는 것이, 후자에 대해서는 인덱스를 사용하지 않는 것이 좋지만 이처럼 선택률에 따라 실행계획을 다르게 하는 것은 힘듭니다. 힌트를 사용해서 소규모 점포 쿼리에는 인덱스를 사용하게끔, 대규모 점포 쿼리에는 테이블 풀 스캔을 하도록 힌트를 줄 수 있지만 한계가 명확한 방법입니다. <br>또한 결합에 있어서도 Nested Loops 내부 테이블 결합 필드에 조건으로 히트되는 레코드가 많으면 반복되는 횟수가 늘어나므로 성능 문제가 발생합니다. <br><br>압축할 검색 조건이 있지만 인덱스를 쓰지 못하는 쿼리를 작성하는 케이스가 있습니다. <br><br>
SELECT order_id
FROM Orders
WHERE shop_name LIKE '%대공원%'
Copy<br>중간일치 또는 후방 일치에는 인덱스를 사용할 수 없습니다. 설령 검색 조건의 선택률이 좋다고 하더라도 풀 테이블 스캔을 사용할 수 밖에 없습니다. <br><br>인덱스로 지정된 필드로 연산하는 경우에는 인덱스를 사용할 수 없습니다. 인덱스 테이블에 존재하는 값은 index_col1이지 index_col1 '*' 1.1 이 아니기 때문입니다.<br>
SELECT `*`
FROM Practice
WHERE index_col1 `*` 1.1 &gt;100; 
Copy<br>하지만 다음과 같은 방식으로 인덱스 자체의 연산을 회피하는 방식으로 인덱스를 사용하게끔 개선할 수 있습니다. <br>WHERE col_1&gt; 100/1.1 
Copy<br>당연히 인덱스가 지정된 필드에 함수 또는 부정형를 사용하는 경우도 인덱스를 사용할 수 없습니다. 함수 색인하는 방법도 있지만, 쓸데 없는 연산 비용이 발생하기 때문에 기본적으로 사용하지 않는 편이 좋습니다. <br>SELECT `*`
FROM Practice
WHERE LENGTH(index_col1) = 10; 
Copy<br>SELECT `*`
FROM Practice
WHERE index_col1 &lt;&gt; 10; 
Copy<br>
<br>
<br>Richard J, Niemiec, Oracle Database 11g Release 2 Performance Tuning Tips &amp; Techniques, Mcgraw-Hill Osborne Media, 2012<a href="about:blank#fnref-1-d77aa48e41bd6931" class="footnote-backref footnote-link" target="_self" rel="noopener">↩︎</a>
]]></description><link>db/rdb/index-잘-쓰는-방법.html</link><guid isPermaLink="false">DB/RDB/Index 잘 쓰는 방법.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Mon, 10 Jun 2024 17:27:08 GMT</pubDate></item><item><title><![CDATA[Index &amp; B-Tree]]></title><description><![CDATA[ 
 <br><br>
RDB 인덱스의 자료구조는 다음과 같이 세 가지로 분류할 수 있습니다. 

<br>B-tree 인덱스 
<br>비트맵 인덱스 
<br>해시 인덱스 

<br><br>DB에서 인덱스라고 말하면 대부분 B-Tree 인덱스를 지칭하는 것입니다. 실제로 CREATE INDEX 구문을 실행하면 기본값으로 B-Tree 인덱스가 생성됩니다. <br>검색 알고리즘으로서는 성능이 뛰어나게 좋진 않다.<br>
B-Tree를 고안했던 사람 중 한 명인 R.Bayer도 만약 데이터가 변화하지 않는다면 다른 인덱스 기술로도 B-Tree와 비슷한 성능을 낼 수 있을 것이다. 라고 말한 적 있습니다. <br>B-Tree의 수정버전<br>
대부분의 DB에서는 트리의 리프 노드에만 키값을 저장하는 B+Tree라는 수정버전을 사용합니다. (Oracle, PostgreSQL, MySQL) B-Tree보다 검색에 있어서 효율적으로 만든 알고리즘입니다.<br>B+Tree가 검색성능이 뛰어난 이유는 몇가지 있습니다. 첫째, B+Tree는 루트와 리프의 거리를 가능한한 일정하게 유지하려합니다. 또한 트리의 깊이도 대개 3~4 정도의수준으로 일정합니다. 데이터 또한 정렬상태를 유지하기 때문에 이분탐색을 적용할 수 있습니다. <br><br>비트 인덱스는 데이터를 비트 플래그로 변환하여 저장하는 형태의 인덱스입니다. 카디널리티가 낮은 필드에 대해 효과를 발휘합니다. 하지만 갱신 시의 오버헤드가 크기 때문에 빈번한 갱신이 일어나지 않는 BI/DWH 용도로 사용합니다. <br>BI/DWH<br>
DWH(Data Warehouse)는 데이터를 수집, 정제, 저장하는 역할을 하며, BI(Business Intelligence)는 DWH에 저장된 데이터를 분석하고 시각화하여 비즈니스 인사이트를 제공합니다.<br><br>키를 분산하여 등가 검색을 고속으로 실행하고자 만들어진 인덱스입니다. 등가 검색외 이점이 별로 없고, 범위 검색이 불가능합니다. 지원하는 DBMS로는 PostgreSQL과 Oracle의 Reverse Index 기능이 있습니다. 효과가 거의 없고 지원하는 DBMS마저 적어서 거의 사용할 일이 없습니다. ]]></description><link>db/rdb/index의-종류.html</link><guid isPermaLink="false">DB/RDB/Index의 종류.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Mon, 10 Jun 2024 16:27:58 GMT</pubDate></item><item><title><![CDATA[Hash 함부로 쓰면 메모리 터진다]]></title><description><![CDATA[ 
 <br><br><br><a data-tooltip-position="top" aria-label="https://www.acmicpc.net/problem/2121" rel="noopener" class="external-link" href="https://www.acmicpc.net/problem/2121" target="_blank">문제풀어보기</a><br>실버 3의 비교적 쉬운 문제처럼 보이는데요. 위 문제는 생각없이 풀면 머리에 ? 띄우기 딱 좋은 문제입니다. 특히 잘못된 풀이의 경우 논리적, 시간복잡도 측면에서도 틀린 것이 전혀 없기 때문에 헤매기 매우 쉽습니다. 풀이방향 잘못 잡으면 메모리 초과가 발생하기 때문에, 공간복잡도를 건드는 문제는 조심해서 접근해야합니다. <br>심지어 python, cpp에서는 문제 없이 통과되는 코드가 Java 특유의 객체지향성과 JVM/GC 특성이 환장의 시너지를 일으켜 통과가 안되는 경우가 꽤 있습니다. (억울) Java 쓴다고 이런 패널티를 받을 수는 없으니, 유의하도록합시다. (혹은 빠른 시일 내에 cpp나 python으로 갈아ㅌ..)<br>대기업 공채에서 이런 문제에 잘못 낚일 경우 6개월에서 1년동안 손가락 빨고 있어야합니다 ㅎㅅㅎ<br><img src="https://i.imgur.com/vhS6I39.png" referrerpolicy="no-referrer"><br>문제를 간단히 요약하면 다음과 같습니다. <br>
<br>n개의 좌표가 입력으로 주어진다. 
<br>직사각형의 길이 a,b가 주어진다. 
<br>n개의 좌표로 직사각형을 만들 때 길이가 일치하는 경우의 수 구하기 
<br>특이한건 전체 데이터의 개수가 약 10^5 개, 각 좌표값은 long 타입 써야할 정도로 숫자가 매우 흉악한데요. 전형적인 데이터 개수 &amp; 크기로 내리찍는 문제입니다. 이 부분을 유의하면서 풀어봅시다. 불행 중 다행으로 전체 경우의 수는 2^31 안으로 나온다했으니, 정답 변수 만큼은 int로 선언할 수 있겠네요.<br><br> 정말 간단하게 접근했을 때의 풀이입니다. 백트래킹이나 4중 반복문을 써서 가능한 모든 조합을 테스트 해보는 것입니다. 먼저 시간 복잡도를 계산해보겠습니다. 백트래킹으로 구현할 경우 조합의 개수 만큼 시간 복잡도가 나옵니다. nC4가 되므로 n=500,000을 넣어 계산해보겠습니다.<br>
500000C4 = 2,60,385,417,812,487,500(~=10^17)이므로 택도 없는 풀이네요.<br><br>그렇다면 고려해볼만한 것은 해시입니다. 풀이는 다음과 같습니다. <br>답안 로직<br>
<br>x와 y좌표를 속성으로 갖고 x,y로 고유성을 판별할 수 있는 Position클래스를 정의합니다. 
<br>주어진 모든 점을 해시셋에 넣습니다. 
<br>가장 왼쪽 아래의 점(x y)을 잡았다 치고 주어진 모든 점을 순회합니다. 
<br>해시셋에서 나머지 3개의 점 (x+a, y+b), (x,y+b), (x+a,y) 이 있는지 확인합니다. 
<br><a data-tooltip-position="top" aria-label="https://www.acmicpc.net/submit/2121/79462950" rel="noopener" class="external-link" href="https://www.acmicpc.net/submit/2121/79462950" target="_blank">전체 코드는 다음과 같습니다.</a><br>시간복잡도를 계산해볼까요?<br>
<br>주어진 입력을 Position 객체로 만들어 해시셋에 저장합니다.(=O(n))
<br>전체 좌표에 대해 순회합니다. (=O(n))
<br>기준 좌표에 대해서 나머지 3개의 좌표가 존재하는 지 해시를 통해 확인합니다. (=O(3x1))
<br>전체 시간 복잡도는 다음과 같습니다. O(n+3*n) = O(n)
<br>전체 시간복잡도는 O(n)으로 매우 무난하게 통과해야하는데요. <br><img src="https://i.imgur.com/l3ixUdK.png" referrerpolicy="no-referrer"><br>????????<br>보시는 바와 같이, 메모리 초과가 발생합니다. 왜 메모리 초과가 발생할까요? 그리고 실전에서 이와 같은 풀이를 방지하려면 어떻게 해야할까요??<br><br>128MB 메모리 제한이 있을 때, Set&lt;Position&gt;가 최대 몇 개의 키를 가질 수 있는지 계산하기 위해서는 각 Position 객체가 차지하는 메모리 크기를 알아야 합니다. 이를 위해 Position 클래스의 메모리 크기를 분석해야 합니다.<br>Position 클래스는 두 개의 long 필드를 가지고 있습니다. long 타입은 64비트(8바이트)이므로, 두 개의 long 필드는 16바이트를 차지합니다. 그러나 Java 객체에는 추가적인 오버헤드가 존재합니다.<br>Java 객체의 메모리 오버헤드는 다음과 같이 계산됩니다:<br>
<br><a data-href="객체 헤더" href="java/객체-헤더.html" class="internal-link" target="_self" rel="noopener">객체 헤더</a>: 12바이트 (8바이트는 기본 객체 헤더, 4바이트는 정렬 패딩)
<br>long 필드 두 개: 16바이트 (각각 8바이트)
<br>따라서, Position 객체는 12바이트(헤더) + 16바이트(필드) = 28바이트가 됩니다. 그러나 Java 객체는 메모리 정렬 패딩에 따라 8바이트 단위로 정렬됩니다. 그러므로 28바이트는 32바이트로 정렬됩니다.<br>하지만 실제로 Map에 키로 사용될 때는 추가적인 메모리 오버헤드가 발생합니다. 일반적으로 HashSet을 예로 들면:<br>
<br>HashSet.Entry 객체: 약 32바이트 (참조 변수와 정렬 패딩 포함)
<br>기타 오버헤드 (해시 테이블 등): 해시 테이블 크기에 따라 다름
<br>보수적으로 계산해보면, 하나의 Position 객체가 HashSet의 키로 사용될 때 약 64바이트의 메모리를 차지한다고 가정할 수 있습니다.<br>이제 전체 메모리 사용량을 계산해 보겠습니다:<br>
<br>주어진 메모리 제한: 128MB = 128  1024  1024 바이트 = 134,217,728 바이트
<br>각 Position 객체가 약 64바이트를 차지하므로, Map이 가질 수 있는 최대 키의 개수는:<br><br>따라서, 128MB 메모리 제한이 있을 때 Set&lt;Position&gt;은 최대 약 2,097,152개의 키를 가질 수 있습니다.<br>문제에서 풀이는 처음 해시셋에 키를 저장할 때 최대 50만개의 키, 3개의 점으로 판단할 때 최대 200만(4x50만)개의 키를 사용합니다. <br>즉 최대 250만개의 키를 사용할 가능성이 있기 때문에 128MB의 메모리 제한이 있을 때 메모리 초과가 발생합니다. <br><br>그렇다면 해시를 사용하지 않으면 어떻게 해야할까요? 바로 이진탐색을 사용하는 것입니다. 속성이 2가지라 이진 탐색 사용이 어려울 것 같지만, java의 comparable 인터페이스를 구현하여 정렬을 하면 비교적 쉽게 구현할 수 있습니다. <br>풀이는 해시와 비슷합니다. <br>
<br>전체 좌표에 대해서 순회한다. 
<br>해당 좌표를 좌하단 좌표로 기준을 잡고 판단한다. 
<br>나머지 3개의 좌표((x+a, y+b), (x,y+b), (x+a,y))를 이진탐색을 활용해 있는지 없는지만 빠르게 판단한다. 
<br>보시는 바와 같이 기본적인 논리구조는 같은데, 실제 값을 찾을 때 해시를 사용할 것이냐, 이진탐색을 사용할 것이냐의 차이로 갈리게 됩니다.<br>시간복잡도는 전체 좌표에 대해서 순회하는 시간 O(n), 이진탐색을 이용해서 나머지 3개의 좌표가 있는지 없는지 판단하는 시간 O(logN) 총 O(3nlogN)이므로 해시보다는 느려도, 매우 넉넉하게 시간 제한 안에 들어올 수 있습니다. <br>실제 코드를 통해 확인해보겠습니다. <br>이진탐색에서 활용할 데이터 셋은 정렬이 필수기 때문에 정렬을 해주는 모습입니다. <br>

for (int i = 0; i &lt; n; i++) {
	tokens = new StringTokenizer(buffer.readLine());

	positions[i] = new Position(
		Long.valueOf(tokens.nextToken()), 
		Long.valueOf(tokens.nextToken())
		);
	}

Arrays.sort(positions);
Copy<br>전체 좌표를 순회하며 좌하단으로 고정했을 때 나머지 3개의 좌표가 있을 때만 세는 코드입니다.<br>long result = Arrays.stream(positions)
                .filter(p-&gt;isValid(positions, p, a,b))
                .count();
Copy<br>
private static boolean isValid(Position[] positions, Position position, int a, int b){
	return binarySearch(positions, position.x+a, position.y+b)&amp;&amp;
			binarySearch(positions, position.x, position.y+b)&amp;&amp;
			binarySearch(positions, position.x+a, position.y);

}
Copy<br>객체의 comparable 인터페이스를 구현하여 두 종류 이상의 변수가 있어도 쉽게 이진탐색을 수행하는 코드입니다. <br>
private static boolean binarySearch(Position[] positions, long targetX, long targetY) {
	int l = 0;
	int h = positions.length;


	while(h&gt;l){
		int mid = (l+h)/2;

		Position midPosition = positions[mid];

		if(midPosition.x==targetX&amp;&amp;midPosition.y==targetY){
			return true;
		}else if(midPosition.compareTo(new Position(targetX, targetY))&lt;0){
			l=mid+1;
		}else{
			h=mid;
		}
	}

	return false;

}

Copy<br>class Position implements Comparable&lt;Position&gt;{
    long x, y;


    public Position(long x, long y){
        this.x = x;
        this.y = y;
    }
	//equals와 compareTo를 오버라이딩한 메서드는 중략... 

    @Override
    public int compareTo(Position o){
        if(this.x==o.x){
            return Long.compare(this.y, o.y);
        }
        return Long.compare(this.x, o.x);
    }
}
Copy<br><br>
<a data-tooltip-position="top" aria-label="https://www.acmicpc.net/source/79467346" rel="noopener" class="external-link" href="https://www.acmicpc.net/source/79467346" target="_blank">파이썬 해시 활용 제출코드</a><br>
<a data-tooltip-position="top" aria-label="https://www.acmicpc.net/source/79464005" rel="noopener" class="external-link" href="https://www.acmicpc.net/source/79464005" target="_blank">자바 이진탐색 활용 제출코드</a>
<br>def is_rectangle_present(x, y, A, B, point_set): 
	return ((x + A, y) in point_set 
				and (x, y + B) in point_set 
				and (x + A, y + B) in point_set)

def count_rectangles(points, A, B):
    point_set = set(points)
    count = 0

    for (x, y) in points:
        if is_rectangle_present(x, y, A, B, point_set):
            count += 1

    return count

import sys
input = sys.stdin.read
data = input().split()

N = int(data[0])
A = int(data[1])
B = int(data[2])

points = []
for i in range(N):
    x = int(data[3 + 2 * i])
    y = int(data[4 + 2 * i])
    points.append((x, y))

result = count_rectangles(points, A, B)


print(result)

Copy<br>해쉬를 사용하는 동일한 풀이를 python으로 작성하고 제출해봤습니다. <br><img src="https://i.imgur.com/mTfnu0R.png" referrerpolicy="no-referrer"><br>자바는 오늘도 연전연패..]]></description><link>알고리즘과-자료구조/hash-함부로-쓰면-메모리-터진다.html</link><guid isPermaLink="false">알고리즘과 자료구조/Hash 함부로 쓰면 메모리 터진다.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Mon, 10 Jun 2024 12:07:28 GMT</pubDate><enclosure url="https://i.imgur.com/vhS6I39.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/vhS6I39.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Parametric Search]]></title><description><![CDATA[ 
 <br><br>
문제를 결정 문제로 변형하여 이분탐색으로 해결하는 방식입니다. 
<br><br>처음들으면 잘 와닿지 않을 수 있다. 예시를 통해서 살펴봅시다. <br>예를들어 손님이 고기 200g을 달라고 해서 고기 덩이에서 200g을 잘라내야한다고 해봅시다.우리는 보통 눈대중으로 잘라서 저울에 재본 후 200g보다 부족하면 조금 더 잘라넣고 200g을 넘어가면 덩어리를 잘라서 저울에 잰다. <br>즉 우리는 "고기 200g을 잘라라"라는 문제를 "지금 자른 고기가 200g보다 무거운가"라는 결정문제로 변형한 뒤 조금씩 고기를 추가하거나 덜어내면서((=이분탐색)으로 문제를 해결한다. 이렇게 원래 주어진 문제를 결정문제로 변형하여 이분탐색을 통해 해결하는 것을 파라메트릭 서치라고 한다. <br><br>
아래 세 조건을 만족하는 문제에서만 사용할 수 있습니다. 
<br>1.특정 조건을 만족하는 최대/최소를 구하는 형식의 문제여야 합니다.<br>
조건이 보이지 않더라도 최소한 해당 조건으로 문제를 변경할 수 있어야합니다. 수행할 변수를 가지고 함수를 세웠을 때 그 함수가 감소함수거나 증가함수이어야 합니다.<br>2.어떤 값이 조건을 만족하면 이후 탐색 범위 내의 모든 값은 모두 조건을 만족해야한다.<br>
최대값을 구하는 문제의 경우 어떤 값이 조건을 만족하면 그 값보다 작은 값은 모두 조건을 만족해야한다. 또한 최솟값을 구하는 경우 어떤 값이 조건을 만족하면 그 값보다 큰 값은 모두 조건을 만족해야합니다. 그래야 조건을 만족하는 경우, 만족하지 않는 경우 다음 범위를 탐색하면서 답을 구할 수 있습니다. <br>3.범위가 이산적이거나 허용오차 범위가 있어야합니다.<br>
이분탐색으로는 연속적인 범위에서는 정답에 한없이 가까워질 뿐 정확한 값은 구할 수 없습니다. (=고등수학에서의 극한을 떠올리면 됩니다.)<br><br><br>
condition(x)를 만족하는 최대값을 찾는 문제라고 가정합니다. 
<br><br>목표 : 후보 범위의 최솟값인 l과 h를 넉넉하게 잡아준 뒤 이를 점점 줄여나가면서 l과 h가 같아지도록 합니다. <br>whlie(l&lt;h){
	int m = (l+h+1)/2; 

	if(condition(m)){
		l = m;
	}else{
		h = m-1;
	}
}


Copy<br>주의 : 무한 루프에 빠지지 않는지 확인하기 <br>m=(l+h)/2인지, m=(l+h+1)/2인지에 따라 무한루프에 걸릴 수 있습니다. <br>무한 루프에 빠지지 않게하려면 이분탐색에 의해 두 구역으로 나눠졌을 때 m이 어디에 속하는지를 확인하면 됩니다. 예를 들어 조건을 만족하는 최댓값을 구하는 경우 m은 h쪽 범위에 속합니다. l과 h가 1차이로 붙어 있을 때 그림은 다음과 같습니다. <br><img src="https://i.imgur.com/JGxXFz2.png" referrerpolicy="no-referrer"><br>
m=(l+r)/2일 경우, 그림처럼 m은 항상 왼쪽 범위로 고정되고 오른쪽 범위는 변하지 않아서 무한 루프에 빠집니다.<br><img src="https://i.imgur.com/Yt8EEkN.png" referrerpolicy="no-referrer"><br>
m=(l+r+1)/2일 경우 m은 오른쪽 범위속하게 되면서 다음 범위는 [m,m]이 됩니다. <br>표로 정리해보겠습니다. <br><br><br>
<br>범위가 m이면 루프는 logM번 실행됩니다. 
<br>조건 함수의 시간 복잡도 = O(C(n))
<br>위 조건을 모두 고려하면 총 시간 복잡도는 O(C(n)logM)이 됩니다. 
<br><br><br>parametirc search에서 결정 문제라는 표현을 썼었습니다. 그게 이 문제에서 어떻게 적용되는지 살펴보겠습니다. 이 문제는 N개를 만들 수 있는 랜선의 최대 길이를 구하는 것이 목표입니다. 이걸 결정 문제로 바꾸면 우리가 구해야하는 답을 인자로, 조건의 참 거짓을 판단하는 문제로 만들 수 있습니다. <br>1. 변수를 지정합니다. (보통은 문제에서 요구하는 최대값/최솟값입니다.)
2. 해당 변수를 이진탐색하면서 codition에 만는지 판단합니다. 
3. condition을 정의합니다. 
4. 기본 템플릿에 맞춰서 구현합니다. 

Copy<br>기본 템플릿을 다시 봐봅시다. <br>whlie(l&lt;h){
	int m = (l+h+1)/2; 

	if(condition(m)){
		l = m;
	}else{
		h = m-1;
	}
}


Copy<br>길이 m을 임의로 선택하여 condition 함수에 넣으면 condition 함수에서는 랜선이 n개 이상일 수 있는지 판단합니다. <br>다음은 완성된 코드입니다. ]]></description><link>알고리즘과-자료구조/알고리즘/이진탐색/parametric-search.html</link><guid isPermaLink="false">알고리즘과 자료구조/알고리즘/이진탐색/Parametric Search.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Mon, 10 Jun 2024 06:34:05 GMT</pubDate><enclosure url="https://i.imgur.com/JGxXFz2.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/JGxXFz2.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[객체 헤더]]></title><description><![CDATA[ 
 <br>Java에서 객체 헤더(object header)는 각 객체의 메타데이터를 저장하는 부분으로, JVM이 객체를 관리하는 데 필요한 정보를 포함합니다. 객체 헤더는 JVM 구현마다 다를 수 있지만, 일반적으로 다음과 같은 정보를 포함합니다:<br>
<br>
Mark Word:

<br>Locking Information: 객체의 락 상태를 저장합니다. 이는 객체가 동기화 블록에 의해 잠겨 있는지 여부를 나타냅니다.
<br>Hash Code: 객체의 해시 코드가 캐시될 수 있습니다.
<br>Garbage Collection Information: GC 상태를 나타낼 수 있습니다.
<br>Age: 객체의 "나이"를 추적하여 GC가 오래된 객체를 더 자주 수집할 수 있도록 합니다.


<br>
Klass Pointer:

<br>Class Metadata: 객체가 어떤 클래스의 인스턴스인지를 가리키는 포인터입니다. 이는 객체가 속한 클래스의 메타데이터를 참조합니다.


<br><br>Java 64비트 HotSpot VM의 경우, 객체 헤더는 일반적으로 다음과 같이 구성됩니다:<br>
<br>Mark Word: 64비트
<br>Klass Pointer: 64비트 (압축된 포인터 사용 시 32비트)
<br>이러한 헤더는 JVM에서 객체를 관리하고 동기화, GC 등을 수행하는 데 필수적입니다.<br><br>다음은 객체 헤더의 역할을 간략히 보여주는 예제입니다:<br>
public class Main {
    public static void main(String[] args) {
        Object obj = new Object();

        // System.identityHashCode는 객체의 헤더에 저장된 해시 코드를 반환
        int hashCode = System.identityHashCode(obj);
        System.out.println("HashCode: " + hashCode);

        // 기본 동기화 블록, 객체의 모니터 락을 획득
        synchronized (obj) {
            System.out.println("Object is locked");
        }
    }
}


Copy<br>이 예제에서:<br>
<br>System.identityHashCode(obj)는 객체의 해시 코드를 반환하는데, 이는 객체 헤더의 일부인 Mark Word에 저장될 수 있습니다.
<br>synchronized (obj)는 객체의 모니터 락을 획득하여, 객체 헤더에 있는 락 정보를 사용합니다.
<br><br>객체 헤더는 Java 객체의 중요한 부분으로, JVM이 객체를 효율적으로 관리하고 동기화, 해시 코드 계산, GC 등의 작업을 수행할 수 있도록 돕습니다. 이를 통해 JVM은 객체 지향 프로그램의 효율성을 극대화할 수 있습니다]]></description><link>java/객체-헤더.html</link><guid isPermaLink="false">Java/객체 헤더.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Mon, 10 Jun 2024 10:41:41 GMT</pubDate></item><item><title><![CDATA[코딩테스트 풀이법]]></title><description><![CDATA[ 
 <br><br><br><br><img src="https://i.imgur.com/WwCBhT7.png" referrerpolicy="no-referrer"><br><br><img src="https://i.imgur.com/6d7CvcV.png" referrerpolicy="no-referrer"><br><br><img src="https://i.imgur.com/WFoAZaQ.png" referrerpolicy="no-referrer"><br><br><br><img src="https://i.imgur.com/1fdPgyc.png" referrerpolicy="no-referrer"><br><br><br>시작점 2개를 먼저 큐에 넣고 시작합니다. <br><br><br><br>BFS를 사용할 때 큐에 쌓이는 순서는 반드시 거리순입니다. <br><br><img src="https://i.imgur.com/H9DFlMj.png" referrerpolicy="no-referrer"><br><br>
<br>임의의 정점 1개 구하기 
<br>정점 x에서 가장 먼 정점y 구하기 
<br>정점 y에서 가장 먼 정점 z 구하기 (=트리의 지름)
<br><br>dist 배열을 이용해 거리를 구하고 가장 긴 거리를 갖는 노드를 반환한다. <br><br><br><br>
<br>들어오는 간선이 없는 루트 노드가 정확히 1개 존재하는가
<br>모든 노드는 반드시 단 하나의 들어오는 간선이 있다. 
<br>루트 노드에서 모든 노드를 방문할 수 있으며 이러한 경로는 유일하다. 
<br><br>
int binarySearch(int[] arr, int target){  
  
    int l = 0;  
    int h = arr.length;  
  
    while(h&gt;l){  
        int mid = (l+h)/2;  
        if(arr[mid]==target){  
            return mid;  
        }else if(arr[mid]&gt;target){  
            h = mid;  
        }else{  
            l = mid+1;  
        }  
    }  
    return -1;  
}
Copy<br><br>int upperIdx(int target, int[] arr){
	int l = 0;
	int h = arr.length;
	while(h&gt;l){
		int mid = (l+h)/2;
		if(arr[mid]&gt;target) h = mid;
		else l = mid+1;
	}
	
	return l;

}
Copy<br><img src="https://i.imgur.com/r6XSZRm.png" referrerpolicy="no-referrer"><br><br>int lowerIdx(int target, int[] arr){
	int l = 0;
	int h = arr.length;
	while(h&gt;l){
		int mid = (l+h)/2;
		if(arr[mid]&gt;=target) h = mid;
		else l = mid+1;
	}
	
	return l;

}
Copy<br><br>
<br>값의 등장 횟수 = 정렬이 유지되는 제일 왼쪽과 오른쪽 인덱스 차이
<br><br><br>
각 배열의 값보다는 요소들의 대소 관계만 알고 싶을 때 크기순 인덱스로 붙여버린다. 
<br>
<br>중복값을 지운다. 
<br>이진탐색으로 해당값의 인덱스를 찾는다.
<br><br>private static int[] getArr() throws IOException{  
    return Arrays.stream(buffer.readLine().split("\\s+"))  
            .mapToInt(Integer::parseInt)  
            .toArray();  
}
Copy<br><br>// 스트림을 사용하여 결과를 StringBuilder에 추가  
String result = Arrays.stream(compressedPositions)  
        .mapToObj(String::valueOf)  
        .collect(Collectors.joining(" "));
Copy<br><br>int[] compressedPositions = IntStream.range(0, n)  
        .map(i -&gt; Collections.binarySearch(uniquePositions, positions[i]))  
        .toArray();
Copy반복문 시작 조정isUsed 사용isUsed 사용dis[nx][ny] = dis[current.x][current.y]+1큐에서 뺄때마다 세기시작점 위치 세기]]></description><link>코딩테스트-풀이법.html</link><guid isPermaLink="false">코딩테스트 풀이법.canvas</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Mon, 10 Jun 2024 07:43:45 GMT</pubDate><enclosure url="https://i.imgur.com/WwCBhT7.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/WwCBhT7.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[채킹 내역 저장을 위한 키 설계]]></title><description><![CDATA[ 
 <br><br><br>DynamoDB의 기술적 구현방식을 다루기보단, DynamoDB를에 대해서 얇고 넓게 소개하고, Cloudy의 채팅 내역 저장 시스템에 어떻게 적용했는지 사례를 공유합니다. 기술적 내용에 대해 자세히 알고 싶다면 하단 참고 자료에 관련 링크들을 참조해주세요<br>아래와 같은 키워드가 등장합니다. 본문에서 개념에 대해 설명하며 진행할 예정이나, 관련 배경지식이 있다면 더 쉽게 이해할 수 있습니다. <br>
<br>Dynamo DB
<br>HotPartition
<br>Scale out  / Scale Up 
<br><br>Dynamo Db에서는 Partiion Key와 Sort Key를 합쳐 Primary Key로 사용하는 매우 독특한 특징이 있습니다. 올바르게 Dynamo DB를 사용하기 위해서 DynamoDB의 특징과 성질을 알아보겠습니다. <br>Partition Key<br>
pk는 많은 파티션 중 내가 찾고자하는 데이터가 어느 파티션에 있는지 알려주는 키입니다. 항상 equal 연산자만 사용할 수 있습니다. <br>Sort Key<br>
sk를 이용해서 1:n 관계의 모델링을 적용할 수 있습니다. 오름차순, 내림차순 대로 데이터를 정렬하여 조회할 수 있습니다. begins with , 등호 연산자 및 범위 연산자를 사용할 수 있습니다.<br>pk와 sk를 합쳐 Primary Key가 됩니다. 오직 Primary key로만 데이터 검색이 가능하기 때문에 pk와 sk 조합을 잘 설계해야합니다.<br>
<img src="https://i.imgur.com/o7S8mKQ.png" referrerpolicy="no-referrer"><br><br><br><img src="https://i.imgur.com/d4RQeDY.png" referrerpolicy="no-referrer"><br>데이터끼리 관계를 맺는 RDBMS는 수평적 확장이 매우 힘듭니다. 때문에 주로 스케일 업을 이용하여 해결합니다. 하지만 태생이 대규모 데이터를 처리하기 위해 나온 NoSQL의 경우 무한히 스케일 아웃을 진행할 수 있습니다.<br>
즉, NoSQL을 활용하는 데이터는 수평으로 확장 가능한 데이터가 되게끔 설계해야합니다. 또한 어느 한쪽의 인스턴스로만 트래픽이 쏠리지 않도록 키를 잘 설계해야합니다.<br><br>논리적 단위인 테이블은 한 개여도, 내부에서는 파티션이라는 단위로 쪼개져 저장됩니다. <br><br>하나의 파티션은 다음과 같은 제약사항을 가집니다. 데이터가 계속해서 늘어나더라도 파티션의 개수 증가하는 개념이지, 한 파티션 내의 제약사항은 절대로 변하지 않습니다. <br>
<br>1k WCU
<br>3K RCU 
<br>10GB<br>
-&gt; 여러개의 파티션이 골고루 사용되도록 파티션을 식별하는 키 디자인을 잘하는 것이 중요합니다.
<br><br><img src="https://i.imgur.com/7wXEKR7.png" referrerpolicy="no-referrer"><br><img src="https://i.imgur.com/qL0u4w9.png" referrerpolicy="no-referrer"><br>Dynamo DB는 Id를 해쉬값으로 변경하여 저장되는 파티션을 결정합니다. Application 구현시 Key값을 해쉬로 변경하는 로직은 짜지 않아도 괜찮습니다. <br><br>Amazon DynamoDB에서 파티션은 데이터의 양과 테이블에 대한 읽기/쓰기 요청의 양에 따라 자동으로 관리됩니다. 파티션이 늘어나는 주요 시점은 다음과 같습니다:<br>1.데이터의 양이 증가할 때:<br>
- DynamoDB 테이블에 저장된 데이터의 양이 파티션당 최대 저장 용량(10GB)을 초과할 때 새로운 파티션이 자동으로 추가됩니다. 즉, 테이블에 있는 데이터의 총량이 증가하여 각 파티션의 용량이 초과될 경우 DynamoDB는 추가 파티션을 생성하여 데이터를 분산 저장합니다.<br>2.프로비저닝된 읽기/쓰기 용량이 증가할 때:<br>
- 테이블의 프로비저닝된 읽기 및 쓰기 용량 단위가 증가하면 DynamoDB는 이를 수용하기 위해 파티션 수를 늘릴 수 있습니다. 파티션당 최대 처리량(읽기/쓰기 용량)이 제한되어 있기 때문에, 필요한 처리량을 제공하기 위해 더 많은 파티션을 생성합니다.<br>3.온디맨드 모드에서의 스케일링:<br>
- DynamoDB 테이블이 온디맨드 모드로 설정되어 있으면, 읽기 및 쓰기 요청의 트래픽 패턴을 자동으로 감지하여 파티션을 조정합니다. 트래픽이 급증하거나 감소할 때 테이블의 파티션 수는 자동으로 늘어나거나 줄어들 수 있습니다.<br><br><img src="https://i.imgur.com/78MRveb.png" referrerpolicy="no-referrer"><br>Dynamo DB는 항상 데이터를 복제하여 저장합니다. 3개의 가용영역에 복제되며 서비스는 3개의 가용영역에서 실행됩니다. <br><br><br>DynamoDB는 RCU와 WCU라는 컴퓨팅 단위를 사용합니다. 일반적인 RDB와는 다르게 WCU와 RCU는 독립적으로 동작합니다. <br><br><br>테이블의 전체 크기를 의미합니다. 테이블에 넣을 수 있는 아이템의 개수로 따지는 것이 아닌 최대 크기로 따집니다. 400KB까지 사용 가능합니다. 하지만 400KB를 전부 사용하는 것은 권장하지 않습니다. DynamoDB는 하나의 아이템에서 한 글자만 바뀌어도 다시 쓰는 특성을 갖습니다. 이러한 이유로 아이템의 사이즈는 작게, 아이템의 개수가 많게끔 저장되는 데이터를 모델링하는 것이 이상적입니다. <br>-&gt; DynamoDB의 컨셉은 무한하게 많은 데이터 중 PK+SK의 조합으로 특정한 데이터를 가능한한 빠르게 반환하는 것임을 잊지말아야합니다. <br><br>기본적으로 Dynamo DB에서는 데이터를 읽기 위한 REST API를 제공합니다. <br><br>
<br>Partition Key의 정확한 값을 지정해야합니다. 
<br>0개 또는 1개의 아이템만 반환합니다. 
<br>아이템 크기에 따라 RCU를 사용합니다. 

<br>아이템 크기가 10kb인 경우 2RCU를 사용합니다. 


<br><br>
<br>Partition Key의 정확한 값을 지정해야합니다. 
<br>선택적으로 attributes에 필터링 조건을 추가할 수 있습니다. 
<br>조건에 맞는 아이템을 여러개 반환합니다. 
<br>조건과 일치하는 아이템 크기에 따라 RCU를 소비하여 단일 결과를 반환합니다. 
<br>LastEvaluatedKey <br>
<br>Query는 단일 호출로 최대 1MB만 반환할 수 있습니다.
<br>응답 메시지가 1MB 이상일 경우 LastEvaluatedKey를 활용해 pagination이 가능합니다.
<br><br>
<br>rdbms에서의 Full Table Scan 과 동일합니다.
<br>Dynamo DB에서는 페이지네이션과 비슷하게 동작합니다. <br>
<br>rdbms에서는 테이블 끝까지 조회하지만, DynamoDB에서는 1MB 단위로 스캔이 가능합니다. 
<br>return 갑 중 token을 활용해 다음 1MB 데이터를 스캔할 수 있습니다. 
<br>사용예시<br>
<br>OLTP의 운영환경에서는 사실상 사용할 일이 없습니다. (어쨌거나 저쨌거나 결국 full table scan입니다.)
<br>온라인 마이그레이션을 할때의 옵션 중 하나입니다. 
<br><br>
<br>ACID를 지원하기 위한 API입니다. 
<br>단일 리전 내에서 여러개의 테이블이나 아이템을 트랜잭션으로 묶어 읽거나 쓸 수 있습니다. 
<br>WCU와 RCU가 2배가 소모되기 때문에, 필요한 곳에만 최소화하여 사용해야합니다. 
<br><br>Amazon DynamoDB에서 LSI(Local Secondary Index)와 GSI(Global Secondary Index)는 테이블의 쿼리 성능을 향상시키기 위해 사용되는 인덱스입니다. 두 인덱스 모두 테이블의 속성을 기준으로 데이터를 효율적으로 검색할 수 있게 해주지만, 사용 방법과 동작 방식에서 몇 가지 중요한 차이점이 있습니다.<br><br><img src="https://i.imgur.com/I7V2d7g.png" referrerpolicy="no-referrer"><br>
<br>테이블의 Primary Key 외의 다른 검색 조건이 필요한 경우 사용합니다.
<br>추가나 삭제가 자유로워 스키마 변경시 유연하게 대처할 수 있습니다. 
<br>원하는 Attribute를 GSI의 PK, SK로 설정합니다. 
<br><br><img src="https://i.imgur.com/YzEEnCb.png" referrerpolicy="no-referrer"><br>
<br>테이블 안에서 동일한 PK를 사용하며, 다른 SK를 사용하고 싶을 때 LSI를 사용합니다.
<br>일반적으로 사용을 권장하지 않습니다.<br>
<br>GSI와 달리 테이블 생성 시점에만 설정이 가능합니다. 
<br>사용 도중 삭제 또한 불가능합니다.
<br><br><br><img src="https://i.imgur.com/XvYMacu.png" referrerpolicy="no-referrer"><br>rdbms에서 처럼 엔티티별로 테이블을 만들지 말자<br>
오른쪽 예시처럼 최대한 빠르게 데이터를 조회하게 끔 해야한다. <br>
<br>application의 usecase가 dynamo db가 잘하는 것과 맞는지 판단해야합니다. 
<br>Dynamodb가 가장 잘하는 것은 무한대의 가까운 item에서 특정개수의 아이템을 Primary Key(PK+SK)로 빠르게 조회하는 것 이다. 대량의 벌크성 쿼리, range 쿼리, 집계 쿼리는 잘 수행하지 못합니다.<br>
<br>액세스 패턴을 식별해야합니다.<br>
읽기/쓰기 워크로드, 쿼리 차원, 집계
<br>사이즈가 작은 여러개의 테이블보다는 사이즈가 큰 하나의 테이블을 사용하는 것이 낫다.<br>
DynamoDB는 테이블 단위 완전 관리형 서비스이다.<br>
Dynamo DB는 풀서버리스 형태의 테이블 단위 완전관리형 서비스입니다. 여러 개의 테이블을 만들게 되면 각 테이블에 대한 설정, 모니터링, 최적화 등의 관리 작업이 필요하게 됩니다. 예를 들어 각 테이블의 스키마 설정 및 변경, 인덱스 관리, 성능 모니터링 및 튜닝, 읽기/쓰기 용량 설정 등을 각각의 테이블 별로 따로 해줘야합니다.<br>
이는 완전관리형 서비스의 설계 철학, 즉 "사용자가 최소한의 관리만으로 데이터베이스를 운영할 수 있도록 한다"는 목표에 어긋나게 됩니다.<br>테이블을 하나로 사용해야지, 여러개의 파티션을 사용하는 DynamoDB의 특성을 제대로 활용할 수 있습니다. 또한 핫 파티션이 발생할 확률이 줄어듭니다. <br>OLTP vs OLAP<br>
OLTP가 적합합니다. OLAP인 경우 DynamoDB 외부로 파이프라인을 만들어 분석을 수행해야합니다. <br>디자인 패턴 <br>비정규화 ]]></description><link>prj/cloudy/dynamo-db-채팅-내역-저장을-위한-키-설계.html</link><guid isPermaLink="false">Prj/Cloudy/Dynamo DB - 채팅 내역 저장을 위한 키 설계.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sat, 08 Jun 2024 03:33:24 GMT</pubDate><enclosure url="https://i.imgur.com/o7S8mKQ.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/o7S8mKQ.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Flux를 활용한 SSE 구현기]]></title><description><![CDATA[ 
 <br><br><br>다양한 EventSreaming 구현방식에 대해 알아봅니다. 또한 Cloudy의 채팅 에 왜 SSE를 선택했고 어떻게 개발했는지 사례를 공유합니다. 기술적 내용에 대해 자세히 알고 싶다면 하단 참고 자료에 관련 링크들을 참조해주세요<br>아래와 같은 키워드가 등장합니다. 본문에서 개념에 대해 설명하며 진행할 예정이나, 관련 배경지식이 있다면 더 쉽게 이해할 수 있습니다. <br>
<br>Event Streaming
<br>SSE
<br>Webflux의 Flux 
<br>Nginx 
<br><br>Cloudy 챗봇들은 질문이 들어오면 다음과 같이 작동합니다. <br>1. AOP가 적용되어 있어 불건전 질문을 자동으로 필터링합니다. 
2. 질문에 대해서 관련 AWS 서비스, it 키워드로 추출합니다. 
3. 추출해낸 키워드를 바탕으로 Vector DB[pinecone]에서 관련 데이터를 찾습니다. 
4. 찾아낸 데이터를 바탕으로 최종 답변을 생성해냅니다. 
Copy<br>REST API로 처리할 경우, 1~4 과정(평균 6~8초) 동안 사용자는 로딩 스피너만 바라보는 상황이 발생합니다.  특히 ChatGPT API를 활용해서 답변을 생성해 내는 시간이 가장 오래 걸립니다. Chat GPT Streaming API와 SSE를 조합해 답변을 생성 중 일지라도, 데이터를 실시간으로 받아볼 수 있게끔 개선하였습니다. <br><img alt="chatbotOudy.gif" src="lib/media/chatbotoudy.gif"><br><br>
먼저 SSE 뿐만 아니라, Polling 등 여러 관련된 방식을 포함하는 Event Streaming을 구현할 수 있는 여러 방법에 대해 알아봅시다.
<br><br><img src="https://i.imgur.com/VS9erwz.png" referrerpolicy="no-referrer"><br>
<br>주기적으로 클라이언트가 서버에 요청을 보냅니다. 
<br>서버는 데이터나 이벤트가 없으면 빈 값을, 있으면 값을 보내줍니다. 
<br><br>
<br>클라이언트에서 대기하는 시간이 길다면 실시간성이 떨어지고, 대기하는 시간이 짧다면 서버에 부담이 간다. 
<br><br><img src="https://i.imgur.com/jMlQ8Wo.png" referrerpolicy="no-referrer"><br>
<br>주기적으로 클라이언트가 서버에 요청을 보냅니ㅣ다. 
<br>서버는 바로 응답하는 것이 아닌, 데이터가 발생하거나, 타임아웃이 발생하면 클라이언트에 응답을 전달합니다. 
<br>클라이언트는 응답을 받은 후 대기를 하지 않고 바로 long poll 요청을 전달합니다. 
<br>쉽게 구현할 수 있습니다. 
<br>이벤트, 데이터가 생길 때 마다 응답을 돌려주기 때문에 실시간성이 높습니다. 
<br><br>
<br>요청과 응답 모두 독립적이기 때문에 header를 모두 포함합니다.<br>
--&gt; 원래는 하나의 http 응답입니다. 공통되는 요소를 반복해서 보내야하기 때문에 오버헤드가 발생합니다.
<br>클라이언트와 서버 모두 TCP/IP 연결을 연상태로 대기합니다.<br>
-&gt; 한정된 커넥션 풀과 관련된 리소스를 신경써야합니다.
<br>클라이언트에게 제공할 이벤트가 큐에 쌓이면 각각의 이벤트를 단건으로 여러개의 long poll 요청에 나눠서 전달해야합니다. 
<br>브라우저, gateway 등 다른 구성요소의 timeout을 고려하여 대기 시간을 설정해야합니다. 
<br><br>
클라이언트와 서버가 연결된 상태에서 지속적으로 데이터를 얻는 방식입니다.<br>
주로 비디오 스트리밍, 음악 스트리밍 등 대용량의 연속적인 데이터 전송에 사용됩니다. 
<br>
Long Polling과 다르게, 하나의 http 응답을 여러개의 http응답으로 나눠서 보내는 것이 아닌, http 응답을 잘게 짤라서(=chnuk 단위)보냅니다.
<br><br>
<br>
HTTP/1.1또는 HTTP/2를 사용할 수 있습니다 

<br>
HTTP/2의 경우 멀티플렉싱을 이용할 수 있습니다. 

<br>
클라이언트가 서버에 요청을 보냅니다. 

<br>
서버가 전달할 이벤트, 데이터 등이 있다면 응답의 일부분을 전달합니다. 

<br>
요청이나 연결을 닫지 않고 이벤트, 데이터를 전달할 때까지 대기합니다. 

<br><br>
동적으로 content를 생성하는 경우 정확한 Content-Length 를 미리 제공할 수 없기 때문에 아래의 방식으로 HTTP Streaming을 구현합니다. 
<br><br>
<br>Transfer-Encoding:chunked 를 헤더에 추가합니다. 
<br>텅 빈 chunk를 전달하기 전까지 값을 읽습니다. 
<br>Http/1.1 이상에서만 사용할 수 있습니다. 
<br><br>
<br>Connection: close 를 헤더에 추가합니다. 
<br>서버가 연결을 종료할때까지 들어오는 값을 읽습니다. 
<br><br>
이벤트 스트리밍을 단방향으로 언제든지 가능하게 합니다.<br>
텍스트 기반의 실시간 업데이트에 적합합니다. 
<br>
<br>이벤트 : 정의한 포멧에 따라 UTF-8f로 인코딩된 텍스트 데이터의 스트림 
<br><br><img src="https://i.imgur.com/LZEifhF.png" referrerpolicy="no-referrer"><br>
<br>클라이언트가 서버에 EventSource 객체를 사용해 연결을 엽니다. 
<br>서버는 text/event-stream MIME 타입을 사용해 이벤트를 전송합니다. 
<br>연결은 클라이언트가 끊을 때까지 지속합니다. 
<br><br>
<br>HTTP/1.1 을 사용합니다. 
<br><br><br>
관련된 기술로서 가장 먼저 생각나는 것은 웹소켓입니다. Websocket이 아닌, SSE를 선택한 이유는 크게 두가지였습니다. 
<br><br><br><img src="https://i.imgur.com/bV6f0SG.png" referrerpolicy="no-referrer"><br><br><img src="https://i.imgur.com/sFJBUBH.png" referrerpolicy="no-referrer"><br>특징을 정리해봅시다. SSE는 서버에서 데이터가 생성될 때마다 stream하는 단방향통신이고, websocket은 핸드 셰이크를 통해 커넥션을 수립하기 때문에 , 클라이언트와 서버 둘다 양방향 통신이 가능합니다. <br>Cloudy에서 제공하는 챗봇을 사용할 때 유저 플로우를 살펴봅시다. <br>1. 유저가 질문을 입력한다. 
2. 답변이 나올 때까지 기다린다. 
3. 답변을 받고나서 질문을 입력한다. 
Copy<br>기존 채팅의 유저 플로우를 살펴봅시다. <br>1. 유저가 질문을 입력한다. 
2. 답변이 나올때까지 기다린다. or 답변이 오기전 다른 대화 주제로 틀어버릴 수 있다. 

Copy<br>2번 과정을 비교해보겠습니다. 일반 사용자끼리의 채팅처럼 일상적인 대화의 경우, 상대방의 대화를 듣기 전 대화 주제가 변할 수 있습니다. 즉, 응답을 받고 있는 중에도 채팅을 보낼 수 있어야합니다. 하지만 Cloudy 처럼 QNA와 관련된 챗봇의 특성상 사용자가 질문을 하자마자 주제가 바뀔 우려는 거의 없습니다. 왜냐하면 사용자는 질문에 대해 답변을 받고 그 답변을 바탕으로 다른 질문을 생성해내기 때문입니다.<br>
즉, cloudy의 서비스 특성상, 사용자 입장에서는 답변이 생성되고 있는 중에, 다른 질문을 보내는 것보다는 완성된 답변을 읽고 답변의 내용을 바탕으로 다른 질문을 보낼 확률이 더 큽니다. 사실상 단방향 통신인 셈입니다. 때문에 서비스의 특성상 one-way communication을 지원하는 SSE로 챗봇을 구현하더라도 크게 상관 없겠다는 판단이 들었습니다. <br><br>웹소켓을 구현할 경우 고려하고 관리해야하는 범위가 늘어납니다. <br>
<br>웹소켓 핸드 셰이크를 위한 config 클래스 
<br>stomp 환경에서 작동할 수 있는 메시징 브로커 그 자체

<br>메시징 브로커와 관련된 Config 클래스들 


<br>채팅 publish와 로그 저장, 채팅 로그 조회 관련된 클래스 
<br>하지만 SSE를 활용하여 구현할 경우 Websocket보다는 고려하고 관리해야하는 범위가 좁습니다. <br>
<br>핸드 셰이크가 필요없이 단일한 REST API 하나를 이용해서 응답을 주고 받습니다. 
<br>메시징 브로커를 쓰지 않습니다.
<br>채팅 publish를 할 필요가 없으며 로그 저장 및 채팅 로그 조회 관련 클래스만 구현하면 됩니다, 
<br><br><img src="https://i.imgur.com/phuHdqN.png" referrerpolicy="no-referrer"><br>
<br>Chunked Transfer-Encoding 기반입니다. 
<br>chunk 단위로 여러 줄로 구성된 문자열을 전달합니다. 
<br>new line으로 이벤트를 구분합니다. 
<br>각각의 문자열은 일반적으로 &lt;field&gt;:&lt;value&gt; 형태로 구성됩니다. 
<br><br><br><br><br>
<br>클라이언트가 서버에 EventSource 객체를 사용해 연결을 엽니다. 
<br>서버는 text/event-stream MIME 타입을 사용해 이벤트를 전송합니다. 

<br>서버는 유저 질의를 OpenAI의 Streaming ChatModel을 사용하여 실시간으로 데이터를 받아들이고 이를 Reacive Stream 의 Fluxfh 반환합니다. 


<br>연결은 클라이언트가 끊을 때까지 지속합니다. 
<br><br>
응답을 Flux로 반환하기 때문에, Flux와 FluxSink에 대해서 알아보고 가겠습니다. 
<br><br>
0~N개의 데이터 항목을 비동기적으로 스트리밍하는 Publisher를 나타냅니다.<br>
데이터 스트림을 처리하고 변환하는 다양한 연산자를 제공합니다. 
<br><br>
Flux.create와 함께 사용하며, Flux의 데이터를 push 방식으로 제공할 수 있게끔합니다. 또한 Flux 스트림 내에서 데이터를 동적으로 생성하고 내보낼 수 있습니다. 
<br>
<br>next, complete, error 메서드를 오버라이딩하여 데이터를 전송하거나 스트림의 완료, 에러 시 처리를 커스텀할 수 있습니다. 
<br><br>
두 객체를 활용해 스트림을 동적으로 생성하고 데이터를 push할 수 있습니다.<br>
Flux.create 메서드는 FluxSink를 인자로 받아 데이터를 스트림에 공급할 수 있는 Flux를 생성합니다. 
<br><br>
클라이언트로 부터 유저 질의를 받아 실시간으로 생성되는 챗봇의 응답을 스트리밍하는 컨트롤러 입니다. 
<br>  

@PostMapping(produces = MediaType.TEXT_EVENT_STREAM_VALUE)
public Flux&lt;String&gt; generateChat(@RequestBody ChatReq question,   
								 @AuthenticationPrincipal Member member) {

	
	return chatBotService.question(question, member.getId());

}

Copy<br>produces = MediaType.TEXT_EVENT_STREAM_VALUE<br>
이 API의 반환 값이 text/event-stream MIME 타입임을 명시합니다. <br>Flux<br>
스트리밍 방식으로 여러개의 문자를 전송하기 위해서 Project Reactor의 Flux 타입을 사용합니다. <br><br>
Open AI의 Streaming Chat Model을 사용하여 실시간으로 데이터를 받아들이고, 이를 Reactive Streams의 Flux로 변환하여 반환합니다.
<br>

  

@Override
public Flux&lt;String&gt; generateStreamingChat(String template, 
										  Map&lt;String, Object&gt; variables, 
										  String userId, Chatbot chatbot) {

  

	Prompt prompt = getPrompt(template, variables);
	
	
	if (openAiStreamingChatModel == null) {
	openAiStreamingChatModel = OpenAiStreamingChatModel.builder()
								.apiKey(openAiKey)
								.modelName(GPT_3_5_TURBO)
								.build();
	}

  
  
  

	return Flux.create(emitter -&gt;
			openAiStreamingChatModel.generate(prompt.text(), 
			new StreamingResponseHandler&lt;&gt;() {
			
			  
			
			@Override
			public void onNext(String token) {
				emitter.next(token);
			}
			
			  
			
			@Override
			public void onComplete(Response&lt;AiMessage&gt; response) {
				chatQueryService.saveChat(userId, 
										 . chatbot, 
										   . response.content().text(), 
											false
										);
			
				emitter.complete();
			}
			
			  
			  
			
			@Override
			public void onError(Throwable error) {	
				log.error("[OpenAiChatService generateStreamingChat] 에러 발생 ::{}", error);
				emitter.next("에러가 발생했습니다. 관리자에게 문의하세요.");
				emitter.complete();
	
			}));

}
Copy<br>Flux.create<br>
Flux 스트림을 생성합니다. emitter는 FluxSink 객체로, 데이터 스트림을 내보낼 수 있습니다. Flux.create는 데이터를 생성하고 Flux.sink를 통해 비즈니스 로직을 제공받아 가공된 Flux를 생성합니다. <br>emitter<br>
FluxSink 인터페이스의 인스턴스입니다. 데이터를 Flux 스트림으로 내보냅니다. next, complete, error 등의 메서드를 오버라이딩하여 스트림을 제어할 수 있습니다. <br>StreamingResponseHandler<br>
Open AI의 스트리밍 응답을 처리하기 위해 해당 StreamingResponseHandler를 사용합니다. 이 핸들러를 사용하기 위해서는 onNext, onComplete, onError 3가지 메서드를 구현해야합니다. <br>onNext 메서드 <br>
실시간으로 생성되는 데이터를 수신했을 때 onNext 메서드를 호출합니다.<br>
emitter.next(token) 을 호출해 받은 데이터를 Flux 스트림으로 전달합니다. 
<br>@Override
public void onNext(String token) {
	emitter.next(token);
}

Copy<br>onComplete 메서드 <br>
스트리밍이 완료되었을 때 호출합니다. 
<br>@Override
public void onComplete(Response&lt;AiMessage&gt; response) {
    chatQueryService.saveChat(userId, 
							  chatbot, 
                              response.content().text(), 
                              false
                             );

    emitter.complete();
}

Copy<br>
<br>다음 접속시에 채팅 내역을 제공해야하기 때문에 Dynamo DB를 활용해 채팅 내용을 저장합니다. 
<br>emitter.complete()  를 호출하여 Flux 스트림을 활용합니다. 
<br>onError 메서드 <br>
스트리밍 중 에러가 발생했을 때 호출합니다. 
<br>
@Override
public void onError(Throwable error) {	
	log.error("[OpenAiChatService generateStreamingChat] 에러 발생 ::{}", error);
	emitter.next("에러가 발생했습니다. 관리자에게 문의하세요.");
	emitter.complete();
}));

Copy<br>원래는 emitter.error() 를 활용해 Publisher에서 에러를 발생시켜야합니다. 하지만, 특정 에러 응답을 반환하기 보다는, 서버에서 에러 로깅 후 클라이언트 대화창에서 바로 에러메시지를 출력하기로 구현 스펙을 결정했기 때문에 다음과 같은 비즈니스 로직으로 구현하였습니다. <br>
<br>에러를 로깅한다. 
<br>대화 로그에 에러 발생 메시지를 포함시킨다. 
<br>스트리밍을 종료한다. 
<br><br><br>Nginx의 디폴트 값<br>
Nginx는 기본적으로 업스트림 요청을 보낼 때, HTTP/1.0버전을 사용합니다. 하지만 SSE는 HTTP/1.1버전 부터 사용할 수 있습니다.<br>
또한 Connection:close 헤더를 사용합니다. SSE는 지속 연결이 되어 있어야하는데, Nginx에서 바로 지속연결을 닫아버리기 때문에 문제가 발생합니다. <br>변경된 설정값<br>proxy_set_header Connection '';
proxy_http_version 1.1;
Copy<br><br>Proxy Buffering이란<br>
클라이언트와 서버 중간에 위치한 Nginx는 트래픽 최적화를 위해, 요청 및 응답을 일시적으로 저장하고 처리합니다. <br>SSE와 Proxy Buffering의 관계<br>
SSE의 특성상 실시간으로 데이터를 스트리밍합니다. 이 스트리밍된 데이터는 바로바로 유저에게 전달되어야합니다. Proxy Buffering이 켜져있을 경우 Nginx가 서버의 응답을 일부 버퍼에 저장하고 버퍼가 차거나 응답 데이터를 모두 전송했을 경우 한번에 클라이언트로 전송합니다. 즉 원래 기능 명세대로, 한글자씩 반환하는 것이 아닌 몇 줄에 한번씩 클라이언트는 답변을 확인할 수 있어 실시간성이 떨어지게 됩니다. <br>X-Accel 활용하기<br>@PostMapping(produces = MediaType.TEXT_EVENT_STREAM_VALUE) 
public Flux&lt;String&gt; generateChat(@RequestBody ChatReq question, 
								 @AuthenticationPrincipal Member member, 
								 ServerHttpResponse response) { 
	log.info("{}", question); 
	headers = response.getHeaders(); 
	headers.add("X-Accel-Buffering", "no"); 
	return chatBotService.question(question, member.getId()); }
}
Copy<br>응답 헤더에 X-accel로 시작하는 헤더가 있으면 Nginx는 버퍼링을 수행하지 않습니다. &nbsp;SSE 응답을 반환하는 API의 헤더에&nbsp;X-Accel-Buffering: no를 붙여줘 SSE 응답만 버퍼링을 하지 않도록 설정하였습니다. <br><br><br>확인해야할 사항<br>
SSE 통신을 하는 동안에는 HTTP Connection이 계속 열려있습니다. 챗봇은 기본적으로 Dynamo DB에 채팅 로그를 저장합니다. HTTP 연결이 지속되는 동안에 DynamoDB 커넥션이 열려있는지 확인하는 과정이 필요합니다. <br>만약 커넥션이 열려있다면?<br>DynamoDB의 제약조건 (파티션)<br>
<br>초당 1k WCU(4kb/s or req/s)제공 
<br>초당 3k RCU(1kb/s or req/s) 제공 
<br>RCU와 WCU는 독립적으로 동작 
<br>10GB 
<br>Dynamo DB의 장점은 <br>Dynamo DB의 세벌복제 시스템 <br>
<br>데이터는 항상 3개의 가용영역에 복제됩니다. 
<br>서비스는 3개의 가용 영역에서 실행됩니다. 
]]></description><link>prj/cloudy/flux를-활용한-sse-구현기.html</link><guid isPermaLink="false">Prj/Cloudy/Flux를 활용한 SSE 구현기.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sat, 08 Jun 2024 03:35:09 GMT</pubDate><enclosure url="lib/media/chatbotoudy.gif" length="0" type="image/gif"/><content:encoded>&lt;figure&gt;&lt;img src="lib/media/chatbotoudy.gif"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[콘팅이 서비스를 잘게 쪼갠 이유]]></title><description><![CDATA[ 
 <br><br><br><img src="https://i.imgur.com/GT8yXth.png" referrerpolicy="no-referrer"><br><br>티케팅 서비스에서 가장 많은 트래픽이 발생하는 비즈니스 로직은 예매 과정이라 생각합니다. 저희 백엔드 팀의 목표는 예매 과정에서 최대한의 가용성을 보장하도록 시스템을 설계하고자 했습니다.<br>먼저 예매시 유저 플로우를 분석하였습니다.<br>먼저 콘팅의 예매시 유저 플로우를 알아보겠습니다. 다음과 같은 유저 플로우를 가집니다.<br>
<img src="https://i.imgur.com/BCFDYeB.png" referrerpolicy="no-referrer"><br><img src="https://i.imgur.com/FdOfVkH.png" referrerpolicy="no-referrer"><br>짧은 시간동안 여러 페이지를 옮겨 다니면서 다양한 API를 호출합니다. 해당 플플로우에서는 짧은 시간 내에 DB IO, Network IO가 대량으로 일어납니다. 짧은 시간 동안 시스템에서 일어나는 IO의 양이 많을 경우 가장 좋은 해결책은 비동기 방식이라 생각했습니다.<br>&lt;결제/티켓&gt; 도메인을 따로 분리한 이유<br>하지만 결제 시스템을 비동기 방식으로 적용하기에는 리스크가 크다고 생각했습니다. 국내 결제 시스템 특성상 PG 사와의 통신을 통해 결제 로직이 구현되고 관련된 트랜잭션을 고려한다면, 비동기는 적합하지 않습니다.<br>그렇다고 같은 프로젝트 내에서 r2dbc(비동기 방식 ORM)와 jpa(동기 방식 ORM)를 동시에 사용할 경우 각 구현체는 서로 다른 패키지에 포함되어야만하고 설정 클래스에서도 컴포넌트 스캔할 대상을 일일히 지정해야했기 때문에 코드간 결합성이 증가하고 유지보수하기가 어려워집니다.<br>R2DBC와 JPA/JDBC 용 repo를 같은 패키지 내에 배치하면 한쪽 Repo를 못찾거나 지원 예외가 발생합니다. 때문에 아래 코드와 같이 repo패키지를 분리후 각각의 repo 패키지를 설정해야합니다. 위 같은 방식은 repo의 개수가 늘어날 때마다 Config 클래스에 불필요한 보일러 플레이트를 생성합니다. 특히 레이어별로 정리한 폴더구조가 아닌 도메인별로 정리한 폴더 구조일 경우 *의 활용도 불가능합니다. <br>@EnableJpaRepositories("com.c209.payment.domain.order.repository.sync")
@EnableR2dbcRepositories("com.c209.payment.domain.order.repository.async")
Copy<br>로직에 알맞은 비동기 방식, 동기 방식을 구현하고, 코드의 유지보수성을 늘리고 확장성을 고려하여 “좌석”과 “결제/티켓” 도메인을 분할하였습니다.<br>대기열 서비스를 추가한 이유<br>
<img src="https://i.imgur.com/7Dcvgzu.png" referrerpolicy="no-referrer"><br>동기 방식을 채택한 “결제/티켓” 서비스의 핵심은 일정 트래픽이 넘지 않도록 제한해야합니다. 서비스 특성상 특정시간(예매 가능시간)이 되면 스파이크성 트래픽이 발생합니다. 스파이크성 트래픽이 발생할 경우, 동기 방식에서 치명적이라 판단하였습니다. 스파이크성 트래픽이 결제 서비스에 발생하는 것을 방지하기 위해, 대기열 서버를 추가하였습니다. 결제시 유저 플로우는 다음과 같이 바뀝니다.<br><img src="https://i.imgur.com/QLW8HpK.png" referrerpolicy="no-referrer"><br>결제와 티켓 도메인을 분할한 이유<br>서비스 특성상 결제와 티켓 발행 로직은 같은 서비스에 처리하여 트랜잭션을 보장하는 것이 맞습니다. 하지만 콘팅에서는 QR 기반 티켓을 제공합니다. 티켓의 검표과정 또한 처리해야하기 때문에 다음과 같은 특수한 상황에서 문제가 발생합니다.<br>A 가수의 공연 예매일과 B가수의 공연 당일이 겹쳤을 경우 
Copy<br>A가수의 공연을 예매하기 위해서 결제 API가 요청이, B가수의 티켓 검표를 진행하기 위해 티켓 API 요청이 동시에 발생합니다. 위와 같은 상황을 가정했을 때, 티켓 서비스와 결제 서비스를 안정적으로 처리하기 위해 두 서비스를 분리하였습니다.<br><br><br>서비스를 분할할수록 비즈니스 로직에 따라 서비스 간의 데이터 정합성을 맞추는 것이 중요합니다.<br>
<br>kafka를 활용한 비동기 큐로 결제서비스가 pub, 좌석 서비스와 티켓서비스가 Sub으로 구현하였습니다. 결제 발생시 좌석 서비스에서는 결제된 좌석이&nbsp;사용 불가능한 좌석으로 업데이트, 티켓 서비스는&nbsp;구매 유저와 좌석 정보를 바탕으로 티켓을 생성합니다.
<br>최종 결제 수행 전 webhook을 활용해 해당 좌석이&nbsp;여전히 구매 가능한 좌석인지 좌석 서비스에서 조회하는 로직을 추가했습니다.
<br><br>콘팅에서는 카프카를 비동기 메시징 큐로 활용합니다. 카프카는 분산 스트리밍 플랫폼으로, 대량의 데이터를 처리하고 실시간으로 전송하는 데 사용합니다. 모든 데이터는 로그 형식으로 파일 시스템에 기록됩니다. 시간순으로 완전히 정렬된 데이터 흐름(=레코드 시퀀스)를 보장합니다. 로그를 한곳에 모아 처리할 수 있도록 중앙집중화되어 있으며, 대용량 데이터를 수집하고 실시간 스트리밍으로 소비할 수 있습니다. <br>레코드는 프로듀서가 보낸 순서로 기록되어 순서가 보장됩니다. 레코드의 위치(offset)으로 컨슈머가 소비한 메시지의 위치를 표시합니다. 각 컨슈머 그룹마다 레코드의 위치를 가지고 있기 때문에 같은 소스에서 서로 다른 여러 개의 컨슈머들이 개별적으로 소비할 수 있습니다. 한 소스에서 여러 소비자가 손실이나 변형 없이 메시지를 소비할 수 있습니다. <br><img src="https://i.imgur.com/zefHRap.png" referrerpolicy="no-referrer"><br><br><br>결제와 티켓 발급을 처리하는 방식으로 분산 시스템 이벤트 기반 아키텍처를 사용하고 있습니다. 콘팅의 분산시스템이 어떻게 나뉘어 있는지 간략하게 설명하고, 카프카를 팀에서 활용하는 방식을 소개하겠습니다. <br>결제 이벤트를 받아 티켓을 발급하는 로직, 결제 이벤트를 받아 <br><br>DB가 분리되면서 편하게 join이 불가능해집니다. join 쿼리가 발생할 경우 network io가 추가로 발생하게 됩니다. 관련해서 문제가 발생하는 API가 있었습니다. 바로 내가 가지고 있는 입장권 조회입니다.<br>
<img src="https://i.imgur.com/JO9ZjAV.png" referrerpolicy="no-referrer"><br>내가 가진 입장권을 출력하기 위해서는 티켓 서비스에서 user_id로 내가 가진 티켓 정보(공연 id, 좌석 id)를 조회해와야합니다.<br>
<img src="https://i.imgur.com/8ds8OTw.png" referrerpolicy="no-referrer"><br>select seat_id, performance_id from ticket where user_id = :userId
Copy<br>조회해온 seat_id와 performance_id로 카탈로그 서비스 API에서 공연 정보를 조회해야합니다.<br>select {공연 메타데이터 칼럼들} from performance 
where performance_id in {앞선 쿼리에서 조회한 performance_id들}
Copy<br>보시는 바와 같이, 서비스간 결합성이 생기고 불필요한 네트워크 IO와 DB IO가 발생합니다. 이를 해결하기 위해서 모바일 로컬 DB인 Realm을 활용했습니다.<br>스플래시 화면에서 공연 정보를 먼저 조회해와 realm에 저장합니다.<br>
<img src="https://i.imgur.com/clIDFvq.png" referrerpolicy="no-referrer"><br>사용자가 입장권 페이지에 접속할 때는 단순히 티켓 서비스에서 내가 가지고 있는 티켓의 공연 id만 조회해온 후 realm에서 공연 데이터를 찾아 페이지를 렌더링하는 방식으로 구현했습니다.<br><img src="https://i.imgur.com/MXyEUyE.png" referrerpolicy="no-referrer">]]></description><link>prj/conting/콘팅이-서비스를-잘게-쪼갠-이유.html</link><guid isPermaLink="false">Prj/Conting/콘팅이 서비스를 잘게 쪼갠 이유.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sat, 08 Jun 2024 04:21:55 GMT</pubDate><enclosure url="https://i.imgur.com/GT8yXth.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/GT8yXth.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[ALB - Application Load Balancer]]></title><description><![CDATA[ 
 <br><br>
7계층에서 동작하는 로드밸런서 입니다. 트래픽을 균형있게 나누어줍니다.
<br><br>
트래픽을 여러 대상에 자동으로 분산시켜 안정적인 운용을 할 수 있습니다.
<br>
<br>EC2뿐만 아니라 컨테이너(ECS), 서버리스(Lambda) 등으로 다양한 서비스와 연계하여 부하를 분배할 수 있습니다.<br>

<br>서로 다른 EC2에 대한 하나의 엔드포인트를 제공합니다.<br>

<br>부하 분산 대상에 대한 헬스 체크, 고정 세션, ssl Offload, 다운서버 제외 기능을 제공합니다.<br>

<br><br><img src="https://hanju.gitbook.io/~gitbook/image?url=https%3A%2F%2F102830355-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FfNpWAsJfDNQXNBCChExd%252Fuploads%252FuEVaLGfjsShiUrHBYllh%252Fimage.png%3Falt%3Dmedia%26token%3Df5a11a54-fadd-49e5-ad48-5973920829bc&amp;width=768&amp;dpr=4&amp;quality=100&amp;sign=af6f198d520aed36cd5bd6b758108b905fd27ff37c455b31fa04467eb73f43e1" referrerpolicy="no-referrer"><br><a rel="noopener" class="external-link" href="https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/introduction.html" target="_blank">https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/introduction.html</a><br>
<br>
위 사진과 같이 Load Balancer, Listener, Target Group으로 나누어져 있습니다.

<br>
기본적으로 VPC에 탑재되며 사용자 요청을 받고, 이를 VPC 내의 리소스에 적절히 부하분산합니다.

<br>
외부의 요청을 받아들이는 리스너, 요청을 분산 전달할 수 있는 리소스의 집합인 대상그룹으로 구성됩니다.

<br>
ELB는 다수의 리스너와 대상 그룹을 거느릴 수 있습니다.

<br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/alb-application-load-balancer/undefined" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/alb-application-load-balancer/undefined" target="_blank">PAGE구성요소</a><br><br>
<br>
앱의 트래픽을 여러 가용영역으로 분산합니다.

<br>
리스너를 이용해 RL, 호스트, 헤더, 메소드를 기반으로 규칙을 구성하여 요청을 처리할 수 있습니다.

<br>
트래픽 부하에 따라 자동으로 스케일 업, 다운을 수행할 수 있습니다.

<br>
하나 이상 타겟 그룹에 라우팅할 수 있으며 각 그룹별 가중치 설정이 가능합니다.

<br>
SSL Offloading을 지원합니다.

<br>
디폴트 알고리즘은 라운드 로빈이며, 최소 미해결 요청 라우팅 알고리즘을 지원합니다.

<br>
교차 영역 로드 밸런싱을 통해 AZ의 모든 타겟 그룹에 트래픽을 분산합니다.

<br><a data-href="고가용성 및 스케일링" href="고가용성 및 스케일링" class="internal-link" target="_self" rel="noopener">고가용성 및 스케일링</a>]]></description><link>0.-aws/1.-고가용성-및-스케일링/alb/alb.html</link><guid isPermaLink="false">0. AWS/1. 고가용성 및 스케일링/ALB/ALB.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 07:09:51 GMT</pubDate><enclosure url="https://hanju.gitbook.io/~gitbook/image?url=https%3A%2F%2F102830355-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FfNpWAsJfDNQXNBCChExd%252Fuploads%252FuEVaLGfjsShiUrHBYllh%252Fimage.png%3Falt%3Dmedia%26token%3Df5a11a54-fadd-49e5-ad48-5973920829bc&amp;width=768&amp;dpr=4&amp;quality=100&amp;sign=af6f198d520aed36cd5bd6b758108b905fd27ff37c455b31fa04467eb73f43e1" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="https://hanju.gitbook.io/~gitbook/image?url=https%3A%2F%2F102830355-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FfNpWAsJfDNQXNBCChExd%252Fuploads%252FuEVaLGfjsShiUrHBYllh%252Fimage.png%3Falt%3Dmedia%26token%3Df5a11a54-fadd-49e5-ad48-5973920829bc&amp;width=768&amp;dpr=4&amp;quality=100&amp;sign=af6f198d520aed36cd5bd6b758108b905fd27ff37c455b31fa04467eb73f43e1"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[고가용성]]></title><description><![CDATA[<a class="tag" href="?query=tag:AWS" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#AWS</a> 
 <br><br><br>
고가용성은 시스템이 예상치 못한 장애나 문제에도 계속해서 가용하고 작동하는 능력을 가리킵니다. 이는 시스템의 가용성을 유지하기 위해 여러 가용 영역에 걸쳐 리소스를 분산하는 등의 방법을 포함할 수 있습니다.
<br><br><br>
스케일링은 시스템이 사용자 또는 트래픽 증가에 유연하게 대응할 수 있는 능력을 의미합니다. 이는 자동으로 리소스를 확장하거나 축소하여 수요에 맞게 조정하는 것을 포함할 수 있습니다.
<br><br><br>
<br>Elastic Load Balancing (ELB):

<br>고가용성: ELB는 여러 가용 영역에 걸쳐 로드 밸런싱을 수행하여 장애 발생 시에도 트래픽을 안정적으로 분산합니다.
<br>스케일링: ELB는 Auto Scaling 그룹과 통합하여 자동으로 인스턴스를 확장하거나 축소하여 트래픽에 대응합니다.


<br>Amazon EC2 Auto Scaling:

<br>고가용성: Auto Scaling은 여러 가용 영역에 인스턴스를 배포하여 고가용성을 제공하며, 인스턴스 장애 시 자동으로 대체 인스턴스를 시작합니다.
<br>스케일링: Auto Scaling은 정의된 조건에 따라 자동으로 인스턴스를 확장하거나 축소하여 트래픽에 대응합니다.


<br>Amazon RDS Multi-AZ (Multi-Availability Zone) Deployment:

<br>고가용성: RDS Multi-AZ는 프라이머리 데이터베이스와 스탠바이 데이터베이스를 여러 가용 영역에 걸쳐 설정하여 장애 발생 시 자동으로 스위치하여 가용성을 제공합니다.
<br>스케일링: RDS는 수동 또는 자동 스케일링을 통해 데이터베이스 인스턴스의 크기를 조정할 수 있습니다.


<br><a data-href="ALB" href="0.-aws/1.-고가용성-및-스케일링/alb/alb.html" class="internal-link" target="_self" rel="noopener">ALB</a><br><a href=".?query=tag:AWS" class="tag" target="_blank" rel="noopener">#AWS</a>]]></description><link>0.-aws/1.-고가용성-및-스케일링/1.-고가용성-및-스케일링.html</link><guid isPermaLink="false">0. AWS/1. 고가용성 및 스케일링/1. 고가용성 및 스케일링.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 10:42:07 GMT</pubDate></item><item><title><![CDATA[0 CloudFormation]]></title><description><![CDATA[ 
 <br>1.Cloud Formation이란?<br>
AWS 리소스 생성 및 배포 자동화 템플릿 서비스입니다.
<br>
<br>AWS 리소스를 모델링하고 설정합니다.

<br>리소스 관리 시간을 줄일 수 있습니다.


<br>AWS 리소스를 설명하는 템플릿(=코드)를 생성하면 리소스의 프로비저닝과 구성을 담당합니다.
<br><br><br><img src="https://hanju.gitbook.io/~gitbook/image?url=https%3A%2F%2F102830355-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FfNpWAsJfDNQXNBCChExd%252Fuploads%252FSGEXGnQfYFl1GV94AXeZ%252Fimage.png%3Falt%3Dmedia%26token%3Dbc8a4eca-5c7a-4f79-bdfa-432e12b2e396&amp;width=768&amp;dpr=4&amp;quality=100&amp;sign=c1ce24f89c350ac9d93c8516d900243166fce2b0bc7954435800b0b33facf49a" referrerpolicy="no-referrer"><br>
<br>Cloud Front에서 실행하는 호출은 모두 템플릿으로 선언됩니다.
<br>해당 템플릿을 local이나 S3에 저장합니다.
<br>Cloudformation에서 템플릿을 활용해 AWS 리소스를 생성하고 스택을 생성합니다.
<br><br><br><br>
리소스 모음을 단일 단위(스택)으로 쉽게 관리할 수 있습니다.
<br><br>
각 개별 서비스를 사용하여 프로비저닝해야하고 서비스간 연동을 진행해야합니다. 모든 작업을 마치고 애플리케이션을 제대로 실행하려면 복잡하고 많은 시간이 소요됩니다.
<br><br>
모든 리소스와 속성을 설명하는 템플릿을 사용합니다. 템플릿을 사용하여 Cloudfront에서 스택을 생성할 경우 필요한 서비스를 자동으로 프로비저닝합니다. 스택의 삭제, 관리가 용이합니다.
<br><br>
가용성을 확대해야하는 경우 여러 리전에서 애플리케이션을 복제할 수 있습니다.
<br><br>
복제시, 애플리케이션에 필요한 모든 AWS 서비스를 숙지, 각 리전에서 해당 서비스를 다시 구성해야합니다.
<br><br>
템플릿을 재사용하여 리소스를 일관되고 반복적으로 생산할 수 있습니다. 또한 여러 리전에서 동일한 리소스를 반복적으로 프로비저닝할 수 있습니다.
<br><br><br>
애플리케이션을 업데이트하고 문제가 발생할 경우 원래 설정으로 롤백해야합니다.<br>
변경된 리소스를 기억하고 원래 설정을 알고 다시 수동으로 복구해야합니다.
<br><br>
템플릿에서 차이점을 추적하여 인프라 변경사항을 추적할 수 있습니다. 형상관리시스템(git)을 활용하여 변경 내용, 변경 시간, 변경한 사람을 정확히 알 수 있습니다. 이전 버전으로 되돌려야할 경우 이전 버전의 템플릿을 사용하면 됩니다.
<br><br><br>
<br>
리소스에 대한 이해가 낮으면 사용하기가 어렵습니다.

<br>
배포에 필요한 모든 옵션을 직접 활용하기에는 설정이 많습니다.<br>


<br>
json, yaml 문법에서 각 참조 방식이 난해합니다.

<br>java같은 곳에서는 ctrl 키를 눌러 해당 함수의 구현체로 바로 이동이 가능합니다.
<br>반면에 json은 데이터를 표현하는 포멧이기 때문에 참조값 추적이 난해합니다.


<br>]]></description><link>0.-aws/1.-iac/cloudformation/0-cloudformation.html</link><guid isPermaLink="false">0. AWS/1. IaC/CloudFormation/0 CloudFormation.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 10:42:28 GMT</pubDate><enclosure url="https://hanju.gitbook.io/~gitbook/image?url=https%3A%2F%2F102830355-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FfNpWAsJfDNQXNBCChExd%252Fuploads%252FSGEXGnQfYFl1GV94AXeZ%252Fimage.png%3Falt%3Dmedia%26token%3Dbc8a4eca-5c7a-4f79-bdfa-432e12b2e396&amp;width=768&amp;dpr=4&amp;quality=100&amp;sign=c1ce24f89c350ac9d93c8516d900243166fce2b0bc7954435800b0b33facf49a" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="https://hanju.gitbook.io/~gitbook/image?url=https%3A%2F%2F102830355-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FfNpWAsJfDNQXNBCChExd%252Fuploads%252FSGEXGnQfYFl1GV94AXeZ%252Fimage.png%3Falt%3Dmedia%26token%3Dbc8a4eca-5c7a-4f79-bdfa-432e12b2e396&amp;width=768&amp;dpr=4&amp;quality=100&amp;sign=c1ce24f89c350ac9d93c8516d900243166fce2b0bc7954435800b0b33facf49a"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[스택]]></title><description><![CDATA[ 
 <br><br>
CloudFormation에서는 스택이라는 하나의 단위로 리소스들을 관리합니다.
<br><br>
<br>스택이라는 하나의 단위로 리소스를 관리합니다.<br>

<br>스택의 모든 리소스는 스택의 CloudFormation 템플릿으로 정의합니다.<br>

<br>스택에서 실행 중인 리소스를 변경해야하는 경우 스택을 업데이트합니다.<br>

<br><br>
스택의 설정을 변경하거나 리소스를 변경하는 경우 스택 업데이트를 이용해서 간편하게 변경할 수 있습니다.
<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-1" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-1" target="_blank"></a><br>2-1. 원리<br>
<br>변경사항(새 입력 파라미터 값 또는 업데이트된 템플릿)을 작성합니다.
<br>CloudFormation에서는 제출한 변경사항과 스택의 현재 상태를 비교하여 변경된 리소스만 업데이트합니다.
<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-2" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-2" target="_blank"></a><br>2-2. 업데이트 방법<br>
직접 업데이트와 변경 세트 생성 및 실행 총 두 가지 방법을 제공합니다.
<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#a" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#a" target="_blank"></a><br>a. 스택을 직접 업데이트<br>
<br>변경사항을 제출합니다.<br>

<br>AWS CloudFormation에서 즉시 해당사항을 배포합니다.<br>

<br>업데이트를 빠르게 배포할 때 사용합니다.<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#b" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#b" target="_blank"></a><br>b. 변경 세트 사용<br>
<br>AWS CloudFormation에서 스택에 대해 변경사항을 미리 확인합니다.
<br>변경사항을 적용할지 결정합니다.
<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-3" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-3" target="_blank"></a><br>2-3 스택 리소스의 업데이트 동작<br>
업데이트한 리소스의 경우 AWS CloudFormation에서는 다음 동작 중 하나를 사용합니다.
<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#a-1" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#a-1" target="_blank"></a><br>a.업데이트(무중단)<br>
해당 리소스의 작동을 중단하지 않고, 리소스의 물리적 ID를 변경하지 않는 상태에서 리소스를 업데이트합니다.
<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#b-1" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#b-1" target="_blank"></a><br>b.업데이트(중단)<br>
리소스를 업데이트하지만, 다소 중단이 발생합니다.
<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#c" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#c" target="_blank"></a><br>c.대체<br>
업데이트 도중 리소스를 다시 생성하며, 물리적 ID도 생성합니다.
<br>일반적인 방법은 아래와 같습니다.<br>
<br>리소스를 먼저 생성합니다.
<br>대체 리소스를 가리키도록 종속 리소스의 참조를 변경합니다
<br>이전 리소스를 삭제합니다.
<br>AWS 리소스 유형에 따라 업데이트하는 속성이 달라집니다. 각 속성에 대한 업데이트 동작은 <a data-tooltip-position="top" aria-label="https://docs.aws.amazon.com/ko_kr/AWSCloudFormation/latest/UserGuide/aws-template-resource-type-ref.html" rel="noopener" class="external-link" href="https://docs.aws.amazon.com/ko_kr/AWSCloudFormation/latest/UserGuide/aws-template-resource-type-ref.html" target="_blank">AWS 리소스 유형 참조</a>에 설명되어 있습니다.<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-3.-aws" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-3.-aws" target="_blank"></a><br>2-3. AWS 리소스를 대체해야하는 경우 설정하기<br>
RDS의 Port를 업데이트하는 경우 CloudFormation에서는 업데이트된 포트 설정을 사용하여 새 DB 인스턴스를 생성하고 대체하여 무중단 배포를 구성할 수 있습니다. 방법은 아래와 같습니다.
<br>
<br>현재 DB의 스냅샷을 생성합니다.
<br>DB 인스턴스를 바꾸는 동안 해당 DB를 사용하는 앱에서 중단을 처리할 방법을 준비합니다.
<br>앱에서 업데이트된 포트 설정과 기타 고려사항이 적용되었는지 확인합니다.
<br>DB 스냅샷을 사용하여 새 DB 인스턴스에서 정보를 복원합니다.
]]></description><link>0.-aws/1.-iac/cloudformation/스택.html</link><guid isPermaLink="false">0. AWS/1. IaC/CloudFormation/스택.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 06:53:02 GMT</pubDate></item><item><title><![CDATA[템플릿이란?]]></title><description><![CDATA[ 
 <br><br><br>
AWS 리소스 구축을 위한 청사진입니다.
<br>
<br>.json, .yaml, .template, .txt 등을 사용합니다.
<br><br><br>
ami-0ff8a91507f77f867 AMI ID, t2.micro 인스턴스 유형, testkey 키 페어 이름 및 Amazon EBS 볼륨을 사용하여 인스턴스를 프로비저닝하는 예시입니다.
<br><br>{
    "AWSTemplateFormatVersion": "2010-09-09",
    "Description": "A sample template",
    "Resources": {
        "MyEC2Instance": {
            "Type": "AWS::EC2::Instance",
            "Properties": {
                "ImageId": "ami-0ff8a91507f77f867",
                "InstanceType": "t2.micro",
                "KeyName": "testkey",
                "BlockDeviceMappings": [
                    {
                        "DeviceName": "/dev/sdm",
                        "Ebs": {
                            "VolumeType": "io1",
                            "Iops": 200,
                            "DeleteOnTermination": false,
                            "VolumeSize": 20
                        }
                    }
                ]
            }
        }
    }
}
Copy<br><br>AWSTemplateFormatVersion: 2010-09-09
Description: A sample template
Resources:
  MyEC2Instance:
    Type: 'AWS::EC2::Instance'
    Properties:
      ImageId: ami-0ff8a91507f77f867
      InstanceType: t2.micro
      KeyName: testkey
      BlockDeviceMappings:
        - DeviceName: /dev/sdm
          Ebs:
            VolumeType: io1
            Iops: 200
            DeleteOnTermination: false
            VolumeSize: 20
Copy<br><br><br>
템플릿에는 여러 주요 섹션이 포함되어 있습니다.
<br>
<br>Resources 섹션만 필수 섹션입니다.<br>

<br><br>
기본적으로는 임의 순서대로 지정이 가능하지만, 이전 섹션을 참고할 수 있습니다. 때문의 다음 순서를 사용하는 것이 좋습니다.
<br><br><br><br><br>
AWSTemplateFormatVersion 섹션은 템플릿의 기능을 식별합니다. 최신 템플릿 포맷 버전은 2010-09-09이며 현재 유일한 유효 값입니다.
<br>
<br>값을 지정하지 않을 경우 최신 버전이라고 가정합니다.<br>

<br>리터럴 문자이어야합니다.<br>

<br>파라미터나 함수를 사용해 포맷 버전을 지정할 수 있습니다.<br>

<br><br>"AWSTemplateFormatVersion" : "2010-09-09"
Copy<br><br>AWSTemplateFormatVersion: "2010-09-09"
Copy<br><br>
템플릿의 Description 섹션(선택 사항)에 템플릿에 대한 설명을 지정합니다.
<br>
<br>0~1023 바이트 길이의 리터럴 문자열이어야 합니다.
<br>파라미터나 함수를 사용할 수 없습니다.
<br>업데이트 중 수정이 불가능합니다.
<br><br>"Description" : "Here are some details about the template."
Copy<br><br>Description: &gt;
  Here are some
  details about
  the template.
Copy]]></description><link>0.-aws/1.-iac/cloudformation/템플릿.html</link><guid isPermaLink="false">0. AWS/1. IaC/CloudFormation/템플릿.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 07:01:53 GMT</pubDate></item><item><title><![CDATA[<font color="#8064a2">IaC Overview</font>]]></title><description><![CDATA[<a class="tag" href="?query=tag:AWS" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#AWS</a> 
 <br><br><br>IaC는 "Infrastructure as Code"의 약자로, 인프라스트럭처를 코드로 정의하고 관리하는 방식을 가리킵니다. 이는 개발자나 시스템 관리자가 코드를 사용하여 인프라 리소스를 프로비저닝하고 구성하는 것을 의미합니다.<br><br><br>
<br>
일관성: 코드로 정의된 인프라는 반복 가능하며, 인프라 구성이 일관되고 예측 가능하게 됩니다.

<br>
자동화: 코드를 통해 인프라를 프로비저닝하고 구성함으로써, 반복적이고 수동적인 작업을 자동화할 수 있습니다.

<br>
버전 관리: 코드로 정의된 인프라는 버전 관리 시스템을 통해 관리될 수 있으며, 변경 이력을 추적하고 롤백할 수 있습니다.

<br>
안정성: IaC를 사용하면 실수를 줄이고, 변경 사항에 대한 테스트 및 검증을 수행할 수 있으므로 시스템의 안정성이 향상됩니다.

<br>
유연성: 코드로 정의된 인프라는 변경에 대응하기 쉽습니다. 새로운 요구 사항이나 확장성이 필요한 경우 코드를 수정하여 인프라를 업데이트할 수 있습니다.

<br><br><br>주요한 IaC 도구로는 AWS CloudFormation, Terraform, Ansible, Chef, Puppet 등이 있습니다. 이러한 도구들을 사용하여 개발자와 운영팀은 코드를 통해 인프라를 효율적으로 관리하고 운영할 수 있습니다.<br><a href=".?query=tag:AWS" class="tag" target="_blank" rel="noopener">#AWS</a><br><a data-href="0 CloudFormation" href="0.-aws/1.-iac/cloudformation/0-cloudformation.html" class="internal-link" target="_self" rel="noopener">0 CloudFormation</a>]]></description><link>0.-aws/1.-iac/1.-iac.html</link><guid isPermaLink="false">0. AWS/1. IaC/1. IaC.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 14:40:31 GMT</pubDate></item><item><title><![CDATA[AWS]]></title><description><![CDATA[<a class="tag" href="?query=tag:Root" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#Root</a> 
 <br><br>AWS는 "Amazon Web Services"의 약자로, 아마존이 제공하는 클라우드 컴퓨팅 플랫폼 및 서비스를 가리킵니다. AWS는 인프라스트럭처(서버, 스토리지, 네트워킹 등)부터 데이터베이스, 인공지능, 머신 러닝, 개발 도구, 보안, 분석, 그리고 IoT와 같은 다양한 기술 스택을 제공합니다. 이를 통해 기업이나 개발자들은 필요한 인프라를 프로비저닝하고 애플리케이션을 배포하며, 스케일링하고 관리하는 등의 작업을 AWS의 클라우드 플랫폼을 통해 수행할 수 있습니다. <br><br>
<br>확장성 및 유연성: AWS는 필요에 따라 리소스를 확장하거나 축소할 수 있는 유연한 인프라를 제공합니다. 개발자는 애플리케이션의 수요가 변할 때 쉽게 대응할 수 있습니다.
<br>다양한 서비스: AWS는 다양한 서비스를 제공하여 개발자가 필요로 하는 모든 것을 하나의 플랫폼에서 제공합니다. 데이터베이스, 스토리지, 컴퓨팅, 인공지능, 머신 러닝, 보안, IoT 등의 다양한 서비스를 활용할 수 있습니다.
<br>비용 효율성: AWS는 사용한 만큼 비용을 지불하는 Pay-As-You-Go 모델을 채택하고 있어, 개발자는 실제로 사용한 리소스에 대해서만 비용을 지불하게 됩니다. 또한 예약 인스턴스 및 스팟 인스턴스와 같은 할인 모델도 제공하여 비용을 절감할 수 있습니다.
<br>보안: AWS는 업계 표준을 준수하며, 다양한 보안 도구 및 서비스를 제공하여 개발자가 애플리케이션을 안전하게 운영할 수 있도록 지원합니다. 이는 데이터 보안, 네트워크 보안, 액세스 제어 및 모니터링 등을 포함합니다.
<br>글로벌 인프라: AWS는 전 세계에 걸쳐 다양한 리전과 가용 영역을 제공하여 개발자가 애플리케이션을 전 세계적으로 배포하고 사용자에게 접근할 수 있도록 합니다.
<br>자동화 및 관리: AWS는 다양한 자동화 도구와 관리 서비스를 제공하여 개발자가 애플리케이션을 효율적으로 관리하고 유지보수할 수 있도록 지원합니다. 예를 들어, AWS Elastic Beanstalk, AWS Lambda, AWS CloudFormation 등의 서비스를 통해 개발 및 배포 과정을 자동화할 수 있습니다.
<br><a data-href="1. 고가용성 및 스케일링" href="0.-aws/1.-고가용성-및-스케일링/1.-고가용성-및-스케일링.html" class="internal-link" target="_self" rel="noopener">1. 고가용성 및 스케일링</a><br>
<a data-href="1. IaC" href="0.-aws/1.-iac/1.-iac.html" class="internal-link" target="_self" rel="noopener">1. IaC</a><br><a href=".?query=tag:Root" class="tag" target="_blank" rel="noopener">#Root</a>]]></description><link>0.-aws/0.-aws.html</link><guid isPermaLink="false">0. AWS/0. AWS.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 14:40:47 GMT</pubDate></item><item><title><![CDATA[구조 패턴]]></title><description><![CDATA[ 
 <br><br>
클래스와 객체를 효율적으로 구성하여 더 큰 구조를 형성하고, 서로 간의 관계를 단순화하고 유연하게 만드는 디자인 패턴의 한 유형입니다.
<br><br>
<br><a data-href="데코레이터" href="0.-clean-code/1.-design-pattern/2.-구조-패턴/데코레이터.html" class="internal-link" target="_self" rel="noopener">데코레이터</a>: 객체에 동적으로 새로운 행동이나 상태를 추가할 수 있게 해주는 패턴.
<br><a data-href="복합체" href="0.-clean-code/1.-design-pattern/2.-구조-패턴/복합체.html" class="internal-link" target="_self" rel="noopener">복합체</a>(Composite): 객체들을 트리 구조로 구성하여 부분-전체 계층을 구현하고, 개별 객체와 복합 객체를 동일하게 다루는 패턴.
<br><a data-href="브리지" href="0.-clean-code/1.-design-pattern/2.-구조-패턴/브리지.html" class="internal-link" target="_self" rel="noopener">브리지</a>(Bridge): 추상적인 부분과 구체적인 구현 부분을 분리하여 독립적으로 변형할 수 있게 해주는 패턴.
<br><a data-href="어댑터" href="0.-clean-code/1.-design-pattern/2.-구조-패턴/어댑터.html" class="internal-link" target="_self" rel="noopener">어댑터</a> (Adapter): 기존 인터페이스를 다른 인터페이스로 변환하여 호환되지 않는 인터페이스들 간의 협력을 가능하게 해주는 패턴.
<br><a data-href="파사드" href="0.-clean-code/1.-design-pattern/2.-구조-패턴/파사드.html" class="internal-link" target="_self" rel="noopener">파사드</a> (Facade): 서브시스템에 대한 간단한 인터페이스를 제공하여 복잡한 서브시스템을 쉽게 사용할 수 있게 해주는 패턴.
<br><a data-href="프록시" href="0.-clean-code/1.-design-pattern/2.-구조-패턴/프록시.html" class="internal-link" target="_self" rel="noopener">프록시</a> (Proxy): 다른 객체에 대한 접근을 제어하기 위해 대리자나 자리 채움 객체를 제공하는 패턴.
<br><a data-href="플라이웨이트" href="0.-clean-code/1.-design-pattern/2.-구조-패턴/플라이웨이트.html" class="internal-link" target="_self" rel="noopener">플라이웨이트</a> (Flyweight): 다수의 작은 객체들을 효율적으로 지원하기 위해 공유를 통해 메모리를 절약하는 패턴.
<br> : ]]></description><link>0.-clean-code/1.-design-pattern/2.-구조-패턴/2.-구조-패턴.html</link><guid isPermaLink="false">0. Clean Code/1. Design Pattern/2. 구조 패턴/2. 구조 패턴.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 12:00:12 GMT</pubDate></item><item><title><![CDATA[데코레이터]]></title><description><![CDATA[ 
 ]]></description><link>0.-clean-code/1.-design-pattern/2.-구조-패턴/데코레이터.html</link><guid isPermaLink="false">0. Clean Code/1. Design Pattern/2. 구조 패턴/데코레이터.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 11:05:49 GMT</pubDate></item><item><title><![CDATA[플라이웨이트]]></title><description><![CDATA[ 
 ]]></description><link>0.-clean-code/1.-design-pattern/2.-구조-패턴/플라이웨이트.html</link><guid isPermaLink="false">0. Clean Code/1. Design Pattern/2. 구조 패턴/플라이웨이트.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 11:06:02 GMT</pubDate></item><item><title><![CDATA[생성 패턴]]></title><description><![CDATA[ 
 <br><br>
객체 생성 메커니즘을 다루는 디자인 패턴의 한 유형입니다.
<br><br>
<br><a data-href="빌더" href="0.-clean-code/1.-design-pattern/2.-생성-패턴/빌더.html" class="internal-link" target="_self" rel="noopener">빌더</a> (Builder): 객체의 생성 과정을 단계별로 나누고, 다양한 표현을 통해 동일한 생성 절차를 수행할 수 있게 하는 패턴.
<br><a data-href="싱글톤" href="0.-clean-code/1.-design-pattern/2.-생성-패턴/싱글톤.html" class="internal-link" target="_self" rel="noopener">싱글톤</a> (Singleton): 클래스의 인스턴스를 하나만 생성하여 전역에서 접근할 수 있도록 보장하는 패턴.
<br><a data-href="추상 팩토리" href="0.-clean-code/1.-design-pattern/2.-생성-패턴/추상-팩토리.html" class="internal-link" target="_self" rel="noopener">추상 팩토리</a> (Abstract Factory): 관련된 객체들을 구체적인 클래스에 의존하지 않고 생성할 수 있게 해주는 인터페이스를 제공하는 패턴.
<br><a data-href="팩토리" href="0.-clean-code/1.-design-pattern/2.-생성-패턴/팩토리.html" class="internal-link" target="_self" rel="noopener">팩토리</a>(Factory Method): 객체 생성을 서브클래스에서 정의할 수 있도록 하여 객체 생성의 인터페이스를 정의하지만, 실제 객체 생성은 서브클래스에서 처리하는 패턴.
<br><a data-href="프로토타입" href="0.-clean-code/1.-design-pattern/2.-생성-패턴/프로토타입.html" class="internal-link" target="_self" rel="noopener">프로토타입</a>(Prototype): 새 객체를 생성할 때, 기존 객체를 복사하여 생성하는 패턴.
]]></description><link>0.-clean-code/1.-design-pattern/2.-생성-패턴/2.-생성-패턴.html</link><guid isPermaLink="false">0. Clean Code/1. Design Pattern/2. 생성 패턴/2. 생성 패턴.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 11:58:52 GMT</pubDate></item><item><title><![CDATA[문제]]></title><description/></item></channel></rss>