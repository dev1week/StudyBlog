<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Hanju]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib/media/favicon.ico</url><title>Hanju</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Mon, 10 Jun 2024 17:38:49 GMT</lastBuildDate><atom:link href="lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Mon, 10 Jun 2024 17:38:48 GMT</pubDate><copyright><![CDATA[1week]]></copyright><ttl>60</ttl><dc:creator>1week</dc:creator><item><title><![CDATA[<font color="#8064a2">Profile.</font>]]></title><description><![CDATA[ 
 <br><br><br><br>
안녕하세요. 백엔드 개발자 김한주입니다.<br>
제 강점은 단순 기능 구현을 넘어 안정적인 상황을 목표로 개발하는 습관입니다.<br>
또한, 다양한 기술 스택을 효율적으로 결합하여 안정적인 시스템을 만들어 나갑니다.<br>
이를 위해 새로운 기술이나 도구를 습득하고 프로젝트에 적용하는 것에 있어서도 익숙합니다.
<br><br><br><br><br><br><br>1.<a data-href="Index 잘 쓰는 방법" href="db/rdb/index-잘-쓰는-방법.html" class="internal-link" target="_self" rel="noopener">Index 잘 쓰는 방법</a><br>
RDBMS에서 Index를 사용할 때 주의점과 팁을 알아봅니다.
<br>2.<a data-href="Hash 함부로 쓰면 메모리 터진다" href="알고리즘과-자료구조/hash-함부로-쓰면-메모리-터진다.html" class="internal-link" target="_self" rel="noopener">Hash 함부로 쓰면 메모리 터진다</a><br>
코테에서 Java의 HashSet을 사용시 메모리가 터질 수 있는 이유와 간단한 계산법을 알아봅니다.
<br>3.<a data-href="Dynamo DB - 채팅 내역 저장을 위한 키 설계" href="prj/cloudy/dynamo-db-채팅-내역-저장을-위한-키-설계.html" class="internal-link" target="_self" rel="noopener">Dynamo DB - 채팅 내역 저장을 위한 키 설계</a>, <a data-href="RDB와 NoSQL의 차이" href="prj/cloudy/rdb와-nosql의-차이.html" class="internal-link" target="_self" rel="noopener">RDB와 NoSQL의 차이</a><br>
Cloudy에서 채팅 내역 저장시 Dynamo DB를 활용한 방향을 소개합니다. 
<br>4.<a data-href="Flux를 활용한 SSE 구현기" href="prj/cloudy/flux를-활용한-sse-구현기.html" class="internal-link" target="_self" rel="noopener">Flux를 활용한 SSE 구현기</a><br>
Cloudy에서 챗봇 사용자 경험을 위해 Flux를 활용해 SSE를 적용한 개선기를 소개합니다.
<br>5.<a data-href="콘팅이 서비스를 잘게 쪼갠 이유" href="prj/conting/콘팅이-서비스를-잘게-쪼갠-이유.html" class="internal-link" target="_self" rel="noopener">콘팅이 서비스를 잘게 쪼갠 이유</a><br>
콘팅의 서비스가 잘게 쪼갠 근거와 그 방향성을 소개합니다. 
<br><br><br>
<br>Seoul National Universiry Of Sicence and Technology Major in Electronic IT Media, (2017.02 ~ 2023.02)
<br>KIST (Korea Institute of Science and Technology / AI &amp; Robot Lab) Intern (2022.09.03 ~ 2023.02.19)
<br>SSAFY (Samsung Software Academy Foy Youth) 10th Trainnee<br>
(2023.07~2024.07)
<br><br><br>
<br>동계 한국방송미디어공학회 대학생 논문/캡스톤디자인 경진대회 최우수상 (2022.11.19)
<br>전자IT미디어공학과 캡스톤디자인 경진대회 우수상 (2023.01.16)
<br>신한은행 해커톤 본선진출 (2023..12)
<br>삼성 청년 SW 아카데미 1학기 관통 프로젝트 최우수상 (2023.11.24)
<br>삼성 청년 SW 아카데미 2학기 공통 프로젝트 우수상 (2024.2.29)
<br>삼성 청년 SW 아카데미 2학기 특화 프로젝트 최우수상 (2024.4.04)
<br>삼성 청년 SW 아카데미 2학기 기업연계 프로젝트 최우수상 (2024.6.06)
<br><br><br>
<br>한국데이터진흥원 SQL Developer 취득 (2022.12.09)
<br>제7차 현대 Softeer 정기 역량 진단(HSAT) Level3 취득(2023.08.11)
<br><br><br><img src="https://i.imgur.com/1c4Jlsl.png" referrerpolicy="no-referrer"><br><br><br><img src="https://i.imgur.com/cehUtrI.png" referrerpolicy="no-referrer"><br>]]></description><link>hanju's-study-note.html</link><guid isPermaLink="false">Hanju's Study Note.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Mon, 10 Jun 2024 17:38:26 GMT</pubDate><enclosure url="https://i.imgur.com/1c4Jlsl.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/1c4Jlsl.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Hash 함부로 쓰면 메모리 터진다]]></title><description><![CDATA[ 
 <br><br><br><a data-tooltip-position="top" aria-label="https://www.acmicpc.net/problem/2121" rel="noopener" class="external-link" href="https://www.acmicpc.net/problem/2121" target="_blank">문제풀어보기</a><br>실버 3의 비교적 쉬운 문제처럼 보이는데요. 위 문제는 생각없이 풀면 머리에 ? 띄우기 딱 좋은 문제입니다. 특히 잘못된 풀이의 경우 논리적, 시간복잡도 측면에서도 틀린 것이 전혀 없기 때문에 헤매기 매우 쉽습니다. 풀이방향 잘못 잡으면 메모리 초과가 발생하기 때문에, 공간복잡도를 건드는 문제는 조심해서 접근해야합니다. <br>심지어 python, cpp에서는 문제 없이 통과되는 코드가 Java 특유의 객체지향성과 JVM/GC 특성이 환장의 시너지를 일으켜 통과가 안되는 경우가 꽤 있습니다. (억울) Java 쓴다고 이런 패널티를 받을 수는 없으니, 유의하도록합시다. (혹은 빠른 시일 내에 cpp나 python으로 갈아ㅌ..)<br>대기업 공채에서 이런 문제에 잘못 낚일 경우 6개월에서 1년동안 손가락 빨고 있어야합니다 ㅎㅅㅎ<br><img src="https://i.imgur.com/vhS6I39.png" referrerpolicy="no-referrer"><br>문제를 간단히 요약하면 다음과 같습니다. <br>
<br>n개의 좌표가 입력으로 주어진다. 
<br>직사각형의 길이 a,b가 주어진다. 
<br>n개의 좌표로 직사각형을 만들 때 길이가 일치하는 경우의 수 구하기 
<br>특이한건 전체 데이터의 개수가 약 10^5 개, 각 좌표값은 long 타입 써야할 정도로 숫자가 매우 흉악한데요. 전형적인 데이터 개수 &amp; 크기로 내리찍는 문제입니다. 이 부분을 유의하면서 풀어봅시다. 불행 중 다행으로 전체 경우의 수는 2^31 안으로 나온다했으니, 정답 변수 만큼은 int로 선언할 수 있겠네요.<br><br> 정말 간단하게 접근했을 때의 풀이입니다. 백트래킹이나 4중 반복문을 써서 가능한 모든 조합을 테스트 해보는 것입니다. 먼저 시간 복잡도를 계산해보겠습니다. 백트래킹으로 구현할 경우 조합의 개수 만큼 시간 복잡도가 나옵니다. nC4가 되므로 n=500,000을 넣어 계산해보겠습니다.<br>
500000C4 = 2,60,385,417,812,487,500(~=10^17)이므로 택도 없는 풀이네요.<br><br>그렇다면 고려해볼만한 것은 해시입니다. 풀이는 다음과 같습니다. <br>답안 로직<br>
<br>x와 y좌표를 속성으로 갖고 x,y로 고유성을 판별할 수 있는 Position클래스를 정의합니다. 
<br>주어진 모든 점을 해시셋에 넣습니다. 
<br>가장 왼쪽 아래의 점(x y)을 잡았다 치고 주어진 모든 점을 순회합니다. 
<br>해시셋에서 나머지 3개의 점 (x+a, y+b), (x,y+b), (x+a,y) 이 있는지 확인합니다. 
<br><a data-tooltip-position="top" aria-label="https://www.acmicpc.net/submit/2121/79462950" rel="noopener" class="external-link" href="https://www.acmicpc.net/submit/2121/79462950" target="_blank">전체 코드는 다음과 같습니다.</a><br>시간복잡도를 계산해볼까요?<br>
<br>주어진 입력을 Position 객체로 만들어 해시셋에 저장합니다.(=O(n))
<br>전체 좌표에 대해 순회합니다. (=O(n))
<br>기준 좌표에 대해서 나머지 3개의 좌표가 존재하는 지 해시를 통해 확인합니다. (=O(3x1))
<br>전체 시간 복잡도는 다음과 같습니다. O(n+3*n) = O(n)
<br>전체 시간복잡도는 O(n)으로 매우 무난하게 통과해야하는데요. <br><img src="https://i.imgur.com/l3ixUdK.png" referrerpolicy="no-referrer"><br>????????<br>보시는 바와 같이, 메모리 초과가 발생합니다. 왜 메모리 초과가 발생할까요? 그리고 실전에서 이와 같은 풀이를 방지하려면 어떻게 해야할까요??<br><br>128MB 메모리 제한이 있을 때, Set&lt;Position&gt;가 최대 몇 개의 키를 가질 수 있는지 계산하기 위해서는 각 Position 객체가 차지하는 메모리 크기를 알아야 합니다. 이를 위해 Position 클래스의 메모리 크기를 분석해야 합니다.<br>Position 클래스는 두 개의 long 필드를 가지고 있습니다. long 타입은 64비트(8바이트)이므로, 두 개의 long 필드는 16바이트를 차지합니다. 그러나 Java 객체에는 추가적인 오버헤드가 존재합니다.<br>Java 객체의 메모리 오버헤드는 다음과 같이 계산됩니다:<br>
<br><a data-href="객체 헤더" href="java/객체-헤더.html" class="internal-link" target="_self" rel="noopener">객체 헤더</a>: 12바이트 (8바이트는 기본 객체 헤더, 4바이트는 정렬 패딩)
<br>long 필드 두 개: 16바이트 (각각 8바이트)
<br>따라서, Position 객체는 12바이트(헤더) + 16바이트(필드) = 28바이트가 됩니다. 그러나 Java 객체는 메모리 정렬 패딩에 따라 8바이트 단위로 정렬됩니다. 그러므로 28바이트는 32바이트로 정렬됩니다.<br>하지만 실제로 Map에 키로 사용될 때는 추가적인 메모리 오버헤드가 발생합니다. 일반적으로 HashSet을 예로 들면:<br>
<br>HashSet.Entry 객체: 약 32바이트 (참조 변수와 정렬 패딩 포함)
<br>기타 오버헤드 (해시 테이블 등): 해시 테이블 크기에 따라 다름
<br>보수적으로 계산해보면, 하나의 Position 객체가 HashSet의 키로 사용될 때 약 64바이트의 메모리를 차지한다고 가정할 수 있습니다.<br>이제 전체 메모리 사용량을 계산해 보겠습니다:<br>
<br>주어진 메모리 제한: 128MB = 128  1024  1024 바이트 = 134,217,728 바이트
<br>각 Position 객체가 약 64바이트를 차지하므로, Map이 가질 수 있는 최대 키의 개수는:<br><br>따라서, 128MB 메모리 제한이 있을 때 Set&lt;Position&gt;은 최대 약 2,097,152개의 키를 가질 수 있습니다.<br>문제에서 풀이는 처음 해시셋에 키를 저장할 때 최대 50만개의 키, 3개의 점으로 판단할 때 최대 200만(4x50만)개의 키를 사용합니다. <br>즉 최대 250만개의 키를 사용할 가능성이 있기 때문에 128MB의 메모리 제한이 있을 때 메모리 초과가 발생합니다. <br><br>그렇다면 해시를 사용하지 않으면 어떻게 해야할까요? 바로 이진탐색을 사용하는 것입니다. 속성이 2가지라 이진 탐색 사용이 어려울 것 같지만, java의 comparable 인터페이스를 구현하여 정렬을 하면 비교적 쉽게 구현할 수 있습니다. <br>풀이는 해시와 비슷합니다. <br>
<br>전체 좌표에 대해서 순회한다. 
<br>해당 좌표를 좌하단 좌표로 기준을 잡고 판단한다. 
<br>나머지 3개의 좌표((x+a, y+b), (x,y+b), (x+a,y))를 이진탐색을 활용해 있는지 없는지만 빠르게 판단한다. 
<br>보시는 바와 같이 기본적인 논리구조는 같은데, 실제 값을 찾을 때 해시를 사용할 것이냐, 이진탐색을 사용할 것이냐의 차이로 갈리게 됩니다.<br>시간복잡도는 전체 좌표에 대해서 순회하는 시간 O(n), 이진탐색을 이용해서 나머지 3개의 좌표가 있는지 없는지 판단하는 시간 O(logN) 총 O(3nlogN)이므로 해시보다는 느려도, 매우 넉넉하게 시간 제한 안에 들어올 수 있습니다. <br>실제 코드를 통해 확인해보겠습니다. <br>이진탐색에서 활용할 데이터 셋은 정렬이 필수기 때문에 정렬을 해주는 모습입니다. <br>

for (int i = 0; i &lt; n; i++) {
	tokens = new StringTokenizer(buffer.readLine());

	positions[i] = new Position(
		Long.valueOf(tokens.nextToken()), 
		Long.valueOf(tokens.nextToken())
		);
	}

Arrays.sort(positions);
Copy<br>전체 좌표를 순회하며 좌하단으로 고정했을 때 나머지 3개의 좌표가 있을 때만 세는 코드입니다.<br>long result = Arrays.stream(positions)
                .filter(p-&gt;isValid(positions, p, a,b))
                .count();
Copy<br>
private static boolean isValid(Position[] positions, Position position, int a, int b){
	return binarySearch(positions, position.x+a, position.y+b)&amp;&amp;
			binarySearch(positions, position.x, position.y+b)&amp;&amp;
			binarySearch(positions, position.x+a, position.y);

}
Copy<br>객체의 comparable 인터페이스를 구현하여 두 종류 이상의 변수가 있어도 쉽게 이진탐색을 수행하는 코드입니다. <br>
private static boolean binarySearch(Position[] positions, long targetX, long targetY) {
	int l = 0;
	int h = positions.length;


	while(h&gt;l){
		int mid = (l+h)/2;

		Position midPosition = positions[mid];

		if(midPosition.x==targetX&amp;&amp;midPosition.y==targetY){
			return true;
		}else if(midPosition.compareTo(new Position(targetX, targetY))&lt;0){
			l=mid+1;
		}else{
			h=mid;
		}
	}

	return false;

}

Copy<br>class Position implements Comparable&lt;Position&gt;{
    long x, y;


    public Position(long x, long y){
        this.x = x;
        this.y = y;
    }
	//equals와 compareTo를 오버라이딩한 메서드는 중략... 

    @Override
    public int compareTo(Position o){
        if(this.x==o.x){
            return Long.compare(this.y, o.y);
        }
        return Long.compare(this.x, o.x);
    }
}
Copy<br><br>
<a data-tooltip-position="top" aria-label="https://www.acmicpc.net/source/79467346" rel="noopener" class="external-link" href="https://www.acmicpc.net/source/79467346" target="_blank">파이썬 해시 활용 제출코드</a><br>
<a data-tooltip-position="top" aria-label="https://www.acmicpc.net/source/79464005" rel="noopener" class="external-link" href="https://www.acmicpc.net/source/79464005" target="_blank">자바 이진탐색 활용 제출코드</a>
<br>def is_rectangle_present(x, y, A, B, point_set): 
	return ((x + A, y) in point_set 
				and (x, y + B) in point_set 
				and (x + A, y + B) in point_set)

def count_rectangles(points, A, B):
    point_set = set(points)
    count = 0

    for (x, y) in points:
        if is_rectangle_present(x, y, A, B, point_set):
            count += 1

    return count

import sys
input = sys.stdin.read
data = input().split()

N = int(data[0])
A = int(data[1])
B = int(data[2])

points = []
for i in range(N):
    x = int(data[3 + 2 * i])
    y = int(data[4 + 2 * i])
    points.append((x, y))

result = count_rectangles(points, A, B)


print(result)

Copy<br>해쉬를 사용하는 동일한 풀이를 python으로 작성하고 제출해봤습니다. <br><img src="https://i.imgur.com/mTfnu0R.png" referrerpolicy="no-referrer"><br>자바는 오늘도 연전연패..]]></description><link>알고리즘과-자료구조/hash-함부로-쓰면-메모리-터진다.html</link><guid isPermaLink="false">알고리즘과 자료구조/Hash 함부로 쓰면 메모리 터진다.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Mon, 10 Jun 2024 12:07:28 GMT</pubDate><enclosure url="https://i.imgur.com/vhS6I39.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/vhS6I39.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Java 코드]]></title><description><![CDATA[ 
 <br><br><br>private int binarySearch(int[] arr, int target){

	//이진 탐색을 이용해 정렬된 배열 arr안에서 target 인덱스 반환 
	//target이 없다면 -1을 반환 

}

Copy<br>
<br>이진 탐색을 이용해 정렬된 배열 arr 안에서 target 인덱스 반환
<br>target이 없다면 -1을 반환
<br><br>arr배열 안에 있는 인덱스를 찾는 과정이므로, arr의 범위인 [0,arr.length)가 탐색 범위입니다. 찾는 범위는 다음과 같이 각각의 변수로 선언합니다. <br>int start = 0;
int end = arr.length; 

Copy<br><br>end-start가 양수일 때까지 탐색을 계속 반복해야 합니다. <br>while(end&gt;start){


}

Copy<br><br>범위의 중간 인덱스와 그 값을 구합니다. <br>
int mid = (start+end)/2;
int value = arr[mid];

Copy<br>찾아낸 중간값으로 target과의 대소 판단 후 범위를 조정합니다. <br>if(value==target){

	return mid;

}else if(value&gt; target){
	//다운 
	//정답은 더 작은 범위에 있다.
	//[start, mid) 
	end = mid;
}else{
	//업
	//정답은 더 큰 범위에 있다. 
	// [mid+1, end)
	start = mid+1; 
}

Copy<br><br>
private static int binarySearch(int[] arr, int target){

	int start = 0;
	int end = arr.length; 

	while(end&gt;start){
		int mid = (start+end)/2;
		int value = arr[mid];
		if(value==mid){
			return mid; 
		}else if(value&gt;target){
			end = mid;
		
		}else{
			start = mid+1; 
		}
	}
}

Copy<br><br><br>정렬기준이 중요한 이유<br>
이진 탐색 문제 대부분은 큰 범위의 정답 후보 중 문제 조건에 맞는 정답을 찾아내는 케이스입니다. 문제에서 요구하는 조건의 검색 결과가 정답 후보의 값에 따라 정렬된 상태인지 확인해야합니다. <br><br>이진 탐색은 정확한 값 뿐만 아니라 정답 조건을 만족하는 값 중 가장 큰 값 혹은 가장 작은 값을 찾는데도 많이 사용됩니다. 파라메트릭 서치를 구현하기 위해서는 다음 2가지를 고려해야합니다.<br>1. 범위 좁히기
2. 범위 표기법 
Copy<br><br>정답 조건을 만족하는 값 중 가장 큰 값을 구하는 경우<br>
중간값을 검사 했을 때 정답을 만족하더라도 더 큰값이 있는지 찾아야합니다. 범위를 큰 쪽으로 좁히되, 검사한 중간 값을 포함해서 좁혀야합니다. <br>정답 조건을 만족하는 값 중 가장 작은 값을 구하는 경우<br>
중간값을 검사했을 때 정답을 만족하더라도 더 작은 값이 있는지 찾아야합니다. 범위를 작은 쪽으로 좁히되, 검사한 중간값을 포함해서 좁혀야합니다. 이 경우 범위에 2개의 값이 남아있을 때 중간값은 start를 선택합니다. start가 정답 조건을 만족한다면 중간값을 포함한 [start, start] 를 선택하게 됩니다.<br>
반대로 start가 정답 조건을 만족하지 않는다면 큰 값이 들어 있는 범위인 [start+1, end]<br>하나의 값만 남았다고 해서 무조건 정답이 아니다.<br>
원소가 하나 남았다면 이 값이 정답을 만족하는지 여부를 한 번 더 검사해야합니다. <br><br><br>자바에서는 배열과 리스트에 적용할 수 있는 두 가지 메서드를 제공합니다. <br>]]></description><link>알고리즘과-자료구조/알고리즘/이진탐색/이진탐색.html</link><guid isPermaLink="false">알고리즘과 자료구조/알고리즘/이진탐색/이진탐색.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Mon, 10 Jun 2024 02:10:06 GMT</pubDate></item><item><title><![CDATA[Parametric Search]]></title><description><![CDATA[ 
 <br><br>
문제를 결정 문제로 변형하여 이분탐색으로 해결하는 방식입니다. 
<br><br>처음들으면 잘 와닿지 않을 수 있다. 예시를 통해서 살펴봅시다. <br>예를들어 손님이 고기 200g을 달라고 해서 고기 덩이에서 200g을 잘라내야한다고 해봅시다.우리는 보통 눈대중으로 잘라서 저울에 재본 후 200g보다 부족하면 조금 더 잘라넣고 200g을 넘어가면 덩어리를 잘라서 저울에 잰다. <br>즉 우리는 "고기 200g을 잘라라"라는 문제를 "지금 자른 고기가 200g보다 무거운가"라는 결정문제로 변형한 뒤 조금씩 고기를 추가하거나 덜어내면서((=이분탐색)으로 문제를 해결한다. 이렇게 원래 주어진 문제를 결정문제로 변형하여 이분탐색을 통해 해결하는 것을 파라메트릭 서치라고 한다. <br><br>
아래 세 조건을 만족하는 문제에서만 사용할 수 있습니다. 
<br>1.특정 조건을 만족하는 최대/최소를 구하는 형식의 문제여야 합니다.<br>
조건이 보이지 않더라도 최소한 해당 조건으로 문제를 변경할 수 있어야합니다. 수행할 변수를 가지고 함수를 세웠을 때 그 함수가 감소함수거나 증가함수이어야 합니다.<br>2.어떤 값이 조건을 만족하면 이후 탐색 범위 내의 모든 값은 모두 조건을 만족해야한다.<br>
최대값을 구하는 문제의 경우 어떤 값이 조건을 만족하면 그 값보다 작은 값은 모두 조건을 만족해야한다. 또한 최솟값을 구하는 경우 어떤 값이 조건을 만족하면 그 값보다 큰 값은 모두 조건을 만족해야합니다. 그래야 조건을 만족하는 경우, 만족하지 않는 경우 다음 범위를 탐색하면서 답을 구할 수 있습니다. <br>3.범위가 이산적이거나 허용오차 범위가 있어야합니다.<br>
이분탐색으로는 연속적인 범위에서는 정답에 한없이 가까워질 뿐 정확한 값은 구할 수 없습니다. (=고등수학에서의 극한을 떠올리면 됩니다.)<br><br><br>
condition(x)를 만족하는 최대값을 찾는 문제라고 가정합니다. 
<br><br>목표 : 후보 범위의 최솟값인 l과 h를 넉넉하게 잡아준 뒤 이를 점점 줄여나가면서 l과 h가 같아지도록 합니다. <br>whlie(l&lt;h){
	int m = (l+h+1)/2; 

	if(condition(m)){
		l = m;
	}else{
		h = m-1;
	}
}


Copy<br>주의 : 무한 루프에 빠지지 않는지 확인하기 <br>m=(l+h)/2인지, m=(l+h+1)/2인지에 따라 무한루프에 걸릴 수 있습니다. <br>무한 루프에 빠지지 않게하려면 이분탐색에 의해 두 구역으로 나눠졌을 때 m이 어디에 속하는지를 확인하면 됩니다. 예를 들어 조건을 만족하는 최댓값을 구하는 경우 m은 h쪽 범위에 속합니다. l과 h가 1차이로 붙어 있을 때 그림은 다음과 같습니다. <br><img src="https://i.imgur.com/JGxXFz2.png" referrerpolicy="no-referrer"><br>
m=(l+r)/2일 경우, 그림처럼 m은 항상 왼쪽 범위로 고정되고 오른쪽 범위는 변하지 않아서 무한 루프에 빠집니다.<br><img src="https://i.imgur.com/Yt8EEkN.png" referrerpolicy="no-referrer"><br>
m=(l+r+1)/2일 경우 m은 오른쪽 범위속하게 되면서 다음 범위는 [m,m]이 됩니다. <br>표로 정리해보겠습니다. <br><br><br>
<br>범위가 m이면 루프는 logM번 실행됩니다. 
<br>조건 함수의 시간 복잡도 = O(C(n))
<br>위 조건을 모두 고려하면 총 시간 복잡도는 O(C(n)logM)이 됩니다. 
<br><br><br>parametirc search에서 결정 문제라는 표현을 썼었습니다. 그게 이 문제에서 어떻게 적용되는지 살펴보겠습니다. 이 문제는 N개를 만들 수 있는 랜선의 최대 길이를 구하는 것이 목표입니다. 이걸 결정 문제로 바꾸면 우리가 구해야하는 답을 인자로, 조건의 참 거짓을 판단하는 문제로 만들 수 있습니다. <br>1. 변수를 지정합니다. (보통은 문제에서 요구하는 최대값/최솟값입니다.)
2. 해당 변수를 이진탐색하면서 codition에 만는지 판단합니다. 
3. condition을 정의합니다. 
4. 기본 템플릿에 맞춰서 구현합니다. 

Copy<br>기본 템플릿을 다시 봐봅시다. <br>whlie(l&lt;h){
	int m = (l+h+1)/2; 

	if(condition(m)){
		l = m;
	}else{
		h = m-1;
	}
}


Copy<br>길이 m을 임의로 선택하여 condition 함수에 넣으면 condition 함수에서는 랜선이 n개 이상일 수 있는지 판단합니다. <br>다음은 완성된 코드입니다. ]]></description><link>알고리즘과-자료구조/알고리즘/이진탐색/parametric-search.html</link><guid isPermaLink="false">알고리즘과 자료구조/알고리즘/이진탐색/Parametric Search.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Mon, 10 Jun 2024 06:34:05 GMT</pubDate><enclosure url="https://i.imgur.com/JGxXFz2.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/JGxXFz2.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[객체 헤더]]></title><description><![CDATA[ 
 <br>Java에서 객체 헤더(object header)는 각 객체의 메타데이터를 저장하는 부분으로, JVM이 객체를 관리하는 데 필요한 정보를 포함합니다. 객체 헤더는 JVM 구현마다 다를 수 있지만, 일반적으로 다음과 같은 정보를 포함합니다:<br>
<br>
Mark Word:

<br>Locking Information: 객체의 락 상태를 저장합니다. 이는 객체가 동기화 블록에 의해 잠겨 있는지 여부를 나타냅니다.
<br>Hash Code: 객체의 해시 코드가 캐시될 수 있습니다.
<br>Garbage Collection Information: GC 상태를 나타낼 수 있습니다.
<br>Age: 객체의 "나이"를 추적하여 GC가 오래된 객체를 더 자주 수집할 수 있도록 합니다.


<br>
Klass Pointer:

<br>Class Metadata: 객체가 어떤 클래스의 인스턴스인지를 가리키는 포인터입니다. 이는 객체가 속한 클래스의 메타데이터를 참조합니다.


<br><br>Java 64비트 HotSpot VM의 경우, 객체 헤더는 일반적으로 다음과 같이 구성됩니다:<br>
<br>Mark Word: 64비트
<br>Klass Pointer: 64비트 (압축된 포인터 사용 시 32비트)
<br>이러한 헤더는 JVM에서 객체를 관리하고 동기화, GC 등을 수행하는 데 필수적입니다.<br><br>다음은 객체 헤더의 역할을 간략히 보여주는 예제입니다:<br>
public class Main {
    public static void main(String[] args) {
        Object obj = new Object();

        // System.identityHashCode는 객체의 헤더에 저장된 해시 코드를 반환
        int hashCode = System.identityHashCode(obj);
        System.out.println("HashCode: " + hashCode);

        // 기본 동기화 블록, 객체의 모니터 락을 획득
        synchronized (obj) {
            System.out.println("Object is locked");
        }
    }
}


Copy<br>이 예제에서:<br>
<br>System.identityHashCode(obj)는 객체의 해시 코드를 반환하는데, 이는 객체 헤더의 일부인 Mark Word에 저장될 수 있습니다.
<br>synchronized (obj)는 객체의 모니터 락을 획득하여, 객체 헤더에 있는 락 정보를 사용합니다.
<br><br>객체 헤더는 Java 객체의 중요한 부분으로, JVM이 객체를 효율적으로 관리하고 동기화, 해시 코드 계산, GC 등의 작업을 수행할 수 있도록 돕습니다. 이를 통해 JVM은 객체 지향 프로그램의 효율성을 극대화할 수 있습니다]]></description><link>java/객체-헤더.html</link><guid isPermaLink="false">Java/객체 헤더.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Mon, 10 Jun 2024 10:41:41 GMT</pubDate></item><item><title><![CDATA[코딩테스트 풀이법]]></title><description><![CDATA[ 
 <br><br><br><br><img src="https://i.imgur.com/WwCBhT7.png" referrerpolicy="no-referrer"><br><br><img src="https://i.imgur.com/6d7CvcV.png" referrerpolicy="no-referrer"><br><br><img src="https://i.imgur.com/WFoAZaQ.png" referrerpolicy="no-referrer"><br><br><br><img src="https://i.imgur.com/1fdPgyc.png" referrerpolicy="no-referrer"><br><br><br>시작점 2개를 먼저 큐에 넣고 시작합니다. <br><br><br><br>BFS를 사용할 때 큐에 쌓이는 순서는 반드시 거리순입니다. <br><br><img src="https://i.imgur.com/H9DFlMj.png" referrerpolicy="no-referrer"><br><br>
<br>임의의 정점 1개 구하기 
<br>정점 x에서 가장 먼 정점y 구하기 
<br>정점 y에서 가장 먼 정점 z 구하기 (=트리의 지름)
<br><br>dist 배열을 이용해 거리를 구하고 가장 긴 거리를 갖는 노드를 반환한다. <br><br><br><br>
<br>들어오는 간선이 없는 루트 노드가 정확히 1개 존재하는가
<br>모든 노드는 반드시 단 하나의 들어오는 간선이 있다. 
<br>루트 노드에서 모든 노드를 방문할 수 있으며 이러한 경로는 유일하다. 
<br><br>
int binarySearch(int[] arr, int target){  
  
    int l = 0;  
    int h = arr.length;  
  
    while(h&gt;l){  
        int mid = (l+h)/2;  
        if(arr[mid]==target){  
            return mid;  
        }else if(arr[mid]&gt;target){  
            h = mid;  
        }else{  
            l = mid+1;  
        }  
    }  
    return -1;  
}
Copy<br><br>int upperIdx(int target, int[] arr){
	int l = 0;
	int h = arr.length;
	while(h&gt;l){
		int mid = (l+h)/2;
		if(arr[mid]&gt;target) h = mid;
		else l = mid+1;
	}
	
	return l;

}
Copy<br><img src="https://i.imgur.com/r6XSZRm.png" referrerpolicy="no-referrer"><br><br>int lowerIdx(int target, int[] arr){
	int l = 0;
	int h = arr.length;
	while(h&gt;l){
		int mid = (l+h)/2;
		if(arr[mid]&gt;=target) h = mid;
		else l = mid+1;
	}
	
	return l;

}
Copy<br><br>
<br>값의 등장 횟수 = 정렬이 유지되는 제일 왼쪽과 오른쪽 인덱스 차이
<br><br><br>
각 배열의 값보다는 요소들의 대소 관계만 알고 싶을 때 크기순 인덱스로 붙여버린다. 
<br>
<br>중복값을 지운다. 
<br>이진탐색으로 해당값의 인덱스를 찾는다.
<br><br>private static int[] getArr() throws IOException{  
    return Arrays.stream(buffer.readLine().split("\\s+"))  
            .mapToInt(Integer::parseInt)  
            .toArray();  
}
Copy<br><br>// 스트림을 사용하여 결과를 StringBuilder에 추가  
String result = Arrays.stream(compressedPositions)  
        .mapToObj(String::valueOf)  
        .collect(Collectors.joining(" "));
Copy<br><br>int[] compressedPositions = IntStream.range(0, n)  
        .map(i -&gt; Collections.binarySearch(uniquePositions, positions[i]))  
        .toArray();
Copy반복문 시작 조정isUsed 사용isUsed 사용dis[nx][ny] = dis[current.x][current.y]+1큐에서 뺄때마다 세기시작점 위치 세기]]></description><link>코딩테스트-풀이법.html</link><guid isPermaLink="false">코딩테스트 풀이법.canvas</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Mon, 10 Jun 2024 07:43:45 GMT</pubDate><enclosure url="https://i.imgur.com/WwCBhT7.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/WwCBhT7.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[채킹 내역 저장을 위한 키 설계]]></title><description><![CDATA[ 
 <br><br><br>DynamoDB의 기술적 구현방식을 다루기보단, DynamoDB를에 대해서 얇고 넓게 소개하고, Cloudy의 채팅 내역 저장 시스템에 어떻게 적용했는지 사례를 공유합니다. 기술적 내용에 대해 자세히 알고 싶다면 하단 참고 자료에 관련 링크들을 참조해주세요<br>아래와 같은 키워드가 등장합니다. 본문에서 개념에 대해 설명하며 진행할 예정이나, 관련 배경지식이 있다면 더 쉽게 이해할 수 있습니다. <br>
<br>Dynamo DB
<br>HotPartition
<br>Scale out  / Scale Up 
<br><br>Dynamo Db에서는 Partiion Key와 Sort Key를 합쳐 Primary Key로 사용하는 매우 독특한 특징이 있습니다. 올바르게 Dynamo DB를 사용하기 위해서 DynamoDB의 특징과 성질을 알아보겠습니다. <br>Partition Key<br>
pk는 많은 파티션 중 내가 찾고자하는 데이터가 어느 파티션에 있는지 알려주는 키입니다. 항상 equal 연산자만 사용할 수 있습니다. <br>Sort Key<br>
sk를 이용해서 1:n 관계의 모델링을 적용할 수 있습니다. 오름차순, 내림차순 대로 데이터를 정렬하여 조회할 수 있습니다. begins with , 등호 연산자 및 범위 연산자를 사용할 수 있습니다.<br>pk와 sk를 합쳐 Primary Key가 됩니다. 오직 Primary key로만 데이터 검색이 가능하기 때문에 pk와 sk 조합을 잘 설계해야합니다.<br>
<img src="https://i.imgur.com/o7S8mKQ.png" referrerpolicy="no-referrer"><br><br><br><img src="https://i.imgur.com/d4RQeDY.png" referrerpolicy="no-referrer"><br>데이터끼리 관계를 맺는 RDBMS는 수평적 확장이 매우 힘듭니다. 때문에 주로 스케일 업을 이용하여 해결합니다. 하지만 태생이 대규모 데이터를 처리하기 위해 나온 NoSQL의 경우 무한히 스케일 아웃을 진행할 수 있습니다.<br>
즉, NoSQL을 활용하는 데이터는 수평으로 확장 가능한 데이터가 되게끔 설계해야합니다. 또한 어느 한쪽의 인스턴스로만 트래픽이 쏠리지 않도록 키를 잘 설계해야합니다.<br><br>논리적 단위인 테이블은 한 개여도, 내부에서는 파티션이라는 단위로 쪼개져 저장됩니다. <br><br>하나의 파티션은 다음과 같은 제약사항을 가집니다. 데이터가 계속해서 늘어나더라도 파티션의 개수 증가하는 개념이지, 한 파티션 내의 제약사항은 절대로 변하지 않습니다. <br>
<br>1k WCU
<br>3K RCU 
<br>10GB<br>
-&gt; 여러개의 파티션이 골고루 사용되도록 파티션을 식별하는 키 디자인을 잘하는 것이 중요합니다.
<br><br><img src="https://i.imgur.com/7wXEKR7.png" referrerpolicy="no-referrer"><br><img src="https://i.imgur.com/qL0u4w9.png" referrerpolicy="no-referrer"><br>Dynamo DB는 Id를 해쉬값으로 변경하여 저장되는 파티션을 결정합니다. Application 구현시 Key값을 해쉬로 변경하는 로직은 짜지 않아도 괜찮습니다. <br><br>Amazon DynamoDB에서 파티션은 데이터의 양과 테이블에 대한 읽기/쓰기 요청의 양에 따라 자동으로 관리됩니다. 파티션이 늘어나는 주요 시점은 다음과 같습니다:<br>1.데이터의 양이 증가할 때:<br>
- DynamoDB 테이블에 저장된 데이터의 양이 파티션당 최대 저장 용량(10GB)을 초과할 때 새로운 파티션이 자동으로 추가됩니다. 즉, 테이블에 있는 데이터의 총량이 증가하여 각 파티션의 용량이 초과될 경우 DynamoDB는 추가 파티션을 생성하여 데이터를 분산 저장합니다.<br>2.프로비저닝된 읽기/쓰기 용량이 증가할 때:<br>
- 테이블의 프로비저닝된 읽기 및 쓰기 용량 단위가 증가하면 DynamoDB는 이를 수용하기 위해 파티션 수를 늘릴 수 있습니다. 파티션당 최대 처리량(읽기/쓰기 용량)이 제한되어 있기 때문에, 필요한 처리량을 제공하기 위해 더 많은 파티션을 생성합니다.<br>3.온디맨드 모드에서의 스케일링:<br>
- DynamoDB 테이블이 온디맨드 모드로 설정되어 있으면, 읽기 및 쓰기 요청의 트래픽 패턴을 자동으로 감지하여 파티션을 조정합니다. 트래픽이 급증하거나 감소할 때 테이블의 파티션 수는 자동으로 늘어나거나 줄어들 수 있습니다.<br><br><img src="https://i.imgur.com/78MRveb.png" referrerpolicy="no-referrer"><br>Dynamo DB는 항상 데이터를 복제하여 저장합니다. 3개의 가용영역에 복제되며 서비스는 3개의 가용영역에서 실행됩니다. <br><br><br>DynamoDB는 RCU와 WCU라는 컴퓨팅 단위를 사용합니다. 일반적인 RDB와는 다르게 WCU와 RCU는 독립적으로 동작합니다. <br><br><br>테이블의 전체 크기를 의미합니다. 테이블에 넣을 수 있는 아이템의 개수로 따지는 것이 아닌 최대 크기로 따집니다. 400KB까지 사용 가능합니다. 하지만 400KB를 전부 사용하는 것은 권장하지 않습니다. DynamoDB는 하나의 아이템에서 한 글자만 바뀌어도 다시 쓰는 특성을 갖습니다. 이러한 이유로 아이템의 사이즈는 작게, 아이템의 개수가 많게끔 저장되는 데이터를 모델링하는 것이 이상적입니다. <br>-&gt; DynamoDB의 컨셉은 무한하게 많은 데이터 중 PK+SK의 조합으로 특정한 데이터를 가능한한 빠르게 반환하는 것임을 잊지말아야합니다. <br><br>기본적으로 Dynamo DB에서는 데이터를 읽기 위한 REST API를 제공합니다. <br><br>
<br>Partition Key의 정확한 값을 지정해야합니다. 
<br>0개 또는 1개의 아이템만 반환합니다. 
<br>아이템 크기에 따라 RCU를 사용합니다. 

<br>아이템 크기가 10kb인 경우 2RCU를 사용합니다. 


<br><br>
<br>Partition Key의 정확한 값을 지정해야합니다. 
<br>선택적으로 attributes에 필터링 조건을 추가할 수 있습니다. 
<br>조건에 맞는 아이템을 여러개 반환합니다. 
<br>조건과 일치하는 아이템 크기에 따라 RCU를 소비하여 단일 결과를 반환합니다. 
<br>LastEvaluatedKey <br>
<br>Query는 단일 호출로 최대 1MB만 반환할 수 있습니다.
<br>응답 메시지가 1MB 이상일 경우 LastEvaluatedKey를 활용해 pagination이 가능합니다.
<br><br>
<br>rdbms에서의 Full Table Scan 과 동일합니다.
<br>Dynamo DB에서는 페이지네이션과 비슷하게 동작합니다. <br>
<br>rdbms에서는 테이블 끝까지 조회하지만, DynamoDB에서는 1MB 단위로 스캔이 가능합니다. 
<br>return 갑 중 token을 활용해 다음 1MB 데이터를 스캔할 수 있습니다. 
<br>사용예시<br>
<br>OLTP의 운영환경에서는 사실상 사용할 일이 없습니다. (어쨌거나 저쨌거나 결국 full table scan입니다.)
<br>온라인 마이그레이션을 할때의 옵션 중 하나입니다. 
<br><br>
<br>ACID를 지원하기 위한 API입니다. 
<br>단일 리전 내에서 여러개의 테이블이나 아이템을 트랜잭션으로 묶어 읽거나 쓸 수 있습니다. 
<br>WCU와 RCU가 2배가 소모되기 때문에, 필요한 곳에만 최소화하여 사용해야합니다. 
<br><br>Amazon DynamoDB에서 LSI(Local Secondary Index)와 GSI(Global Secondary Index)는 테이블의 쿼리 성능을 향상시키기 위해 사용되는 인덱스입니다. 두 인덱스 모두 테이블의 속성을 기준으로 데이터를 효율적으로 검색할 수 있게 해주지만, 사용 방법과 동작 방식에서 몇 가지 중요한 차이점이 있습니다.<br><br><img src="https://i.imgur.com/I7V2d7g.png" referrerpolicy="no-referrer"><br>
<br>테이블의 Primary Key 외의 다른 검색 조건이 필요한 경우 사용합니다.
<br>추가나 삭제가 자유로워 스키마 변경시 유연하게 대처할 수 있습니다. 
<br>원하는 Attribute를 GSI의 PK, SK로 설정합니다. 
<br><br><img src="https://i.imgur.com/YzEEnCb.png" referrerpolicy="no-referrer"><br>
<br>테이블 안에서 동일한 PK를 사용하며, 다른 SK를 사용하고 싶을 때 LSI를 사용합니다.
<br>일반적으로 사용을 권장하지 않습니다.<br>
<br>GSI와 달리 테이블 생성 시점에만 설정이 가능합니다. 
<br>사용 도중 삭제 또한 불가능합니다.
<br><br><br><img src="https://i.imgur.com/XvYMacu.png" referrerpolicy="no-referrer"><br>rdbms에서 처럼 엔티티별로 테이블을 만들지 말자<br>
오른쪽 예시처럼 최대한 빠르게 데이터를 조회하게 끔 해야한다. <br>
<br>application의 usecase가 dynamo db가 잘하는 것과 맞는지 판단해야합니다. 
<br>Dynamodb가 가장 잘하는 것은 무한대의 가까운 item에서 특정개수의 아이템을 Primary Key(PK+SK)로 빠르게 조회하는 것 이다. 대량의 벌크성 쿼리, range 쿼리, 집계 쿼리는 잘 수행하지 못합니다.<br>
<br>액세스 패턴을 식별해야합니다.<br>
읽기/쓰기 워크로드, 쿼리 차원, 집계
<br>사이즈가 작은 여러개의 테이블보다는 사이즈가 큰 하나의 테이블을 사용하는 것이 낫다.<br>
DynamoDB는 테이블 단위 완전 관리형 서비스이다.<br>
Dynamo DB는 풀서버리스 형태의 테이블 단위 완전관리형 서비스입니다. 여러 개의 테이블을 만들게 되면 각 테이블에 대한 설정, 모니터링, 최적화 등의 관리 작업이 필요하게 됩니다. 예를 들어 각 테이블의 스키마 설정 및 변경, 인덱스 관리, 성능 모니터링 및 튜닝, 읽기/쓰기 용량 설정 등을 각각의 테이블 별로 따로 해줘야합니다.<br>
이는 완전관리형 서비스의 설계 철학, 즉 "사용자가 최소한의 관리만으로 데이터베이스를 운영할 수 있도록 한다"는 목표에 어긋나게 됩니다.<br>테이블을 하나로 사용해야지, 여러개의 파티션을 사용하는 DynamoDB의 특성을 제대로 활용할 수 있습니다. 또한 핫 파티션이 발생할 확률이 줄어듭니다. <br>OLTP vs OLAP<br>
OLTP가 적합합니다. OLAP인 경우 DynamoDB 외부로 파이프라인을 만들어 분석을 수행해야합니다. <br>디자인 패턴 <br>비정규화 ]]></description><link>prj/cloudy/dynamo-db-채팅-내역-저장을-위한-키-설계.html</link><guid isPermaLink="false">Prj/Cloudy/Dynamo DB - 채팅 내역 저장을 위한 키 설계.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sat, 08 Jun 2024 03:33:24 GMT</pubDate><enclosure url="https://i.imgur.com/o7S8mKQ.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/o7S8mKQ.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Flux를 활용한 SSE 구현기]]></title><description><![CDATA[ 
 <br><br><br>다양한 EventSreaming 구현방식에 대해 알아봅니다. 또한 Cloudy의 채팅 에 왜 SSE를 선택했고 어떻게 개발했는지 사례를 공유합니다. 기술적 내용에 대해 자세히 알고 싶다면 하단 참고 자료에 관련 링크들을 참조해주세요<br>아래와 같은 키워드가 등장합니다. 본문에서 개념에 대해 설명하며 진행할 예정이나, 관련 배경지식이 있다면 더 쉽게 이해할 수 있습니다. <br>
<br>Event Streaming
<br>SSE
<br>Webflux의 Flux 
<br>Nginx 
<br><br>Cloudy 챗봇들은 질문이 들어오면 다음과 같이 작동합니다. <br>1. AOP가 적용되어 있어 불건전 질문을 자동으로 필터링합니다. 
2. 질문에 대해서 관련 AWS 서비스, it 키워드로 추출합니다. 
3. 추출해낸 키워드를 바탕으로 Vector DB[pinecone]에서 관련 데이터를 찾습니다. 
4. 찾아낸 데이터를 바탕으로 최종 답변을 생성해냅니다. 
Copy<br>REST API로 처리할 경우, 1~4 과정(평균 6~8초) 동안 사용자는 로딩 스피너만 바라보는 상황이 발생합니다.  특히 ChatGPT API를 활용해서 답변을 생성해 내는 시간이 가장 오래 걸립니다. Chat GPT Streaming API와 SSE를 조합해 답변을 생성 중 일지라도, 데이터를 실시간으로 받아볼 수 있게끔 개선하였습니다. <br><img alt="chatbotOudy.gif" src="lib/media/chatbotoudy.gif"><br><br>
먼저 SSE 뿐만 아니라, Polling 등 여러 관련된 방식을 포함하는 Event Streaming을 구현할 수 있는 여러 방법에 대해 알아봅시다.
<br><br><img src="https://i.imgur.com/VS9erwz.png" referrerpolicy="no-referrer"><br>
<br>주기적으로 클라이언트가 서버에 요청을 보냅니다. 
<br>서버는 데이터나 이벤트가 없으면 빈 값을, 있으면 값을 보내줍니다. 
<br><br>
<br>클라이언트에서 대기하는 시간이 길다면 실시간성이 떨어지고, 대기하는 시간이 짧다면 서버에 부담이 간다. 
<br><br><img src="https://i.imgur.com/jMlQ8Wo.png" referrerpolicy="no-referrer"><br>
<br>주기적으로 클라이언트가 서버에 요청을 보냅니ㅣ다. 
<br>서버는 바로 응답하는 것이 아닌, 데이터가 발생하거나, 타임아웃이 발생하면 클라이언트에 응답을 전달합니다. 
<br>클라이언트는 응답을 받은 후 대기를 하지 않고 바로 long poll 요청을 전달합니다. 
<br>쉽게 구현할 수 있습니다. 
<br>이벤트, 데이터가 생길 때 마다 응답을 돌려주기 때문에 실시간성이 높습니다. 
<br><br>
<br>요청과 응답 모두 독립적이기 때문에 header를 모두 포함합니다.<br>
--&gt; 원래는 하나의 http 응답입니다. 공통되는 요소를 반복해서 보내야하기 때문에 오버헤드가 발생합니다.
<br>클라이언트와 서버 모두 TCP/IP 연결을 연상태로 대기합니다.<br>
-&gt; 한정된 커넥션 풀과 관련된 리소스를 신경써야합니다.
<br>클라이언트에게 제공할 이벤트가 큐에 쌓이면 각각의 이벤트를 단건으로 여러개의 long poll 요청에 나눠서 전달해야합니다. 
<br>브라우저, gateway 등 다른 구성요소의 timeout을 고려하여 대기 시간을 설정해야합니다. 
<br><br>
클라이언트와 서버가 연결된 상태에서 지속적으로 데이터를 얻는 방식입니다.<br>
주로 비디오 스트리밍, 음악 스트리밍 등 대용량의 연속적인 데이터 전송에 사용됩니다. 
<br>
Long Polling과 다르게, 하나의 http 응답을 여러개의 http응답으로 나눠서 보내는 것이 아닌, http 응답을 잘게 짤라서(=chnuk 단위)보냅니다.
<br><br>
<br>
HTTP/1.1또는 HTTP/2를 사용할 수 있습니다 

<br>
HTTP/2의 경우 멀티플렉싱을 이용할 수 있습니다. 

<br>
클라이언트가 서버에 요청을 보냅니다. 

<br>
서버가 전달할 이벤트, 데이터 등이 있다면 응답의 일부분을 전달합니다. 

<br>
요청이나 연결을 닫지 않고 이벤트, 데이터를 전달할 때까지 대기합니다. 

<br><br>
동적으로 content를 생성하는 경우 정확한 Content-Length 를 미리 제공할 수 없기 때문에 아래의 방식으로 HTTP Streaming을 구현합니다. 
<br><br>
<br>Transfer-Encoding:chunked 를 헤더에 추가합니다. 
<br>텅 빈 chunk를 전달하기 전까지 값을 읽습니다. 
<br>Http/1.1 이상에서만 사용할 수 있습니다. 
<br><br>
<br>Connection: close 를 헤더에 추가합니다. 
<br>서버가 연결을 종료할때까지 들어오는 값을 읽습니다. 
<br><br>
이벤트 스트리밍을 단방향으로 언제든지 가능하게 합니다.<br>
텍스트 기반의 실시간 업데이트에 적합합니다. 
<br>
<br>이벤트 : 정의한 포멧에 따라 UTF-8f로 인코딩된 텍스트 데이터의 스트림 
<br><br><img src="https://i.imgur.com/LZEifhF.png" referrerpolicy="no-referrer"><br>
<br>클라이언트가 서버에 EventSource 객체를 사용해 연결을 엽니다. 
<br>서버는 text/event-stream MIME 타입을 사용해 이벤트를 전송합니다. 
<br>연결은 클라이언트가 끊을 때까지 지속합니다. 
<br><br>
<br>HTTP/1.1 을 사용합니다. 
<br><br><br>
관련된 기술로서 가장 먼저 생각나는 것은 웹소켓입니다. Websocket이 아닌, SSE를 선택한 이유는 크게 두가지였습니다. 
<br><br><br><img src="https://i.imgur.com/bV6f0SG.png" referrerpolicy="no-referrer"><br><br><img src="https://i.imgur.com/sFJBUBH.png" referrerpolicy="no-referrer"><br>특징을 정리해봅시다. SSE는 서버에서 데이터가 생성될 때마다 stream하는 단방향통신이고, websocket은 핸드 셰이크를 통해 커넥션을 수립하기 때문에 , 클라이언트와 서버 둘다 양방향 통신이 가능합니다. <br>Cloudy에서 제공하는 챗봇을 사용할 때 유저 플로우를 살펴봅시다. <br>1. 유저가 질문을 입력한다. 
2. 답변이 나올 때까지 기다린다. 
3. 답변을 받고나서 질문을 입력한다. 
Copy<br>기존 채팅의 유저 플로우를 살펴봅시다. <br>1. 유저가 질문을 입력한다. 
2. 답변이 나올때까지 기다린다. or 답변이 오기전 다른 대화 주제로 틀어버릴 수 있다. 

Copy<br>2번 과정을 비교해보겠습니다. 일반 사용자끼리의 채팅처럼 일상적인 대화의 경우, 상대방의 대화를 듣기 전 대화 주제가 변할 수 있습니다. 즉, 응답을 받고 있는 중에도 채팅을 보낼 수 있어야합니다. 하지만 Cloudy 처럼 QNA와 관련된 챗봇의 특성상 사용자가 질문을 하자마자 주제가 바뀔 우려는 거의 없습니다. 왜냐하면 사용자는 질문에 대해 답변을 받고 그 답변을 바탕으로 다른 질문을 생성해내기 때문입니다.<br>
즉, cloudy의 서비스 특성상, 사용자 입장에서는 답변이 생성되고 있는 중에, 다른 질문을 보내는 것보다는 완성된 답변을 읽고 답변의 내용을 바탕으로 다른 질문을 보낼 확률이 더 큽니다. 사실상 단방향 통신인 셈입니다. 때문에 서비스의 특성상 one-way communication을 지원하는 SSE로 챗봇을 구현하더라도 크게 상관 없겠다는 판단이 들었습니다. <br><br>웹소켓을 구현할 경우 고려하고 관리해야하는 범위가 늘어납니다. <br>
<br>웹소켓 핸드 셰이크를 위한 config 클래스 
<br>stomp 환경에서 작동할 수 있는 메시징 브로커 그 자체

<br>메시징 브로커와 관련된 Config 클래스들 


<br>채팅 publish와 로그 저장, 채팅 로그 조회 관련된 클래스 
<br>하지만 SSE를 활용하여 구현할 경우 Websocket보다는 고려하고 관리해야하는 범위가 좁습니다. <br>
<br>핸드 셰이크가 필요없이 단일한 REST API 하나를 이용해서 응답을 주고 받습니다. 
<br>메시징 브로커를 쓰지 않습니다.
<br>채팅 publish를 할 필요가 없으며 로그 저장 및 채팅 로그 조회 관련 클래스만 구현하면 됩니다, 
<br><br><img src="https://i.imgur.com/phuHdqN.png" referrerpolicy="no-referrer"><br>
<br>Chunked Transfer-Encoding 기반입니다. 
<br>chunk 단위로 여러 줄로 구성된 문자열을 전달합니다. 
<br>new line으로 이벤트를 구분합니다. 
<br>각각의 문자열은 일반적으로 &lt;field&gt;:&lt;value&gt; 형태로 구성됩니다. 
<br><br><br><br><br>
<br>클라이언트가 서버에 EventSource 객체를 사용해 연결을 엽니다. 
<br>서버는 text/event-stream MIME 타입을 사용해 이벤트를 전송합니다. 

<br>서버는 유저 질의를 OpenAI의 Streaming ChatModel을 사용하여 실시간으로 데이터를 받아들이고 이를 Reacive Stream 의 Fluxfh 반환합니다. 


<br>연결은 클라이언트가 끊을 때까지 지속합니다. 
<br><br>
응답을 Flux로 반환하기 때문에, Flux와 FluxSink에 대해서 알아보고 가겠습니다. 
<br><br>
0~N개의 데이터 항목을 비동기적으로 스트리밍하는 Publisher를 나타냅니다.<br>
데이터 스트림을 처리하고 변환하는 다양한 연산자를 제공합니다. 
<br><br>
Flux.create와 함께 사용하며, Flux의 데이터를 push 방식으로 제공할 수 있게끔합니다. 또한 Flux 스트림 내에서 데이터를 동적으로 생성하고 내보낼 수 있습니다. 
<br>
<br>next, complete, error 메서드를 오버라이딩하여 데이터를 전송하거나 스트림의 완료, 에러 시 처리를 커스텀할 수 있습니다. 
<br><br>
두 객체를 활용해 스트림을 동적으로 생성하고 데이터를 push할 수 있습니다.<br>
Flux.create 메서드는 FluxSink를 인자로 받아 데이터를 스트림에 공급할 수 있는 Flux를 생성합니다. 
<br><br>
클라이언트로 부터 유저 질의를 받아 실시간으로 생성되는 챗봇의 응답을 스트리밍하는 컨트롤러 입니다. 
<br>  

@PostMapping(produces = MediaType.TEXT_EVENT_STREAM_VALUE)
public Flux&lt;String&gt; generateChat(@RequestBody ChatReq question,   
								 @AuthenticationPrincipal Member member) {

	
	return chatBotService.question(question, member.getId());

}

Copy<br>produces = MediaType.TEXT_EVENT_STREAM_VALUE<br>
이 API의 반환 값이 text/event-stream MIME 타입임을 명시합니다. <br>Flux<br>
스트리밍 방식으로 여러개의 문자를 전송하기 위해서 Project Reactor의 Flux 타입을 사용합니다. <br><br>
Open AI의 Streaming Chat Model을 사용하여 실시간으로 데이터를 받아들이고, 이를 Reactive Streams의 Flux로 변환하여 반환합니다.
<br>

  

@Override
public Flux&lt;String&gt; generateStreamingChat(String template, 
										  Map&lt;String, Object&gt; variables, 
										  String userId, Chatbot chatbot) {

  

	Prompt prompt = getPrompt(template, variables);
	
	
	if (openAiStreamingChatModel == null) {
	openAiStreamingChatModel = OpenAiStreamingChatModel.builder()
								.apiKey(openAiKey)
								.modelName(GPT_3_5_TURBO)
								.build();
	}

  
  
  

	return Flux.create(emitter -&gt;
			openAiStreamingChatModel.generate(prompt.text(), 
			new StreamingResponseHandler&lt;&gt;() {
			
			  
			
			@Override
			public void onNext(String token) {
				emitter.next(token);
			}
			
			  
			
			@Override
			public void onComplete(Response&lt;AiMessage&gt; response) {
				chatQueryService.saveChat(userId, 
										 . chatbot, 
										   . response.content().text(), 
											false
										);
			
				emitter.complete();
			}
			
			  
			  
			
			@Override
			public void onError(Throwable error) {	
				log.error("[OpenAiChatService generateStreamingChat] 에러 발생 ::{}", error);
				emitter.next("에러가 발생했습니다. 관리자에게 문의하세요.");
				emitter.complete();
	
			}));

}
Copy<br>Flux.create<br>
Flux 스트림을 생성합니다. emitter는 FluxSink 객체로, 데이터 스트림을 내보낼 수 있습니다. Flux.create는 데이터를 생성하고 Flux.sink를 통해 비즈니스 로직을 제공받아 가공된 Flux를 생성합니다. <br>emitter<br>
FluxSink 인터페이스의 인스턴스입니다. 데이터를 Flux 스트림으로 내보냅니다. next, complete, error 등의 메서드를 오버라이딩하여 스트림을 제어할 수 있습니다. <br>StreamingResponseHandler<br>
Open AI의 스트리밍 응답을 처리하기 위해 해당 StreamingResponseHandler를 사용합니다. 이 핸들러를 사용하기 위해서는 onNext, onComplete, onError 3가지 메서드를 구현해야합니다. <br>onNext 메서드 <br>
실시간으로 생성되는 데이터를 수신했을 때 onNext 메서드를 호출합니다.<br>
emitter.next(token) 을 호출해 받은 데이터를 Flux 스트림으로 전달합니다. 
<br>@Override
public void onNext(String token) {
	emitter.next(token);
}

Copy<br>onComplete 메서드 <br>
스트리밍이 완료되었을 때 호출합니다. 
<br>@Override
public void onComplete(Response&lt;AiMessage&gt; response) {
    chatQueryService.saveChat(userId, 
							  chatbot, 
                              response.content().text(), 
                              false
                             );

    emitter.complete();
}

Copy<br>
<br>다음 접속시에 채팅 내역을 제공해야하기 때문에 Dynamo DB를 활용해 채팅 내용을 저장합니다. 
<br>emitter.complete()  를 호출하여 Flux 스트림을 활용합니다. 
<br>onError 메서드 <br>
스트리밍 중 에러가 발생했을 때 호출합니다. 
<br>
@Override
public void onError(Throwable error) {	
	log.error("[OpenAiChatService generateStreamingChat] 에러 발생 ::{}", error);
	emitter.next("에러가 발생했습니다. 관리자에게 문의하세요.");
	emitter.complete();
}));

Copy<br>원래는 emitter.error() 를 활용해 Publisher에서 에러를 발생시켜야합니다. 하지만, 특정 에러 응답을 반환하기 보다는, 서버에서 에러 로깅 후 클라이언트 대화창에서 바로 에러메시지를 출력하기로 구현 스펙을 결정했기 때문에 다음과 같은 비즈니스 로직으로 구현하였습니다. <br>
<br>에러를 로깅한다. 
<br>대화 로그에 에러 발생 메시지를 포함시킨다. 
<br>스트리밍을 종료한다. 
<br><br><br>Nginx의 디폴트 값<br>
Nginx는 기본적으로 업스트림 요청을 보낼 때, HTTP/1.0버전을 사용합니다. 하지만 SSE는 HTTP/1.1버전 부터 사용할 수 있습니다.<br>
또한 Connection:close 헤더를 사용합니다. SSE는 지속 연결이 되어 있어야하는데, Nginx에서 바로 지속연결을 닫아버리기 때문에 문제가 발생합니다. <br>변경된 설정값<br>proxy_set_header Connection '';
proxy_http_version 1.1;
Copy<br><br>Proxy Buffering이란<br>
클라이언트와 서버 중간에 위치한 Nginx는 트래픽 최적화를 위해, 요청 및 응답을 일시적으로 저장하고 처리합니다. <br>SSE와 Proxy Buffering의 관계<br>
SSE의 특성상 실시간으로 데이터를 스트리밍합니다. 이 스트리밍된 데이터는 바로바로 유저에게 전달되어야합니다. Proxy Buffering이 켜져있을 경우 Nginx가 서버의 응답을 일부 버퍼에 저장하고 버퍼가 차거나 응답 데이터를 모두 전송했을 경우 한번에 클라이언트로 전송합니다. 즉 원래 기능 명세대로, 한글자씩 반환하는 것이 아닌 몇 줄에 한번씩 클라이언트는 답변을 확인할 수 있어 실시간성이 떨어지게 됩니다. <br>X-Accel 활용하기<br>@PostMapping(produces = MediaType.TEXT_EVENT_STREAM_VALUE) 
public Flux&lt;String&gt; generateChat(@RequestBody ChatReq question, 
								 @AuthenticationPrincipal Member member, 
								 ServerHttpResponse response) { 
	log.info("{}", question); 
	headers = response.getHeaders(); 
	headers.add("X-Accel-Buffering", "no"); 
	return chatBotService.question(question, member.getId()); }
}
Copy<br>응답 헤더에 X-accel로 시작하는 헤더가 있으면 Nginx는 버퍼링을 수행하지 않습니다. &nbsp;SSE 응답을 반환하는 API의 헤더에&nbsp;X-Accel-Buffering: no를 붙여줘 SSE 응답만 버퍼링을 하지 않도록 설정하였습니다. <br><br><br>확인해야할 사항<br>
SSE 통신을 하는 동안에는 HTTP Connection이 계속 열려있습니다. 챗봇은 기본적으로 Dynamo DB에 채팅 로그를 저장합니다. HTTP 연결이 지속되는 동안에 DynamoDB 커넥션이 열려있는지 확인하는 과정이 필요합니다. <br>만약 커넥션이 열려있다면?<br>DynamoDB의 제약조건 (파티션)<br>
<br>초당 1k WCU(4kb/s or req/s)제공 
<br>초당 3k RCU(1kb/s or req/s) 제공 
<br>RCU와 WCU는 독립적으로 동작 
<br>10GB 
<br>Dynamo DB의 장점은 <br>Dynamo DB의 세벌복제 시스템 <br>
<br>데이터는 항상 3개의 가용영역에 복제됩니다. 
<br>서비스는 3개의 가용 영역에서 실행됩니다. 
]]></description><link>prj/cloudy/flux를-활용한-sse-구현기.html</link><guid isPermaLink="false">Prj/Cloudy/Flux를 활용한 SSE 구현기.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sat, 08 Jun 2024 03:35:09 GMT</pubDate><enclosure url="lib/media/chatbotoudy.gif" length="0" type="image/gif"/><content:encoded>&lt;figure&gt;&lt;img src="lib/media/chatbotoudy.gif"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[콘팅이 서비스를 잘게 쪼갠 이유]]></title><description><![CDATA[ 
 <br><br><br><img src="https://i.imgur.com/GT8yXth.png" referrerpolicy="no-referrer"><br><br>티케팅 서비스에서 가장 많은 트래픽이 발생하는 비즈니스 로직은 예매 과정이라 생각합니다. 저희 백엔드 팀의 목표는 예매 과정에서 최대한의 가용성을 보장하도록 시스템을 설계하고자 했습니다.<br>먼저 예매시 유저 플로우를 분석하였습니다.<br>먼저 콘팅의 예매시 유저 플로우를 알아보겠습니다. 다음과 같은 유저 플로우를 가집니다.<br>
<img src="https://i.imgur.com/BCFDYeB.png" referrerpolicy="no-referrer"><br><img src="https://i.imgur.com/FdOfVkH.png" referrerpolicy="no-referrer"><br>짧은 시간동안 여러 페이지를 옮겨 다니면서 다양한 API를 호출합니다. 해당 플플로우에서는 짧은 시간 내에 DB IO, Network IO가 대량으로 일어납니다. 짧은 시간 동안 시스템에서 일어나는 IO의 양이 많을 경우 가장 좋은 해결책은 비동기 방식이라 생각했습니다.<br>&lt;결제/티켓&gt; 도메인을 따로 분리한 이유<br>하지만 결제 시스템을 비동기 방식으로 적용하기에는 리스크가 크다고 생각했습니다. 국내 결제 시스템 특성상 PG 사와의 통신을 통해 결제 로직이 구현되고 관련된 트랜잭션을 고려한다면, 비동기는 적합하지 않습니다.<br>그렇다고 같은 프로젝트 내에서 r2dbc(비동기 방식 ORM)와 jpa(동기 방식 ORM)를 동시에 사용할 경우 각 구현체는 서로 다른 패키지에 포함되어야만하고 설정 클래스에서도 컴포넌트 스캔할 대상을 일일히 지정해야했기 때문에 코드간 결합성이 증가하고 유지보수하기가 어려워집니다.<br>R2DBC와 JPA/JDBC 용 repo를 같은 패키지 내에 배치하면 한쪽 Repo를 못찾거나 지원 예외가 발생합니다. 때문에 아래 코드와 같이 repo패키지를 분리후 각각의 repo 패키지를 설정해야합니다. 위 같은 방식은 repo의 개수가 늘어날 때마다 Config 클래스에 불필요한 보일러 플레이트를 생성합니다. 특히 레이어별로 정리한 폴더구조가 아닌 도메인별로 정리한 폴더 구조일 경우 *의 활용도 불가능합니다. <br>@EnableJpaRepositories("com.c209.payment.domain.order.repository.sync")
@EnableR2dbcRepositories("com.c209.payment.domain.order.repository.async")
Copy<br>로직에 알맞은 비동기 방식, 동기 방식을 구현하고, 코드의 유지보수성을 늘리고 확장성을 고려하여 “좌석”과 “결제/티켓” 도메인을 분할하였습니다.<br>대기열 서비스를 추가한 이유<br>
<img src="https://i.imgur.com/7Dcvgzu.png" referrerpolicy="no-referrer"><br>동기 방식을 채택한 “결제/티켓” 서비스의 핵심은 일정 트래픽이 넘지 않도록 제한해야합니다. 서비스 특성상 특정시간(예매 가능시간)이 되면 스파이크성 트래픽이 발생합니다. 스파이크성 트래픽이 발생할 경우, 동기 방식에서 치명적이라 판단하였습니다. 스파이크성 트래픽이 결제 서비스에 발생하는 것을 방지하기 위해, 대기열 서버를 추가하였습니다. 결제시 유저 플로우는 다음과 같이 바뀝니다.<br><img src="https://i.imgur.com/QLW8HpK.png" referrerpolicy="no-referrer"><br>결제와 티켓 도메인을 분할한 이유<br>서비스 특성상 결제와 티켓 발행 로직은 같은 서비스에 처리하여 트랜잭션을 보장하는 것이 맞습니다. 하지만 콘팅에서는 QR 기반 티켓을 제공합니다. 티켓의 검표과정 또한 처리해야하기 때문에 다음과 같은 특수한 상황에서 문제가 발생합니다.<br>A 가수의 공연 예매일과 B가수의 공연 당일이 겹쳤을 경우 
Copy<br>A가수의 공연을 예매하기 위해서 결제 API가 요청이, B가수의 티켓 검표를 진행하기 위해 티켓 API 요청이 동시에 발생합니다. 위와 같은 상황을 가정했을 때, 티켓 서비스와 결제 서비스를 안정적으로 처리하기 위해 두 서비스를 분리하였습니다.<br><br><br>서비스를 분할할수록 비즈니스 로직에 따라 서비스 간의 데이터 정합성을 맞추는 것이 중요합니다.<br>
<br>kafka를 활용한 비동기 큐로 결제서비스가 pub, 좌석 서비스와 티켓서비스가 Sub으로 구현하였습니다. 결제 발생시 좌석 서비스에서는 결제된 좌석이&nbsp;사용 불가능한 좌석으로 업데이트, 티켓 서비스는&nbsp;구매 유저와 좌석 정보를 바탕으로 티켓을 생성합니다.
<br>최종 결제 수행 전 webhook을 활용해 해당 좌석이&nbsp;여전히 구매 가능한 좌석인지 좌석 서비스에서 조회하는 로직을 추가했습니다.
<br><br>콘팅에서는 카프카를 비동기 메시징 큐로 활용합니다. 카프카는 분산 스트리밍 플랫폼으로, 대량의 데이터를 처리하고 실시간으로 전송하는 데 사용합니다. 모든 데이터는 로그 형식으로 파일 시스템에 기록됩니다. 시간순으로 완전히 정렬된 데이터 흐름(=레코드 시퀀스)를 보장합니다. 로그를 한곳에 모아 처리할 수 있도록 중앙집중화되어 있으며, 대용량 데이터를 수집하고 실시간 스트리밍으로 소비할 수 있습니다. <br>레코드는 프로듀서가 보낸 순서로 기록되어 순서가 보장됩니다. 레코드의 위치(offset)으로 컨슈머가 소비한 메시지의 위치를 표시합니다. 각 컨슈머 그룹마다 레코드의 위치를 가지고 있기 때문에 같은 소스에서 서로 다른 여러 개의 컨슈머들이 개별적으로 소비할 수 있습니다. 한 소스에서 여러 소비자가 손실이나 변형 없이 메시지를 소비할 수 있습니다. <br><img src="https://i.imgur.com/zefHRap.png" referrerpolicy="no-referrer"><br><br><br>결제와 티켓 발급을 처리하는 방식으로 분산 시스템 이벤트 기반 아키텍처를 사용하고 있습니다. 콘팅의 분산시스템이 어떻게 나뉘어 있는지 간략하게 설명하고, 카프카를 팀에서 활용하는 방식을 소개하겠습니다. <br>결제 이벤트를 받아 티켓을 발급하는 로직, 결제 이벤트를 받아 <br><br>DB가 분리되면서 편하게 join이 불가능해집니다. join 쿼리가 발생할 경우 network io가 추가로 발생하게 됩니다. 관련해서 문제가 발생하는 API가 있었습니다. 바로 내가 가지고 있는 입장권 조회입니다.<br>
<img src="https://i.imgur.com/JO9ZjAV.png" referrerpolicy="no-referrer"><br>내가 가진 입장권을 출력하기 위해서는 티켓 서비스에서 user_id로 내가 가진 티켓 정보(공연 id, 좌석 id)를 조회해와야합니다.<br>
<img src="https://i.imgur.com/8ds8OTw.png" referrerpolicy="no-referrer"><br>select seat_id, performance_id from ticket where user_id = :userId
Copy<br>조회해온 seat_id와 performance_id로 카탈로그 서비스 API에서 공연 정보를 조회해야합니다.<br>select {공연 메타데이터 칼럼들} from performance 
where performance_id in {앞선 쿼리에서 조회한 performance_id들}
Copy<br>보시는 바와 같이, 서비스간 결합성이 생기고 불필요한 네트워크 IO와 DB IO가 발생합니다. 이를 해결하기 위해서 모바일 로컬 DB인 Realm을 활용했습니다.<br>스플래시 화면에서 공연 정보를 먼저 조회해와 realm에 저장합니다.<br>
<img src="https://i.imgur.com/clIDFvq.png" referrerpolicy="no-referrer"><br>사용자가 입장권 페이지에 접속할 때는 단순히 티켓 서비스에서 내가 가지고 있는 티켓의 공연 id만 조회해온 후 realm에서 공연 데이터를 찾아 페이지를 렌더링하는 방식으로 구현했습니다.<br><img src="https://i.imgur.com/MXyEUyE.png" referrerpolicy="no-referrer">]]></description><link>prj/conting/콘팅이-서비스를-잘게-쪼갠-이유.html</link><guid isPermaLink="false">Prj/Conting/콘팅이 서비스를 잘게 쪼갠 이유.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sat, 08 Jun 2024 04:21:55 GMT</pubDate><enclosure url="https://i.imgur.com/GT8yXth.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.imgur.com/GT8yXth.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[ALB - Application Load Balancer]]></title><description><![CDATA[ 
 <br><br>
7계층에서 동작하는 로드밸런서 입니다. 트래픽을 균형있게 나누어줍니다.
<br><br>
트래픽을 여러 대상에 자동으로 분산시켜 안정적인 운용을 할 수 있습니다.
<br>
<br>EC2뿐만 아니라 컨테이너(ECS), 서버리스(Lambda) 등으로 다양한 서비스와 연계하여 부하를 분배할 수 있습니다.<br>

<br>서로 다른 EC2에 대한 하나의 엔드포인트를 제공합니다.<br>

<br>부하 분산 대상에 대한 헬스 체크, 고정 세션, ssl Offload, 다운서버 제외 기능을 제공합니다.<br>

<br><br><img src="https://hanju.gitbook.io/~gitbook/image?url=https%3A%2F%2F102830355-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FfNpWAsJfDNQXNBCChExd%252Fuploads%252FuEVaLGfjsShiUrHBYllh%252Fimage.png%3Falt%3Dmedia%26token%3Df5a11a54-fadd-49e5-ad48-5973920829bc&amp;width=768&amp;dpr=4&amp;quality=100&amp;sign=af6f198d520aed36cd5bd6b758108b905fd27ff37c455b31fa04467eb73f43e1" referrerpolicy="no-referrer"><br><a rel="noopener" class="external-link" href="https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/introduction.html" target="_blank">https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/introduction.html</a><br>
<br>
위 사진과 같이 Load Balancer, Listener, Target Group으로 나누어져 있습니다.

<br>
기본적으로 VPC에 탑재되며 사용자 요청을 받고, 이를 VPC 내의 리소스에 적절히 부하분산합니다.

<br>
외부의 요청을 받아들이는 리스너, 요청을 분산 전달할 수 있는 리소스의 집합인 대상그룹으로 구성됩니다.

<br>
ELB는 다수의 리스너와 대상 그룹을 거느릴 수 있습니다.

<br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/alb-application-load-balancer/undefined" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/alb-application-load-balancer/undefined" target="_blank">PAGE구성요소</a><br><br>
<br>
앱의 트래픽을 여러 가용영역으로 분산합니다.

<br>
리스너를 이용해 RL, 호스트, 헤더, 메소드를 기반으로 규칙을 구성하여 요청을 처리할 수 있습니다.

<br>
트래픽 부하에 따라 자동으로 스케일 업, 다운을 수행할 수 있습니다.

<br>
하나 이상 타겟 그룹에 라우팅할 수 있으며 각 그룹별 가중치 설정이 가능합니다.

<br>
SSL Offloading을 지원합니다.

<br>
디폴트 알고리즘은 라운드 로빈이며, 최소 미해결 요청 라우팅 알고리즘을 지원합니다.

<br>
교차 영역 로드 밸런싱을 통해 AZ의 모든 타겟 그룹에 트래픽을 분산합니다.

<br><a data-href="고가용성 및 스케일링" href="고가용성 및 스케일링" class="internal-link" target="_self" rel="noopener">고가용성 및 스케일링</a>]]></description><link>0.-aws/1.-고가용성-및-스케일링/alb/alb.html</link><guid isPermaLink="false">0. AWS/1. 고가용성 및 스케일링/ALB/ALB.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 07:09:51 GMT</pubDate><enclosure url="https://hanju.gitbook.io/~gitbook/image?url=https%3A%2F%2F102830355-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FfNpWAsJfDNQXNBCChExd%252Fuploads%252FuEVaLGfjsShiUrHBYllh%252Fimage.png%3Falt%3Dmedia%26token%3Df5a11a54-fadd-49e5-ad48-5973920829bc&amp;width=768&amp;dpr=4&amp;quality=100&amp;sign=af6f198d520aed36cd5bd6b758108b905fd27ff37c455b31fa04467eb73f43e1" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="https://hanju.gitbook.io/~gitbook/image?url=https%3A%2F%2F102830355-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FfNpWAsJfDNQXNBCChExd%252Fuploads%252FuEVaLGfjsShiUrHBYllh%252Fimage.png%3Falt%3Dmedia%26token%3Df5a11a54-fadd-49e5-ad48-5973920829bc&amp;width=768&amp;dpr=4&amp;quality=100&amp;sign=af6f198d520aed36cd5bd6b758108b905fd27ff37c455b31fa04467eb73f43e1"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[고가용성]]></title><description><![CDATA[<a class="tag" href="?query=tag:AWS" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#AWS</a> 
 <br><br><br>
고가용성은 시스템이 예상치 못한 장애나 문제에도 계속해서 가용하고 작동하는 능력을 가리킵니다. 이는 시스템의 가용성을 유지하기 위해 여러 가용 영역에 걸쳐 리소스를 분산하는 등의 방법을 포함할 수 있습니다.
<br><br><br>
스케일링은 시스템이 사용자 또는 트래픽 증가에 유연하게 대응할 수 있는 능력을 의미합니다. 이는 자동으로 리소스를 확장하거나 축소하여 수요에 맞게 조정하는 것을 포함할 수 있습니다.
<br><br><br>
<br>Elastic Load Balancing (ELB):

<br>고가용성: ELB는 여러 가용 영역에 걸쳐 로드 밸런싱을 수행하여 장애 발생 시에도 트래픽을 안정적으로 분산합니다.
<br>스케일링: ELB는 Auto Scaling 그룹과 통합하여 자동으로 인스턴스를 확장하거나 축소하여 트래픽에 대응합니다.


<br>Amazon EC2 Auto Scaling:

<br>고가용성: Auto Scaling은 여러 가용 영역에 인스턴스를 배포하여 고가용성을 제공하며, 인스턴스 장애 시 자동으로 대체 인스턴스를 시작합니다.
<br>스케일링: Auto Scaling은 정의된 조건에 따라 자동으로 인스턴스를 확장하거나 축소하여 트래픽에 대응합니다.


<br>Amazon RDS Multi-AZ (Multi-Availability Zone) Deployment:

<br>고가용성: RDS Multi-AZ는 프라이머리 데이터베이스와 스탠바이 데이터베이스를 여러 가용 영역에 걸쳐 설정하여 장애 발생 시 자동으로 스위치하여 가용성을 제공합니다.
<br>스케일링: RDS는 수동 또는 자동 스케일링을 통해 데이터베이스 인스턴스의 크기를 조정할 수 있습니다.


<br><a data-href="ALB" href="0.-aws/1.-고가용성-및-스케일링/alb/alb.html" class="internal-link" target="_self" rel="noopener">ALB</a><br><a href=".?query=tag:AWS" class="tag" target="_blank" rel="noopener">#AWS</a>]]></description><link>0.-aws/1.-고가용성-및-스케일링/1.-고가용성-및-스케일링.html</link><guid isPermaLink="false">0. AWS/1. 고가용성 및 스케일링/1. 고가용성 및 스케일링.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 10:42:07 GMT</pubDate></item><item><title><![CDATA[0 CloudFormation]]></title><description><![CDATA[ 
 <br>1.Cloud Formation이란?<br>
AWS 리소스 생성 및 배포 자동화 템플릿 서비스입니다.
<br>
<br>AWS 리소스를 모델링하고 설정합니다.

<br>리소스 관리 시간을 줄일 수 있습니다.


<br>AWS 리소스를 설명하는 템플릿(=코드)를 생성하면 리소스의 프로비저닝과 구성을 담당합니다.
<br><br><br><img src="https://hanju.gitbook.io/~gitbook/image?url=https%3A%2F%2F102830355-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FfNpWAsJfDNQXNBCChExd%252Fuploads%252FSGEXGnQfYFl1GV94AXeZ%252Fimage.png%3Falt%3Dmedia%26token%3Dbc8a4eca-5c7a-4f79-bdfa-432e12b2e396&amp;width=768&amp;dpr=4&amp;quality=100&amp;sign=c1ce24f89c350ac9d93c8516d900243166fce2b0bc7954435800b0b33facf49a" referrerpolicy="no-referrer"><br>
<br>Cloud Front에서 실행하는 호출은 모두 템플릿으로 선언됩니다.
<br>해당 템플릿을 local이나 S3에 저장합니다.
<br>Cloudformation에서 템플릿을 활용해 AWS 리소스를 생성하고 스택을 생성합니다.
<br><br><br><br>
리소스 모음을 단일 단위(스택)으로 쉽게 관리할 수 있습니다.
<br><br>
각 개별 서비스를 사용하여 프로비저닝해야하고 서비스간 연동을 진행해야합니다. 모든 작업을 마치고 애플리케이션을 제대로 실행하려면 복잡하고 많은 시간이 소요됩니다.
<br><br>
모든 리소스와 속성을 설명하는 템플릿을 사용합니다. 템플릿을 사용하여 Cloudfront에서 스택을 생성할 경우 필요한 서비스를 자동으로 프로비저닝합니다. 스택의 삭제, 관리가 용이합니다.
<br><br>
가용성을 확대해야하는 경우 여러 리전에서 애플리케이션을 복제할 수 있습니다.
<br><br>
복제시, 애플리케이션에 필요한 모든 AWS 서비스를 숙지, 각 리전에서 해당 서비스를 다시 구성해야합니다.
<br><br>
템플릿을 재사용하여 리소스를 일관되고 반복적으로 생산할 수 있습니다. 또한 여러 리전에서 동일한 리소스를 반복적으로 프로비저닝할 수 있습니다.
<br><br><br>
애플리케이션을 업데이트하고 문제가 발생할 경우 원래 설정으로 롤백해야합니다.<br>
변경된 리소스를 기억하고 원래 설정을 알고 다시 수동으로 복구해야합니다.
<br><br>
템플릿에서 차이점을 추적하여 인프라 변경사항을 추적할 수 있습니다. 형상관리시스템(git)을 활용하여 변경 내용, 변경 시간, 변경한 사람을 정확히 알 수 있습니다. 이전 버전으로 되돌려야할 경우 이전 버전의 템플릿을 사용하면 됩니다.
<br><br><br>
<br>
리소스에 대한 이해가 낮으면 사용하기가 어렵습니다.

<br>
배포에 필요한 모든 옵션을 직접 활용하기에는 설정이 많습니다.<br>


<br>
json, yaml 문법에서 각 참조 방식이 난해합니다.

<br>java같은 곳에서는 ctrl 키를 눌러 해당 함수의 구현체로 바로 이동이 가능합니다.
<br>반면에 json은 데이터를 표현하는 포멧이기 때문에 참조값 추적이 난해합니다.


<br>]]></description><link>0.-aws/1.-iac/cloudformation/0-cloudformation.html</link><guid isPermaLink="false">0. AWS/1. IaC/CloudFormation/0 CloudFormation.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 10:42:28 GMT</pubDate><enclosure url="https://hanju.gitbook.io/~gitbook/image?url=https%3A%2F%2F102830355-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FfNpWAsJfDNQXNBCChExd%252Fuploads%252FSGEXGnQfYFl1GV94AXeZ%252Fimage.png%3Falt%3Dmedia%26token%3Dbc8a4eca-5c7a-4f79-bdfa-432e12b2e396&amp;width=768&amp;dpr=4&amp;quality=100&amp;sign=c1ce24f89c350ac9d93c8516d900243166fce2b0bc7954435800b0b33facf49a" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="https://hanju.gitbook.io/~gitbook/image?url=https%3A%2F%2F102830355-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FfNpWAsJfDNQXNBCChExd%252Fuploads%252FSGEXGnQfYFl1GV94AXeZ%252Fimage.png%3Falt%3Dmedia%26token%3Dbc8a4eca-5c7a-4f79-bdfa-432e12b2e396&amp;width=768&amp;dpr=4&amp;quality=100&amp;sign=c1ce24f89c350ac9d93c8516d900243166fce2b0bc7954435800b0b33facf49a"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[스택]]></title><description><![CDATA[ 
 <br><br>
CloudFormation에서는 스택이라는 하나의 단위로 리소스들을 관리합니다.
<br><br>
<br>스택이라는 하나의 단위로 리소스를 관리합니다.<br>

<br>스택의 모든 리소스는 스택의 CloudFormation 템플릿으로 정의합니다.<br>

<br>스택에서 실행 중인 리소스를 변경해야하는 경우 스택을 업데이트합니다.<br>

<br><br>
스택의 설정을 변경하거나 리소스를 변경하는 경우 스택 업데이트를 이용해서 간편하게 변경할 수 있습니다.
<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-1" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-1" target="_blank"></a><br>2-1. 원리<br>
<br>변경사항(새 입력 파라미터 값 또는 업데이트된 템플릿)을 작성합니다.
<br>CloudFormation에서는 제출한 변경사항과 스택의 현재 상태를 비교하여 변경된 리소스만 업데이트합니다.
<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-2" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-2" target="_blank"></a><br>2-2. 업데이트 방법<br>
직접 업데이트와 변경 세트 생성 및 실행 총 두 가지 방법을 제공합니다.
<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#a" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#a" target="_blank"></a><br>a. 스택을 직접 업데이트<br>
<br>변경사항을 제출합니다.<br>

<br>AWS CloudFormation에서 즉시 해당사항을 배포합니다.<br>

<br>업데이트를 빠르게 배포할 때 사용합니다.<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#b" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#b" target="_blank"></a><br>b. 변경 세트 사용<br>
<br>AWS CloudFormation에서 스택에 대해 변경사항을 미리 확인합니다.
<br>변경사항을 적용할지 결정합니다.
<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-3" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-3" target="_blank"></a><br>2-3 스택 리소스의 업데이트 동작<br>
업데이트한 리소스의 경우 AWS CloudFormation에서는 다음 동작 중 하나를 사용합니다.
<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#a-1" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#a-1" target="_blank"></a><br>a.업데이트(무중단)<br>
해당 리소스의 작동을 중단하지 않고, 리소스의 물리적 ID를 변경하지 않는 상태에서 리소스를 업데이트합니다.
<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#b-1" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#b-1" target="_blank"></a><br>b.업데이트(중단)<br>
리소스를 업데이트하지만, 다소 중단이 발생합니다.
<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#c" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#c" target="_blank"></a><br>c.대체<br>
업데이트 도중 리소스를 다시 생성하며, 물리적 ID도 생성합니다.
<br>일반적인 방법은 아래와 같습니다.<br>
<br>리소스를 먼저 생성합니다.
<br>대체 리소스를 가리키도록 종속 리소스의 참조를 변경합니다
<br>이전 리소스를 삭제합니다.
<br>AWS 리소스 유형에 따라 업데이트하는 속성이 달라집니다. 각 속성에 대한 업데이트 동작은 <a data-tooltip-position="top" aria-label="https://docs.aws.amazon.com/ko_kr/AWSCloudFormation/latest/UserGuide/aws-template-resource-type-ref.html" rel="noopener" class="external-link" href="https://docs.aws.amazon.com/ko_kr/AWSCloudFormation/latest/UserGuide/aws-template-resource-type-ref.html" target="_blank">AWS 리소스 유형 참조</a>에 설명되어 있습니다.<br><br><a data-tooltip-position="top" aria-label="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-3.-aws" rel="noopener" class="external-link" href="https://hanju.gitbook.io/studynote/aws/iac/cloud-formation/undefined-1#id-2-3.-aws" target="_blank"></a><br>2-3. AWS 리소스를 대체해야하는 경우 설정하기<br>
RDS의 Port를 업데이트하는 경우 CloudFormation에서는 업데이트된 포트 설정을 사용하여 새 DB 인스턴스를 생성하고 대체하여 무중단 배포를 구성할 수 있습니다. 방법은 아래와 같습니다.
<br>
<br>현재 DB의 스냅샷을 생성합니다.
<br>DB 인스턴스를 바꾸는 동안 해당 DB를 사용하는 앱에서 중단을 처리할 방법을 준비합니다.
<br>앱에서 업데이트된 포트 설정과 기타 고려사항이 적용되었는지 확인합니다.
<br>DB 스냅샷을 사용하여 새 DB 인스턴스에서 정보를 복원합니다.
]]></description><link>0.-aws/1.-iac/cloudformation/스택.html</link><guid isPermaLink="false">0. AWS/1. IaC/CloudFormation/스택.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 06:53:02 GMT</pubDate></item><item><title><![CDATA[템플릿이란?]]></title><description><![CDATA[ 
 <br><br><br>
AWS 리소스 구축을 위한 청사진입니다.
<br>
<br>.json, .yaml, .template, .txt 등을 사용합니다.
<br><br><br>
ami-0ff8a91507f77f867 AMI ID, t2.micro 인스턴스 유형, testkey 키 페어 이름 및 Amazon EBS 볼륨을 사용하여 인스턴스를 프로비저닝하는 예시입니다.
<br><br>{
    "AWSTemplateFormatVersion": "2010-09-09",
    "Description": "A sample template",
    "Resources": {
        "MyEC2Instance": {
            "Type": "AWS::EC2::Instance",
            "Properties": {
                "ImageId": "ami-0ff8a91507f77f867",
                "InstanceType": "t2.micro",
                "KeyName": "testkey",
                "BlockDeviceMappings": [
                    {
                        "DeviceName": "/dev/sdm",
                        "Ebs": {
                            "VolumeType": "io1",
                            "Iops": 200,
                            "DeleteOnTermination": false,
                            "VolumeSize": 20
                        }
                    }
                ]
            }
        }
    }
}
Copy<br><br>AWSTemplateFormatVersion: 2010-09-09
Description: A sample template
Resources:
  MyEC2Instance:
    Type: 'AWS::EC2::Instance'
    Properties:
      ImageId: ami-0ff8a91507f77f867
      InstanceType: t2.micro
      KeyName: testkey
      BlockDeviceMappings:
        - DeviceName: /dev/sdm
          Ebs:
            VolumeType: io1
            Iops: 200
            DeleteOnTermination: false
            VolumeSize: 20
Copy<br><br><br>
템플릿에는 여러 주요 섹션이 포함되어 있습니다.
<br>
<br>Resources 섹션만 필수 섹션입니다.<br>

<br><br>
기본적으로는 임의 순서대로 지정이 가능하지만, 이전 섹션을 참고할 수 있습니다. 때문의 다음 순서를 사용하는 것이 좋습니다.
<br><br><br><br><br>
AWSTemplateFormatVersion 섹션은 템플릿의 기능을 식별합니다. 최신 템플릿 포맷 버전은 2010-09-09이며 현재 유일한 유효 값입니다.
<br>
<br>값을 지정하지 않을 경우 최신 버전이라고 가정합니다.<br>

<br>리터럴 문자이어야합니다.<br>

<br>파라미터나 함수를 사용해 포맷 버전을 지정할 수 있습니다.<br>

<br><br>"AWSTemplateFormatVersion" : "2010-09-09"
Copy<br><br>AWSTemplateFormatVersion: "2010-09-09"
Copy<br><br>
템플릿의 Description 섹션(선택 사항)에 템플릿에 대한 설명을 지정합니다.
<br>
<br>0~1023 바이트 길이의 리터럴 문자열이어야 합니다.
<br>파라미터나 함수를 사용할 수 없습니다.
<br>업데이트 중 수정이 불가능합니다.
<br><br>"Description" : "Here are some details about the template."
Copy<br><br>Description: &gt;
  Here are some
  details about
  the template.
Copy]]></description><link>0.-aws/1.-iac/cloudformation/템플릿.html</link><guid isPermaLink="false">0. AWS/1. IaC/CloudFormation/템플릿.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 07:01:53 GMT</pubDate></item><item><title><![CDATA[<font color="#8064a2">IaC Overview</font>]]></title><description><![CDATA[<a class="tag" href="?query=tag:AWS" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#AWS</a> 
 <br><br><br>IaC는 "Infrastructure as Code"의 약자로, 인프라스트럭처를 코드로 정의하고 관리하는 방식을 가리킵니다. 이는 개발자나 시스템 관리자가 코드를 사용하여 인프라 리소스를 프로비저닝하고 구성하는 것을 의미합니다.<br><br><br>
<br>
일관성: 코드로 정의된 인프라는 반복 가능하며, 인프라 구성이 일관되고 예측 가능하게 됩니다.

<br>
자동화: 코드를 통해 인프라를 프로비저닝하고 구성함으로써, 반복적이고 수동적인 작업을 자동화할 수 있습니다.

<br>
버전 관리: 코드로 정의된 인프라는 버전 관리 시스템을 통해 관리될 수 있으며, 변경 이력을 추적하고 롤백할 수 있습니다.

<br>
안정성: IaC를 사용하면 실수를 줄이고, 변경 사항에 대한 테스트 및 검증을 수행할 수 있으므로 시스템의 안정성이 향상됩니다.

<br>
유연성: 코드로 정의된 인프라는 변경에 대응하기 쉽습니다. 새로운 요구 사항이나 확장성이 필요한 경우 코드를 수정하여 인프라를 업데이트할 수 있습니다.

<br><br><br>주요한 IaC 도구로는 AWS CloudFormation, Terraform, Ansible, Chef, Puppet 등이 있습니다. 이러한 도구들을 사용하여 개발자와 운영팀은 코드를 통해 인프라를 효율적으로 관리하고 운영할 수 있습니다.<br><a href=".?query=tag:AWS" class="tag" target="_blank" rel="noopener">#AWS</a><br><a data-href="0 CloudFormation" href="0.-aws/1.-iac/cloudformation/0-cloudformation.html" class="internal-link" target="_self" rel="noopener">0 CloudFormation</a>]]></description><link>0.-aws/1.-iac/1.-iac.html</link><guid isPermaLink="false">0. AWS/1. IaC/1. IaC.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 14:40:31 GMT</pubDate></item><item><title><![CDATA[AWS]]></title><description><![CDATA[<a class="tag" href="?query=tag:Root" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#Root</a> 
 <br><br>AWS는 "Amazon Web Services"의 약자로, 아마존이 제공하는 클라우드 컴퓨팅 플랫폼 및 서비스를 가리킵니다. AWS는 인프라스트럭처(서버, 스토리지, 네트워킹 등)부터 데이터베이스, 인공지능, 머신 러닝, 개발 도구, 보안, 분석, 그리고 IoT와 같은 다양한 기술 스택을 제공합니다. 이를 통해 기업이나 개발자들은 필요한 인프라를 프로비저닝하고 애플리케이션을 배포하며, 스케일링하고 관리하는 등의 작업을 AWS의 클라우드 플랫폼을 통해 수행할 수 있습니다. <br><br>
<br>확장성 및 유연성: AWS는 필요에 따라 리소스를 확장하거나 축소할 수 있는 유연한 인프라를 제공합니다. 개발자는 애플리케이션의 수요가 변할 때 쉽게 대응할 수 있습니다.
<br>다양한 서비스: AWS는 다양한 서비스를 제공하여 개발자가 필요로 하는 모든 것을 하나의 플랫폼에서 제공합니다. 데이터베이스, 스토리지, 컴퓨팅, 인공지능, 머신 러닝, 보안, IoT 등의 다양한 서비스를 활용할 수 있습니다.
<br>비용 효율성: AWS는 사용한 만큼 비용을 지불하는 Pay-As-You-Go 모델을 채택하고 있어, 개발자는 실제로 사용한 리소스에 대해서만 비용을 지불하게 됩니다. 또한 예약 인스턴스 및 스팟 인스턴스와 같은 할인 모델도 제공하여 비용을 절감할 수 있습니다.
<br>보안: AWS는 업계 표준을 준수하며, 다양한 보안 도구 및 서비스를 제공하여 개발자가 애플리케이션을 안전하게 운영할 수 있도록 지원합니다. 이는 데이터 보안, 네트워크 보안, 액세스 제어 및 모니터링 등을 포함합니다.
<br>글로벌 인프라: AWS는 전 세계에 걸쳐 다양한 리전과 가용 영역을 제공하여 개발자가 애플리케이션을 전 세계적으로 배포하고 사용자에게 접근할 수 있도록 합니다.
<br>자동화 및 관리: AWS는 다양한 자동화 도구와 관리 서비스를 제공하여 개발자가 애플리케이션을 효율적으로 관리하고 유지보수할 수 있도록 지원합니다. 예를 들어, AWS Elastic Beanstalk, AWS Lambda, AWS CloudFormation 등의 서비스를 통해 개발 및 배포 과정을 자동화할 수 있습니다.
<br><a data-href="1. 고가용성 및 스케일링" href="0.-aws/1.-고가용성-및-스케일링/1.-고가용성-및-스케일링.html" class="internal-link" target="_self" rel="noopener">1. 고가용성 및 스케일링</a><br>
<a data-href="1. IaC" href="0.-aws/1.-iac/1.-iac.html" class="internal-link" target="_self" rel="noopener">1. IaC</a><br><a href=".?query=tag:Root" class="tag" target="_blank" rel="noopener">#Root</a>]]></description><link>0.-aws/0.-aws.html</link><guid isPermaLink="false">0. AWS/0. AWS.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 14:40:47 GMT</pubDate></item><item><title><![CDATA[구조 패턴]]></title><description><![CDATA[ 
 <br><br>
클래스와 객체를 효율적으로 구성하여 더 큰 구조를 형성하고, 서로 간의 관계를 단순화하고 유연하게 만드는 디자인 패턴의 한 유형입니다.
<br><br>
<br><a data-href="데코레이터" href="0.-clean-code/1.-design-pattern/2.-구조-패턴/데코레이터.html" class="internal-link" target="_self" rel="noopener">데코레이터</a>: 객체에 동적으로 새로운 행동이나 상태를 추가할 수 있게 해주는 패턴.
<br><a data-href="복합체" href="0.-clean-code/1.-design-pattern/2.-구조-패턴/복합체.html" class="internal-link" target="_self" rel="noopener">복합체</a>(Composite): 객체들을 트리 구조로 구성하여 부분-전체 계층을 구현하고, 개별 객체와 복합 객체를 동일하게 다루는 패턴.
<br><a data-href="브리지" href="0.-clean-code/1.-design-pattern/2.-구조-패턴/브리지.html" class="internal-link" target="_self" rel="noopener">브리지</a>(Bridge): 추상적인 부분과 구체적인 구현 부분을 분리하여 독립적으로 변형할 수 있게 해주는 패턴.
<br><a data-href="어댑터" href="0.-clean-code/1.-design-pattern/2.-구조-패턴/어댑터.html" class="internal-link" target="_self" rel="noopener">어댑터</a> (Adapter): 기존 인터페이스를 다른 인터페이스로 변환하여 호환되지 않는 인터페이스들 간의 협력을 가능하게 해주는 패턴.
<br><a data-href="파사드" href="0.-clean-code/1.-design-pattern/2.-구조-패턴/파사드.html" class="internal-link" target="_self" rel="noopener">파사드</a> (Facade): 서브시스템에 대한 간단한 인터페이스를 제공하여 복잡한 서브시스템을 쉽게 사용할 수 있게 해주는 패턴.
<br><a data-href="프록시" href="0.-clean-code/1.-design-pattern/2.-구조-패턴/프록시.html" class="internal-link" target="_self" rel="noopener">프록시</a> (Proxy): 다른 객체에 대한 접근을 제어하기 위해 대리자나 자리 채움 객체를 제공하는 패턴.
<br><a data-href="플라이웨이트" href="0.-clean-code/1.-design-pattern/2.-구조-패턴/플라이웨이트.html" class="internal-link" target="_self" rel="noopener">플라이웨이트</a> (Flyweight): 다수의 작은 객체들을 효율적으로 지원하기 위해 공유를 통해 메모리를 절약하는 패턴.
<br> : ]]></description><link>0.-clean-code/1.-design-pattern/2.-구조-패턴/2.-구조-패턴.html</link><guid isPermaLink="false">0. Clean Code/1. Design Pattern/2. 구조 패턴/2. 구조 패턴.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 12:00:12 GMT</pubDate></item><item><title><![CDATA[데코레이터]]></title><description><![CDATA[ 
 ]]></description><link>0.-clean-code/1.-design-pattern/2.-구조-패턴/데코레이터.html</link><guid isPermaLink="false">0. Clean Code/1. Design Pattern/2. 구조 패턴/데코레이터.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 11:05:49 GMT</pubDate></item><item><title><![CDATA[플라이웨이트]]></title><description><![CDATA[ 
 ]]></description><link>0.-clean-code/1.-design-pattern/2.-구조-패턴/플라이웨이트.html</link><guid isPermaLink="false">0. Clean Code/1. Design Pattern/2. 구조 패턴/플라이웨이트.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 11:06:02 GMT</pubDate></item><item><title><![CDATA[생성 패턴]]></title><description><![CDATA[ 
 <br><br>
객체 생성 메커니즘을 다루는 디자인 패턴의 한 유형입니다.
<br><br>
<br><a data-href="빌더" href="0.-clean-code/1.-design-pattern/2.-생성-패턴/빌더.html" class="internal-link" target="_self" rel="noopener">빌더</a> (Builder): 객체의 생성 과정을 단계별로 나누고, 다양한 표현을 통해 동일한 생성 절차를 수행할 수 있게 하는 패턴.
<br><a data-href="싱글톤" href="0.-clean-code/1.-design-pattern/2.-생성-패턴/싱글톤.html" class="internal-link" target="_self" rel="noopener">싱글톤</a> (Singleton): 클래스의 인스턴스를 하나만 생성하여 전역에서 접근할 수 있도록 보장하는 패턴.
<br><a data-href="추상 팩토리" href="0.-clean-code/1.-design-pattern/2.-생성-패턴/추상-팩토리.html" class="internal-link" target="_self" rel="noopener">추상 팩토리</a> (Abstract Factory): 관련된 객체들을 구체적인 클래스에 의존하지 않고 생성할 수 있게 해주는 인터페이스를 제공하는 패턴.
<br><a data-href="팩토리" href="0.-clean-code/1.-design-pattern/2.-생성-패턴/팩토리.html" class="internal-link" target="_self" rel="noopener">팩토리</a>(Factory Method): 객체 생성을 서브클래스에서 정의할 수 있도록 하여 객체 생성의 인터페이스를 정의하지만, 실제 객체 생성은 서브클래스에서 처리하는 패턴.
<br><a data-href="프로토타입" href="0.-clean-code/1.-design-pattern/2.-생성-패턴/프로토타입.html" class="internal-link" target="_self" rel="noopener">프로토타입</a>(Prototype): 새 객체를 생성할 때, 기존 객체를 복사하여 생성하는 패턴.
]]></description><link>0.-clean-code/1.-design-pattern/2.-생성-패턴/2.-생성-패턴.html</link><guid isPermaLink="false">0. Clean Code/1. Design Pattern/2. 생성 패턴/2. 생성 패턴.md</guid><dc:creator><![CDATA[1week]]></dc:creator><pubDate>Sun, 02 Jun 2024 11:58:52 GMT</pubDate></item><item><title><![CDATA[문제]]></title><description/></item></channel></rss>